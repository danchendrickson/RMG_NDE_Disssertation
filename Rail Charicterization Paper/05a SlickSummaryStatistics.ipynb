{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASC Accelerometer analysis via Summary Statistics \n",
    "\n",
    "FDeveloping moving average acceleration and moving Standard Deviation for each data set.\n",
    "\n",
    "Can run through a whole folder, or through random selections from the folder\n",
    "\n",
    "## This is attempting a slicker method using matrix multiplication.  With that can then attempt GPU parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "import pandas as pd\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "if not 'location' in locals():\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\n",
    "    #location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\Prospectus\\\\Document\\\\Figures\\\\'\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Phd\\\\Play\\\\'\n",
    "\n",
    "#Standard cycle for collors and line styles\n",
    "#default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "#plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import statistics as st\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns names for a file with all 6 dimmensions\n",
    "Header = np.array(['T', 'X','Y','Z','R','Theta','Phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opens all files in a folder and returns the 3 axis acceleration in one array\n",
    "# made to run in parallel\n",
    "\n",
    "def getAcceleration(FileName):\n",
    "    try:\n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\n",
    "        return [[FileName[:7]+FileName[-5:-4],'x',DataSet[:,3]],[FileName[:7]+FileName[-5:-4],'y',DataSet[:,4]],[FileName[:7]+FileName[-5:-4],'z',DataSet[:,5]]]\n",
    "    except:\n",
    "        return [False,FileName,False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first attempt at making stats by brute force, very slow\n",
    "def makeStats(DataArray):\n",
    "    try:\n",
    "        Arange = 50\n",
    "        length = np.shape(DataArray[2])[0]\n",
    "        StdDev = np.zeros(length)\n",
    "        for j in range(length-Arange):\n",
    "            k = (length-1)-j\n",
    "            DataArray[2][k] = np.average(DataArray[2][k-Arange:k])\n",
    "            StdDev[k]=st.stdev(DataArray[2][k-Arange:k])\n",
    "        return [DataArray[0],DataArray[1],max(DataArray[2]),max(StdDev)]\n",
    "    except:\n",
    "        return ['','','','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses matrixes and numpy to calculate the standard deviations of each row simultaneously.\n",
    "# designed to run each time step independently\n",
    "# can be run in parallel\n",
    "\n",
    "def MatStdDev(MoveMatrix, AvgVector):\n",
    "    width = np.shape(MoveMatrix)[1]\n",
    "\n",
    "    AvgMatrix = np.concatenate((AvgVector,AvgVector),axis=1)\n",
    "    for i in range(width-2):\n",
    "        AvgMatrix = np.concatenate((AvgMatrix,AvgVector),axis=1)\n",
    "    AvgVector = []\n",
    "\n",
    "    Deltas = MoveMatrix - AvgMatrix\n",
    "    AvgMatrix = []\n",
    "    MoveMatrix = []\n",
    "\n",
    "    SquareDifference = np.power(Deltas,2)\n",
    "    Deltas = []\n",
    "\n",
    "    one = np.ones((width))\n",
    "\n",
    "    SumSquares = SquareDifference.dot(one)\n",
    "    SquareDifference = []\n",
    "\n",
    "    StdDev = np.power(SumSquares, 0.5) / width\n",
    "    SumSquares = []\n",
    "\n",
    "    return StdDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs:\n",
    "folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\n",
    "folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\n",
    "\n",
    "folder1 = \"S:\\\\\"\n",
    "folder2 = \"S:\\\\\"\n",
    "\n",
    "folder1 = '/sciclone/scr10/dchendrickson01/Recordings2/SubSet/'\n",
    "folder2 = '/sciclone/scr10/dchendrickson01/Recordings2/SubSet/'\n",
    "files = os.listdir(folder2)\n",
    "\n",
    "Groups = 0\n",
    "GroupSize = 50\n",
    "\n",
    "RollingSize = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Calculations\n",
    "\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "if np.shape(files)[0] < GroupSize:\n",
    "    GroupSize = np.shape(files)[0]\n",
    "\n",
    "if Groups !=0:\n",
    "    files = random.sample(files,GroupSize*Groups-1)\n",
    "\n",
    "if np.size(files) % GroupSize ==0:\n",
    "    loops = int(np.size(files)/GroupSize)\n",
    "else:\n",
    "    loops = int(float(np.size(files))/float(GroupSize))+1\n",
    "start = time.time()\n",
    "\n",
    "inverseRollingSize = 1 / RollingSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "AllEvents=[]\n",
    "Fails = []\n",
    "#    for i in range(loops):\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder2+file) for file in files[i*GroupSize:((i+1)*GroupSize)])\n",
    "MetaData = []\n",
    "DataOnlyMatrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 11745763 and the array at index 1 has size 26036970",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_151413/3298064324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mDataOnlyMatrix\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllAccels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0mDataOnlyMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataOnlyMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllAccels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mDataOnlyMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataOnlyMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 11745763 and the array at index 1 has size 26036970"
     ]
    }
   ],
   "source": [
    "for j in range(np.shape(AllAccels)[0]):\n",
    "    if AllAccels[j][0] == False :\n",
    "        if AllAccels[j][1][4:9] =='Point':\n",
    "            print(j,AllAccels[j][1])\n",
    "    else: \n",
    "        for k in range(3):\n",
    "            MetaData.append([AllAccels[j][k][0], AllAccels[j][k][1]])\n",
    "            if np.shape(np.matrix(AllAccels[j][k][2]))[1] < 60000:\n",
    "                temp = np.pad(np.matrix(AllAccels[j][k][2]),(60000-np.shape(np.matrix(AllAccels[j][k][2]))[1],0))[0]\n",
    "                temp=np.matrix(temp)\n",
    "                if np.size(DataOnlyMatrix) == 0:\n",
    "                    DataOnlyMatrix =np.matrix(temp)\n",
    "                    temp=[]\n",
    "                else:\n",
    "                    DataOnlyMatrix = np.concatenate((DataOnlyMatrix,temp),axis=0)\n",
    "                    temp=[]\n",
    "            else:\n",
    "                if np.size(DataOnlyMatrix) == 0:\n",
    "                    DataOnlyMatrix =np.matrix(AllAccels[j][k][2])\n",
    "                else:\n",
    "                    DataOnlyMatrix = np.concatenate((DataOnlyMatrix,np.matrix(AllAccels[j][k][2])),axis=0)\n",
    "\n",
    "DataOnlyMatrix = np.matrix(DataOnlyMatrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 (8, 3)\n"
     ]
    }
   ],
   "source": [
    "length = np.shape(DataOnlyMatrix)[1]\n",
    "halfLength = int(length / 2)\n",
    "\n",
    "print(length, halfLength, np.shape(AllAccels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllAccels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights1 = np.zeros((halfLength,halfLength))\n",
    "Weights2 = np.zeros((halfLength,halfLength+RollingSize-1))\n",
    "\n",
    "for j in range(halfLength):\n",
    "    r = j+1\n",
    "\n",
    "    if r < RollingSize:\n",
    "       ir = 1/ r\n",
    "       for k in range(r):\n",
    "            Weights1[k,j] = ir\n",
    "    else:\n",
    "        for k in range(RollingSize):\n",
    "            Weights1[r-RollingSize+k, j] = inverseRollingSize\n",
    "    for k in range(RollingSize):\n",
    "        Weights2[j,j+k] = inverseRollingSize\n",
    "\n",
    "FirstBit = np.dot(DataOnlyMatrix[:,:halfLength], Weights1)\n",
    "Weights1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if length % 2 == 1: halfLength += 1\n",
    "Weights2=Weights2[:,:halfLength]\n",
    "SecondBit = np.dot(DataOnlyMatrix[:,halfLength:], Weights2)\n",
    "\n",
    "Weights2 = [] \n",
    "\n",
    "Weights3 = np.zeros((halfLength,halfLength))\n",
    "for j in range(RollingSize-1):\n",
    "    for k in range(RollingSize-j-1):\n",
    "        Weights3[halfLength-k-1,j] = inverseRollingSize\n",
    "\n",
    "SecondBit = SecondBit + np.dot(DataOnlyMatrix[:,halfLength:], Weights3)\n",
    "Weights3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_151413/60285780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRollingSize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRollingSize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mWeights3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhalfLength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverseRollingSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mSecondBit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSecondBit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataOnlyMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalfLength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeights3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "Averages = np.concatenate((FirstBit, SecondBit), axis=1)\n",
    "FirstBit = []\n",
    "SecondBit = []\n",
    "\n",
    "# Calculating the Standard Devation by square\n",
    "AllStdDevs = Parallel(n_jobs=num_cores)(delayed(MatStdDev)(DataOnlyMatrix[:,i:RollingSize+i],Averages[:,RollingSize+i] ) for i in range(length-RollingSize))\n",
    "AllStdDevs=np.squeeze(AllStdDevs)\n",
    "AllStdDevs = np.concatenate( (np.zeros((RollingSize,np.shape(AllStdDevs)[1])), AllStdDevs),axis=0)\n",
    "\n",
    "one = np.ones((length))\n",
    "AvgVector = Averages.dot(one) / np.shape(Averages)[0]\n",
    "#Averages = []\n",
    "\n",
    "AllStdDevs = np.transpose(AllStdDevs)\n",
    "StdDevVector = AllStdDevs.dot(one) / np.shape(AllStdDevs)[0]\n",
    "#AllStdDevs = []\n",
    "\n",
    "if np.size(AllEvents) == 0:\n",
    "    temp = np.concatenate((MetaData, AvgVector.transpose()), axis=1)\n",
    "    AllEvents = np.concatenate((temp, np.matrix(StdDevVector).transpose()),axis = 1)\n",
    "else:\n",
    "    temp = np.concatenate((MetaData, AvgVector.transpose()), axis=1)\n",
    "    temp = np.concatenate((temp, np.matrix(StdDevVector).transpose()),axis = 1)\n",
    "    AllEvents = np.concatenate((AllEvents,temp),axis=0)\n",
    "    temp=[]\n",
    "print('Loop ' + str(i+1) + ' of ' + str(loops) + '.  Total time is ' + str((time.time() - start) / 60) + ' min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=AllEvents)\n",
    "df.to_csv(folder1 + 'StatisticsReport2.csv', sep=',', index = False, header=False,quotechar='\"')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "54d4a74d2acb620b973b6686d9e092ebabe111cf1da47c2d23b0fd51788c9859"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
