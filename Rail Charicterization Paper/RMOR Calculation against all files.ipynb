{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at accelerometer data \n",
    "\n",
    "Finding Zero velocity times by rail axis acceleration noise levels, making summary statistics for the noise levels across the whole day files.  Spot check graphs to see what works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "\n",
    "from time import time as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CoreFunctions as cf\n",
    "from skimage.restoration import denoise_wavelet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Platform\n",
    "Working is beinging conducted on several computers, and author needs to be able to run code on all without rewriting..  This segment of determines which computer is being used, and sets the directories accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HostName = platform.node()\n",
    "\n",
    "if HostName == \"Server\":\n",
    "    Computer = \"Desktop\"   \n",
    "elif HostName[-6:] == 'wm.edu':\n",
    "    Computer = \"SciClone\"\n",
    "elif HostName == \"SchoolLaptop\":\n",
    "    Computer = \"LinLap\"\n",
    "elif HostName == \"WTC-TAB-512\":\n",
    "    Computer = \"PortLap\"\n",
    "else:\n",
    "    Computer = \"WinLap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home/dchendrickson01/'\n",
    "    folder = '/sciclone/scr10/dchendrickson01/Recordings2/Recent/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\SubSet\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'Recordings2/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'Recordings2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(folder)\n",
    "#files=files[15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saving = False\n",
    "location = folder\n",
    "Titles = True\n",
    "Ledgends = True\n",
    "\n",
    "f = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RollingStdDev(RawData, SmoothData, RollSize = 25):\n",
    "    StdDevs = []\n",
    "    for i in range(RollSize):\n",
    "        Diffs = RawData[0:i+1]-SmoothData[0:i+1]\n",
    "        Sqs = Diffs * Diffs\n",
    "        Var = sum(Sqs) / (i+1)\n",
    "        StdDev = np.sqrt(Var)\n",
    "        StdDevs.append(StdDev)\n",
    "    for i in range(len(RawData)-RollSize-1):\n",
    "        j = i + RollSize\n",
    "        Diffs = RawData[i:j]-SmoothData[i:j]\n",
    "        Sqs = Diffs * Diffs\n",
    "        Var = sum(Sqs) / RollSize\n",
    "        StdDev = np.sqrt(Var)\n",
    "        StdDevs.append(StdDev)  \n",
    "    \n",
    "    return StdDevs\n",
    "\n",
    "def RollingSum(Data, Length = 100):\n",
    "    RollSumStdDev = []\n",
    "    for i in range(Length):\n",
    "        RollSumStdDev.append(sum(Data[0:i+1]))\n",
    "    for i in range(len(Data) - Length):\n",
    "        RollSumStdDev.append(sum(Data[i:i+Length]))\n",
    "    return RollSumStdDev\n",
    "\n",
    "def SquelchPattern(DataSet, StallRange = 5000, SquelchLevel = 0.0086):\n",
    "    SquelchSignal = []\n",
    "\n",
    "    for i in range(StallRange):\n",
    "        SquelchSignal.append(1)\n",
    "\n",
    "    for i in range(len(DataSet)-2*StallRange):\n",
    "        if np.average(DataSet[i:i+2*StallRange]) < SquelchLevel:\n",
    "            SquelchSignal.append(0)\n",
    "        else:\n",
    "            SquelchSignal.append(1)\n",
    "\n",
    "    for i in range(StallRange+1):\n",
    "        SquelchSignal.append(1)    \n",
    "    \n",
    "    return SquelchSignal\n",
    "\n",
    "def getVelocity(Acceleration, Timestamps = 0.003, Squelch = [], corrected = 0):\n",
    "    velocity = np.zeros(len(Acceleration))\n",
    "    \n",
    "    if len(Timestamps) == 1:\n",
    "        dTime = Timestamps\n",
    "    elif len(Timestamps) == len(Acceleration):\n",
    "        totTime = 0\n",
    "        for i in range(len(Timestamps)-1):\n",
    "            if Timestamps[i]<Timestamps[i+1]:\n",
    "                totTime += (Timestamps[i+1] - Timestamps[i])\n",
    "            else:\n",
    "                totTime += (Timestamps[i+1] - Timestamps[i] + 10000)\n",
    "        dTime = totTime / len(Timestamps)\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "    dTime = dTime / 10000.0\n",
    "\n",
    "    velocity[0] = Acceleration[0] * (dTime)\n",
    "\n",
    "    for i in range(len(Acceleration)-1):\n",
    "        j = i + 1\n",
    "        if corrected ==2:\n",
    "            if Squelch[j]==0:\n",
    "                velocity[j]=0\n",
    "            else:\n",
    "                velocity[j] = velocity[i] + Acceleration[j] * dTime                \n",
    "        else:\n",
    "            velocity[j] = velocity[i] + Acceleration[j] * dTime\n",
    "\n",
    "    if corrected == 1:\n",
    "        PointVairance = velocity[-1:] / len(velocity)\n",
    "        for i in range(len(velocity)):\n",
    "            velocity[i] -=  PointVairance * i\n",
    "    \n",
    "    velocity *= 9.81\n",
    "\n",
    "    return velocity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth = cf.Smoothing(ODataSet[:,3],2) #,50)\n",
    "def DeviationVelocity(file):\n",
    "    if file[-3:] =='csv':\n",
    "        #try: \n",
    "        ODataSet = np.genfromtxt(open(folder+file,'r'), delimiter=',',skip_header=0,missing_values=0,invalid_raise=False)\n",
    "        SmoothX = denoise_wavelet(ODataSet[:,3], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "        SmoothY = denoise_wavelet(ODataSet[:,4], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "        SmoothZ = denoise_wavelet(ODataSet[:,5], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "        StdDevsX = RollingStdDev(ODataSet[:,3],SmoothX)\n",
    "        StdDevsY = RollingStdDev(ODataSet[:,4],SmoothY)\n",
    "        StdDevsZ = RollingStdDev(ODataSet[:,5],SmoothZ)\n",
    "        StdDevsX.append(0)\n",
    "        StdDevsY.append(0)\n",
    "        StdDevsZ.append(0)\n",
    "        StdDevsX = np.asarray(StdDevsX)\n",
    "        StdDevsY = np.asarray(StdDevsY)\n",
    "        StdDevsZ = np.asarray(StdDevsZ)\n",
    "        SmoothDevX = denoise_wavelet(StdDevsX, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "        SmoothDevY = denoise_wavelet(StdDevsY, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "        SmoothDevZ = denoise_wavelet(StdDevsZ, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "        RollSumStdDevX = RollingSum(SmoothDevX)\n",
    "        RollSumStdDevX = np.asarray(RollSumStdDevX)\n",
    "        RollSumStdDevY = RollingSum(SmoothDevY)\n",
    "        RollSumStdDevY = np.asarray(RollSumStdDevY)\n",
    "        RollSumStdDevZ = RollingSum(SmoothDevZ)\n",
    "        RollSumStdDevZ = np.asarray(RollSumStdDevZ)\n",
    "        SquelchSignal = SquelchPattern(SmoothDevX, 3000, 0.01)\n",
    "        Velocity = getVelocity(ODataSet[:,3], ODataSet[:,2],SquelchSignal, 2)\n",
    "        Velocity = np.asarray(Velocity)\n",
    "\n",
    "        #except:\n",
    "        #    Velocity = file\n",
    "        #    StdDevsX = 0\n",
    "        #    RollSumStdDevX = 0\n",
    "        #    StdDevsY = 0\n",
    "        #    RollSumStdDevY = 0\n",
    "        #    StdDevsZ = 0\n",
    "        #    RollSumStdDevZ = 0\n",
    "        #    SquelchSignal = 0\n",
    "        #    print(file)\n",
    "        return [Velocity, [StdDevsX, StdDevsY, StdDevsZ], [RollSumStdDevX,RollSumStdDevY,RollSumStdDevZ], SquelchSignal]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "fi2 = []\n",
    "\n",
    "now = dt.datetime.now()\n",
    "ago = now-dt.timedelta(days=60) #last run 1/19\n",
    "\n",
    "for root, dirs,files in os.walk(folder):  \n",
    "    for fname in files:\n",
    "        path = os.path.join(root, fname)\n",
    "        st = os.stat(path)    \n",
    "        mtime = dt.datetime.fromtimestamp(st.st_ctime)\n",
    "        if mtime > ago:\n",
    "            fi2.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['230610 recording2.csv',\n",
       " '230515 recording1.csv',\n",
       " '230602 recording1.csv',\n",
       " '230515 recording4.csv',\n",
       " '230606 recording2.csv',\n",
       " '230607 recording2.csv',\n",
       " '230616 recording1.csv',\n",
       " '230611 recording4.csv',\n",
       " '230609 recording1.csv',\n",
       " '230603 recording1.csv',\n",
       " '230613 recording2.csv',\n",
       " '230622 recording1.csv',\n",
       " '230614 recording1.csv',\n",
       " '230704 recording4.csv',\n",
       " '230522 recording2.csv',\n",
       " '230611 recording1.csv',\n",
       " '230522 recording4a.csv',\n",
       " '230614 recording4.csv',\n",
       " '230517 recording4.csv',\n",
       " '230618 recording1.csv',\n",
       " '230516 recording4.csv',\n",
       " '230619 recording1.csv',\n",
       " '230518 recording4.csv',\n",
       " '230615 recording1.csv',\n",
       " '230519 recording4.csv',\n",
       " '230617 recording1.csv',\n",
       " '230520 recording4.csv',\n",
       " '230615 recording4.csv',\n",
       " '230522 recording4.csv',\n",
       " '230618 recording4.csv',\n",
       " '230523 recording2.csv',\n",
       " '230616 recording2.csv',\n",
       " '230521 recording4.csv',\n",
       " '230616 recording4.csv',\n",
       " '230523 recording4.csv',\n",
       " '230617 recording4.csv',\n",
       " '230524 recording4.csv',\n",
       " '230621 recording4.csv',\n",
       " '230524 recording2.csv',\n",
       " '230615 recording2.csv',\n",
       " '230527 recording2.csv',\n",
       " '230626 recording1.csv',\n",
       " '230525 recording2.csv',\n",
       " '230622 recording4.csv',\n",
       " '230528 recording2.csv',\n",
       " '230619 recording4.csv',\n",
       " '230529 recording2.csv',\n",
       " '230614 recording2.csv',\n",
       " '230530 recording2.csv',\n",
       " '230624 recording1.csv',\n",
       " '230531 recording2.csv',\n",
       " '230620 recording4.csv',\n",
       " '230601 recording1.csv',\n",
       " '230601 recording2.csv',\n",
       " '230625 recording1.csv',\n",
       " '230526 recording2.csv',\n",
       " '230620 recording1.csv',\n",
       " '230602 recording2.csv',\n",
       " '230627 recording1.csv',\n",
       " '230603 recording2.csv',\n",
       " '230628 recording1.csv',\n",
       " '230604 recording1.csv',\n",
       " '230621 recording1.csv',\n",
       " '230604 recording2.csv',\n",
       " '230623 recording4.csv',\n",
       " '230606 recording1.csv',\n",
       " '230704 recording1.csv',\n",
       " '230605 recording2.csv',\n",
       " '230605 recording1.csv',\n",
       " '230704 recording2.csv',\n",
       " '230607 recording1.csv',\n",
       " '230623 recording1.csv',\n",
       " '230624 recording4.csv',\n",
       " '230608 recording1.csv',\n",
       " '230610 recording4.csv',\n",
       " '230628 recording2.csv',\n",
       " '230608 recording2.csv',\n",
       " '230610 recording1.csv',\n",
       " '230609 recording2.csv',\n",
       " '230612 recording4.csv',\n",
       " '230626 recording4.csv',\n",
       " '230612 recording1.csv',\n",
       " '230627 recording2.csv',\n",
       " '230612 recording2.csv',\n",
       " '230627 recording4.csv',\n",
       " '230613 recording1.csv',\n",
       " '230611 recording2.csv',\n",
       " '230613 recording4.csv',\n",
       " '230625 recording4.csv',\n",
       " '230819 recording2.csv',\n",
       " '230703 recording4.csv',\n",
       " '230702 recording4.csv',\n",
       " '230703 recording1.csv',\n",
       " '230701 recording1.csv',\n",
       " '230817 recording2.csv',\n",
       " '230702 recording1.csv',\n",
       " '230701 recording4.csv',\n",
       " '230702 recording2.csv',\n",
       " '230703 recording2.csv',\n",
       " '230630 recording1.csv',\n",
       " '230630 recording4.csv',\n",
       " '230701 recording2.csv',\n",
       " '230629 recording4.csv',\n",
       " '230807 recording2.csv',\n",
       " '230629 recording1.csv',\n",
       " '230630 recording2.csv',\n",
       " '230628 recording4.csv',\n",
       " '230714 recording2.csv',\n",
       " '230626 recording3.csv',\n",
       " '230629 recording2.csv',\n",
       " '230515 recording3.csv',\n",
       " '230508 recording3.csv',\n",
       " '230823 recording2.csv',\n",
       " '230821 recording1.csv',\n",
       " '230816 recording2.csv',\n",
       " '230821 recording2.csv',\n",
       " '230820 recording2.csv',\n",
       " '230522 recording3.csv',\n",
       " '230815 recording2.csv',\n",
       " '230818 recording2.csv',\n",
       " '230626 recording2.csv',\n",
       " '230818 recording1.csv',\n",
       " '230716 recording1.csv',\n",
       " '230325 recording3.csv',\n",
       " '230322 recording3.csv',\n",
       " '230319 recording3.csv',\n",
       " '230317 recording3.csv',\n",
       " '230320 recording3.csv',\n",
       " '230321 recording3.csv',\n",
       " '230318 recording3.csv',\n",
       " '230805 recording2.csv',\n",
       " '230822 recording1.csv',\n",
       " '230804 recording2.csv',\n",
       " '230819 recording1.csv',\n",
       " '230718 recording2.csv',\n",
       " '230901 recording1.csv',\n",
       " '230824 recording2.csv',\n",
       " '230814 recording2.csv',\n",
       " '230820 recording1.csv',\n",
       " '230806 recording2.csv',\n",
       " '230822 recording2.csv',\n",
       " '230901 recording2.csv',\n",
       " '230813 recording2.csv',\n",
       " '230831 recording1.csv',\n",
       " '230810 recording2.csv',\n",
       " '230830 recording1.csv',\n",
       " '230812 recording2.csv',\n",
       " '230828 recording1.csv',\n",
       " '230803 recording1.csv',\n",
       " '230829 recording1.csv',\n",
       " '230809 recording2.csv',\n",
       " '230831 recording2.csv',\n",
       " '230808 recording2.csv',\n",
       " '230830 recording2.csv',\n",
       " '230726 recording1.csv',\n",
       " '230829 recording2.csv',\n",
       " '230802 recording2.csv',\n",
       " '230828 recording2.csv',\n",
       " '230731 recording2.csv',\n",
       " '230827 recording1.csv',\n",
       " '230801 recording1.csv',\n",
       " '230826 recording1.csv',\n",
       " '230803 recording2.csv',\n",
       " '230825 recording1.csv',\n",
       " '230326 recording3.csv',\n",
       " '230826 recording2.csv',\n",
       " '230802 recording1.csv',\n",
       " '230827 recording2.csv',\n",
       " '230731 recording1.csv',\n",
       " '230824 recording1.csv',\n",
       " '230715 recording1.csv',\n",
       " '230823 recording1.csv',\n",
       " '230717 recording2.csv',\n",
       " '230825 recording2.csv',\n",
       " '230716 recording2.csv',\n",
       " '230727 recording1.csv',\n",
       " '230818 recording2b.csv',\n",
       " '230715 recording2.csv',\n",
       " '230811 recording2.csv',\n",
       " '230801 recording2.csv',\n",
       " '230725 recording1.csv',\n",
       " '230723 recording1.csv',\n",
       " '230724 recording1.csv',\n",
       " '230722 recording1.csv',\n",
       " '230721 recording1.csv',\n",
       " '230720 recording1.csv',\n",
       " '230719 recording2.csv',\n",
       " '230719 recording1.csv',\n",
       " '230718 recording1.csv',\n",
       " '230717 recording1.csv',\n",
       " '230714 recording1.csv',\n",
       " '230626 recording1b.csv',\n",
       " '230327 recording3.csv',\n",
       " '230329 recording3.csv',\n",
       " '230330 recording3.csv',\n",
       " '230331 recording3.csv',\n",
       " '230401 recording3.csv',\n",
       " '230403 recording3.csv',\n",
       " '230410 recording3.csv',\n",
       " '230413 recording3.csv',\n",
       " '230417 recording3.csv',\n",
       " '230420 recording3.csv',\n",
       " '230424 recording3.csv',\n",
       " '230627 recording3.csv',\n",
       " '230628 recording3.csv',\n",
       " '230629 recording3.csv',\n",
       " '230630 recording3.csv',\n",
       " '230701 recording3.csv',\n",
       " '230704 recording3.csv',\n",
       " '230714 recording3.csv',\n",
       " '230715 recording3.csv',\n",
       " '230716 recording3.csv',\n",
       " '230717 recording3.csv',\n",
       " '230718 recording3.csv',\n",
       " '230726 recording3.csv',\n",
       " '230731 recording3.csv',\n",
       " '230901 recording1b.csv',\n",
       " '230901 recording2b.csv',\n",
       " '230902 recording2.csv',\n",
       " '230903 recording2.csv',\n",
       " '230904 recording2.csv',\n",
       " '230905 recording2.csv',\n",
       " '230906 recording2.csv',\n",
       " '230907 recording2.csv',\n",
       " '230908 recording2.csv',\n",
       " '230909 recording2.csv',\n",
       " '230910 recording2.csv',\n",
       " '230911 recording2.csv',\n",
       " '230912 recording1.csv',\n",
       " '230912 recording2.csv',\n",
       " '230912 recording2b.csv',\n",
       " '230912 recording3.csv',\n",
       " '230913 recording1.csv',\n",
       " '230913 recording2.csv',\n",
       " '230913 recording3.csv',\n",
       " '230914 recording1.csv',\n",
       " '230914 recording2.csv',\n",
       " '230914 recording3.csv',\n",
       " '230915 recording1.csv',\n",
       " '230915 recording2.csv',\n",
       " '230915 recording3.csv',\n",
       " '230916 recording2.csv',\n",
       " '230916 recording3.csv',\n",
       " '230917 recording2.csv',\n",
       " '230917 recording3.csv',\n",
       " '230918 recording2.csv',\n",
       " '230918 recording2b.csv',\n",
       " '230918 recording3.csv',\n",
       " '230919 recording2.csv',\n",
       " '230920 recording2.csv',\n",
       " '230921 recording2.csv',\n",
       " '230922 recording2.csv',\n",
       " '230923 recording2.csv',\n",
       " '230924 recording2.csv',\n",
       " '230925 recording2.csv',\n",
       " '231012 recording1.csv',\n",
       " '231013 recording1.csv',\n",
       " '231011 recording1.csv',\n",
       " '231016 recording1.csv',\n",
       " '231004 recording1.csv',\n",
       " '231005 recording2.csv',\n",
       " '231013 recording2.csv',\n",
       " '231004 recording3.csv',\n",
       " '230925 recording1.csv',\n",
       " '231016 recording2.csv',\n",
       " '231004 recording2.csv',\n",
       " '231011 recording2.csv',\n",
       " '231015 recording1.csv',\n",
       " '231010 recording1.csv',\n",
       " '231014 recording2.csv',\n",
       " '230919 recording3.csv',\n",
       " '231014 recording1.csv',\n",
       " '231005 recording1.csv',\n",
       " '231015 recording2.csv',\n",
       " '230920 recording3.csv',\n",
       " '231012 recording2.csv',\n",
       " '231009 recording1.csv',\n",
       " '231010 recording2.csv',\n",
       " '231008 recording1.csv',\n",
       " '231009 recording2.csv',\n",
       " '231006 recording3.csv',\n",
       " '231007 recording1.csv',\n",
       " '231008 recording2.csv',\n",
       " '231007 recording2.csv',\n",
       " '231006 recording1.csv',\n",
       " '230925 recording3.csv',\n",
       " '231006 recording2.csv',\n",
       " '231005 recording3.csv',\n",
       " '231002 recording1.csv',\n",
       " '231003 recording1.csv',\n",
       " '230930 recording1.csv',\n",
       " '231002 recording2.csv',\n",
       " '231003 recording2.csv',\n",
       " '230930 recording2.csv',\n",
       " '231001 recording1.csv',\n",
       " '230929 recording1.csv',\n",
       " '231001 recording2.csv',\n",
       " '231004 recording1b.csv',\n",
       " '230927 recording1.csv',\n",
       " '230928 recording1.csv',\n",
       " '230918 recording1.csv',\n",
       " '230929 recording2.csv',\n",
       " '230928 recording2.csv',\n",
       " '230926 recording2.csv',\n",
       " '230927 recording2.csv',\n",
       " '231004 recording2b.csv',\n",
       " '230925 recording2b.csv',\n",
       " '230926 recording1.csv',\n",
       " '230316 recording3.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = fi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoopFiles = 12\n",
    "loops = int(len(files) / LoopFiles) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootfolder = '/sciclone/home/dchendrickson01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeedHeader = True\n",
    "if os.path.exists(rootfolder + 'StdDevBySpeedSummaryStatistics6.csv'):\n",
    "    NeedHeader=False\n",
    "\n",
    "WriteFile = open(rootfolder + 'StdDevBySpeedSummaryStatistics6.csv','a')\n",
    "if NeedHeader:\n",
    "    WriteFile.write('Year, Month, Day, Sensor, am, np.average(MovingDevX), np.average(StopedDevX), np.average(MovingDevY), np.average(StopedDevY), np.average(MovingDevY), np.average(StopedDevY), DevX0, DevX1, DevX2, DevX3, DevX4, DevX5p,DevY0, DevY1, DevY2, DevY3, DevY4, DevY5p,DevZ0, DevZ1, DevZ2, DevZ3, DevZ4, DevZ5p \\n')\n",
    "\n",
    "#k = 22\n",
    "#LoopFiles = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WriteFile\n",
    "\n",
    "\n",
    "st = ti()\n",
    "\n",
    "#loops = 30\n",
    "bump = 0\n",
    "#LoopFiles = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = DeviationVelocity(files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sciclone/home/dchendrickson01/.local/lib/python3.10/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/sciclone/home/dchendrickson01/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12 56.86740265289942\n",
      "1 12 90.18689184983572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scr/dchendrickson01/TMPDIR/ipykernel_175001/1456841940.py:5: ConversionWarning: Some errors were detected !\n",
      "    Line #22828535 (got 2 columns instead of 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 12 123.44124998648961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scr/dchendrickson01/TMPDIR/ipykernel_175001/1456841940.py:5: ConversionWarning: Some errors were detected !\n",
      "    Line #12114045 (got 2 columns instead of 7)\n"
     ]
    }
   ],
   "source": [
    "for j in range(loops-bump):\n",
    "    k = j + bump\n",
    "    if k == loops -1:\n",
    "        tfiles = files[k*LoopFiles:]\n",
    "    else:\n",
    "        tfiles = files[k*LoopFiles:(k+1)*LoopFiles]\n",
    "    Results = Parallel(n_jobs=LoopFiles)(delayed(DeviationVelocity)(file) for file in tfiles)\n",
    "    Velocities = []\n",
    "    StdDevsX = []\n",
    "    SumStdDevsX = []\n",
    "    StdDevsY = []\n",
    "    SumStdDevsY = []\n",
    "    StdDevsZ = []\n",
    "    SumStdDevsZ = []\n",
    "    NewFiles=[]\n",
    "\n",
    "    for i in range(len(Results)):\n",
    "        if Results[i] != None:\n",
    "            Velocities.append(Results[i][0])\n",
    "            StdDevsX.append(Results[i][1][0])\n",
    "            SumStdDevsX.append(Results[i][2][0])\n",
    "            StdDevsY.append(Results[i][1][1])\n",
    "            SumStdDevsY.append(Results[i][2][1])\n",
    "            StdDevsZ.append(Results[i][1][2])\n",
    "            SumStdDevsZ.append(Results[i][2][2])\n",
    "            NewFiles.append(tfiles[i])\n",
    "    MaxDevX=[]\n",
    "    MaxRollX=[]\n",
    "    MaxDevY=[]\n",
    "    MaxRollY=[]\n",
    "    MaxDevZ=[]\n",
    "    MaxRollZ=[]\n",
    "    for i in range(len(StdDevsZ)):\n",
    "        MaxDevX.append(np.max(StdDevsX[i]))\n",
    "        MaxRollX.append(np.max(SumStdDevsX[i]))\n",
    "        MaxDevY.append(np.max(StdDevsY[i]))\n",
    "        MaxRollY.append(np.max(SumStdDevsY[i]))\n",
    "        MaxDevZ.append(np.max(StdDevsZ[i]))\n",
    "        MaxRollZ.append(np.max(SumStdDevsZ[i]))\n",
    "    \n",
    "    Results = []\n",
    "    for i in range(len(MaxDevZ)):\n",
    "        if MaxDevX[i] != 0:\n",
    "            UnitSpeeds = np.abs(Velocities[i]).astype('int')\n",
    "            MovingDevX = StdDevsX[i][np.abs(Velocities[i]) > 1]\n",
    "            StopedDevX = StdDevsX[i][np.abs(Velocities[i]) < 1]\n",
    "            MovingDevY = StdDevsY[i][np.abs(Velocities[i]) > 1]\n",
    "            StopedDevY = StdDevsY[i][np.abs(Velocities[i]) < 1]\n",
    "            MovingDevZ = StdDevsZ[i][np.abs(Velocities[i]) > 1]\n",
    "            StopedDevZ = StdDevsZ[i][np.abs(Velocities[i]) < 1]\n",
    "            DevX0 = np.average(StdDevsX[i][UnitSpeeds < 1])\n",
    "            DevX1 = np.average(StdDevsX[i][(UnitSpeeds < 2) & (UnitSpeeds >= 1)])\n",
    "            DevX2 = np.average(StdDevsX[i][(UnitSpeeds < 3) & (UnitSpeeds >= 2)])\n",
    "            DevX3 = np.average(StdDevsX[i][(UnitSpeeds < 4) & (UnitSpeeds >= 3)])\n",
    "            DevX4 = np.average(StdDevsX[i][(UnitSpeeds < 5) & (UnitSpeeds >= 4)])\n",
    "            DevX5p = np.average(StdDevsX[i][UnitSpeeds >= 3])\n",
    "            DevY0 = np.average(StdDevsY[i][UnitSpeeds < 1])\n",
    "            DevY1 = np.average(StdDevsY[i][(UnitSpeeds < 2) & (UnitSpeeds >= 1)])\n",
    "            DevY2 = np.average(StdDevsY[i][(UnitSpeeds < 3) & (UnitSpeeds >= 2)])\n",
    "            DevY3 = np.average(StdDevsY[i][(UnitSpeeds < 4) & (UnitSpeeds >= 3)])\n",
    "            DevY4 = np.average(StdDevsY[i][(UnitSpeeds < 5) & (UnitSpeeds >= 4)])\n",
    "            DevY5p = np.average(StdDevsY[i][UnitSpeeds >= 3])\n",
    "            DevZ0 = np.average(StdDevsZ[i][UnitSpeeds < 1])\n",
    "            DevZ1 = np.average(StdDevsZ[i][(UnitSpeeds < 2) & (UnitSpeeds >= 1)])\n",
    "            DevZ2 = np.average(StdDevsZ[i][(UnitSpeeds < 3) & (UnitSpeeds >= 2)])\n",
    "            DevZ3 = np.average(StdDevsZ[i][(UnitSpeeds < 4) & (UnitSpeeds >= 3)])\n",
    "            DevZ4 = np.average(StdDevsZ[i][(UnitSpeeds < 5) & (UnitSpeeds >= 4)])\n",
    "            DevZ5p = np.average(StdDevsZ[i][UnitSpeeds >= 3])\n",
    "\n",
    "            if NewFiles[i][17:18] == 'a':\n",
    "                am = 1\n",
    "            else:\n",
    "                am = 0\n",
    "\n",
    "            Results.append([int(NewFiles[i][:2]), int(NewFiles[i][2:4]), int(NewFiles[i][4:6]), int(NewFiles[i][16:17]), am, np.average(MovingDevX), np.average(StopedDevX), \n",
    "                            np.average(MovingDevY), np.average(StopedDevY), np.average(MovingDevY), \n",
    "                            np.average(StopedDevY), DevX0, DevX1, DevX2, DevX3, DevX4, DevX5p,\n",
    "                            DevY0, DevY1, DevY2, DevY3, DevY4, DevY5p,\n",
    "                            DevZ0, DevZ1, DevZ2, DevZ3, DevZ4, DevZ5p])\n",
    "\n",
    "    for i in range(len(Results)):\n",
    "        line = ''\n",
    "        for j in range(len(Results[i])):\n",
    "            line += str(Results[i][j])+', ' \n",
    "        line += '\\n'\n",
    "        WriteFile.write(line)\n",
    "    print(k, len(Results), (ti()-st)/60.0)\n",
    "\n",
    "    WriteFile.close()\n",
    "    WriteFile = open(rootfolder + 'StdDevBySpeedSummaryStatistics6.csv','a')\n",
    "    \n",
    "\n",
    "WriteFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6.67,3.75),dpi=800,linewidth=0.5) \n",
    "\n",
    "PlotLength = min(len(Velocities[f]), len(StdDevsY[f]))\n",
    "v = Velocities[f][:PlotLength]\n",
    "sd = StdDevsY[f][:PlotLength]\n",
    "\n",
    "ax1.set_xlabel('Time') \n",
    "ax1.set_ylabel('Velocity', color = 'red') \n",
    "ax1.plot(range(PlotLength), v, color = 'red', linestyle = 'dashed', label='Velocity' )\n",
    "ax1.tick_params(axis ='y', labelcolor = 'red') \n",
    "#plt.ylim(-6,6)\n",
    "legend_1 = ax1.legend(loc=2)\n",
    "legend_1.remove()\n",
    "\n",
    "# Adding Twin Axes\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "\n",
    "ax2.set_ylabel('Acceleration', color = 'blue') \n",
    "ax2.plot(range(PlotLength), sd, color = 'blue', label='Std Dev of Acceleration') \n",
    "ax2.tick_params(axis ='y', labelcolor = 'blue') \n",
    "#plt.ylim(0.0,0.6)\n",
    "ax2.legend(loc=1)\n",
    "ax2.add_artist(legend_1)\n",
    "# Show plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 3800000\n",
    "length = 200000\n",
    "end = start+length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6.67,3.75),dpi=800,linewidth=0.5) \n",
    "\n",
    "ax1.set_xlabel('Time') \n",
    "ax1.set_ylabel('m/s', color = 'red') \n",
    "#ax1.plot(range(length), Velocity[start:end], color = 'red', linestyle = 'dashed', label='Velocity' )\n",
    "ax1.plot(range(length), Velocities[f][start:end], color = 'red', linestyle = 'dashed', label='Velocity' )\n",
    "ax1.tick_params(axis ='y', labelcolor = 'red') \n",
    "#plt.ylim(-6,6)\n",
    "legend_1 = ax1.legend(loc=2)\n",
    "legend_1.remove()\n",
    "\n",
    "# Adding Twin Axes\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "\n",
    "ax2.set_ylabel('Acceleration', color = 'blue') \n",
    "ax2.plot(range(length), StdDevsY[f][start:end], color = 'blue', label='g of Acceleration') \n",
    "ax2.tick_params(axis ='y', labelcolor = 'blue') \n",
    "#plt.ylim(0.0,0.6)\n",
    "ax2.legend(loc=1)\n",
    "ax2.add_artist(legend_1)\n",
    "# Show plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(MaxDevZ)):\n",
    "    print(NewFiles[i],MaxDevX[i], MaxRollX[i],MaxDevY[i], MaxRollY[i],MaxDevZ[i], MaxRollZ[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = []\n",
    "for i in range(len(MaxDevZ)):\n",
    "    if MaxDevX[i] != 0:\n",
    "        UnitSpeeds = np.abs(Velocities[i]).astype('int')\n",
    "        MovingDevX = StdDevsX[i][np.abs(Velocities[i]) > 1]\n",
    "        StopedDevX = StdDevsX[i][np.abs(Velocities[i]) < 1]\n",
    "        MovingDevY = StdDevsY[i][np.abs(Velocities[i]) > 1]\n",
    "        StopedDevY = StdDevsY[i][np.abs(Velocities[i]) < 1]\n",
    "        MovingDevZ = StdDevsZ[i][np.abs(Velocities[i]) > 1]\n",
    "        StopedDevZ = StdDevsZ[i][np.abs(Velocities[i]) < 1]\n",
    "        DevX0 = np.average(StdDevsX[i][UnitSpeeds < 1])\n",
    "        DevX1 = np.average(StdDevsX[i][(UnitSpeeds < 2) & (UnitSpeeds >= 1)])\n",
    "        DevX2 = np.average(StdDevsX[i][(UnitSpeeds < 3) & (UnitSpeeds >= 2)])\n",
    "        DevX3 = np.average(StdDevsX[i][(UnitSpeeds < 4) & (UnitSpeeds >= 3)])\n",
    "        DevX4 = np.average(StdDevsX[i][(UnitSpeeds < 5) & (UnitSpeeds >= 4)])\n",
    "        DevX5p = np.average(StdDevsX[i][UnitSpeeds >= 1])\n",
    "        DevY0 = np.average(StdDevsY[i][UnitSpeeds < 1])\n",
    "        DevY1 = np.average(StdDevsY[i][(UnitSpeeds < 2) & (UnitSpeeds >= 1)])\n",
    "        DevY2 = np.average(StdDevsY[i][(UnitSpeeds < 3) & (UnitSpeeds >= 2)])\n",
    "        DevY3 = np.average(StdDevsY[i][(UnitSpeeds < 4) & (UnitSpeeds >= 3)])\n",
    "        DevY4 = np.average(StdDevsY[i][(UnitSpeeds < 5) & (UnitSpeeds >= 4)])\n",
    "        DevY5p = np.average(StdDevsY[i][UnitSpeeds >= 5])\n",
    "        DevZ0 = np.average(StdDevsZ[i][UnitSpeeds < 1])\n",
    "        DevZ1 = np.average(StdDevsZ[i][(UnitSpeeds < 2) & (UnitSpeeds >= 1)])\n",
    "        DevZ2 = np.average(StdDevsZ[i][(UnitSpeeds < 3) & (UnitSpeeds >= 2)])\n",
    "        DevZ3 = np.average(StdDevsZ[i][(UnitSpeeds < 4) & (UnitSpeeds >= 3)])\n",
    "        DevZ4 = np.average(StdDevsZ[i][(UnitSpeeds < 5) & (UnitSpeeds >= 4)])\n",
    "        DevZ5p = np.average(StdDevsZ[i][UnitSpeeds >= 5])\n",
    "        \n",
    "        if NewFiles[i][16:17] == 'a':\n",
    "            am = 1\n",
    "        else:\n",
    "            am = 0\n",
    "        \n",
    "        Results.append([int(NewFiles[i][:2]), int(NewFiles[i][2:4]), int(NewFiles[i][4:6]), int(NewFiles[i][16:17]), am, np.average(MovingDevX), np.average(StopedDevX), \n",
    "                        np.average(MovingDevY), np.average(StopedDevY), np.average(MovingDevY), \n",
    "                        np.average(StopedDevY), DevX0, DevX1, DevX2, DevX3, DevX4, DevX5p,\n",
    "                        DevY0, DevY1, DevY2, DevY3, DevY4, DevY5p,\n",
    "                        DevZ0, DevZ1, DevZ2, DevZ3, DevZ4, DevZ5p])\n",
    "        \n",
    "        print(NewFiles[i], np.average(MovingDevX)/np.average(StopedDevX), \n",
    "          np.average(MovingDevY)/np.average(StopedDevY), np.average(MovingDevY)/np.average(StopedDevY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
