{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5a7460-efdf-4253-b1cb-c7d3a3bddcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e47574-3887-40ad-9d01-808c82f846fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432d9729-c278-4b8e-88f6-280221677a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_wavelet\n",
    "from time import time as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687a599a-6ca3-43eb-b1d9-216f635c3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 1200\n",
    "Skips = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9d5c70-565c-422b-9188-84c4c5b46056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RollingStdDevFaster(RawData, SmoothData, RollSize = 25):\n",
    "\n",
    "    Diffs = RawData - SmoothData\n",
    "    del RawData, SmoothData\n",
    "    \n",
    "    Sqs = Diffs * Diffs\n",
    "    del Diffs\n",
    "    \n",
    "    Sqs = Sqs.tolist() \n",
    "    Sqs.extend(np.zeros(RollSize))\n",
    "    mSqs = np.matrix(Sqs)\n",
    "    \n",
    "    for i in range(RollSize):\n",
    "        Sqs.insert(0, Sqs.pop())\n",
    "        mSqs = np.concatenate((np.matrix(Sqs),mSqs))\n",
    "    \n",
    "    sVect = mSqs.sum(axis=0)\n",
    "    eVect = (mSqs!=0).sum(axis=0)\n",
    "    del mSqs, Sqs\n",
    "    \n",
    "    VarVect = sVect / eVect\n",
    "    StdDevs = np.sqrt(VarVect)\n",
    "    return np.asarray(StdDevs[:-RollSize].T)\n",
    "\n",
    "def SquelchPattern(DataSet, StallRange = 5000, SquelchLevel = 0.02, verbose = False):\n",
    "    \n",
    "    SquelchSignal = np.ones(len(DataSet))\n",
    "    if verbose:\n",
    "        print(len(SquelchSignal))\n",
    "        \n",
    "    for i in range(len(DataSet)-2*StallRange):\n",
    "        if np.average(DataSet[i:i+StallRange]) < SquelchLevel:\n",
    "            SquelchSignal[i+StallRange]=0\n",
    "\n",
    "    return SquelchSignal\n",
    "\n",
    "def split_list_by_zeros(original_list, ones_list):\n",
    "    # modified split_list_by_ones function to instead split by the zeros.\n",
    "    #\n",
    "    #\n",
    "    # Created with Bing AI support\n",
    "    #  1st request: \"python split list into chunks based on value\"\n",
    "    #  2nd request: \"I want to split the list based on the values in a second list.  Second list is all 1s and 0s.  I want all 0s removed, and each set of consequtive ones as its own item\"\n",
    "    #  3rd request: \"That is close.  Here is an example of the two lists, and what I would want returned: original_list = [1, 2, 3, 8, 7, 4, 5, 6, 4, 7, 8, 9]\n",
    "    #                ones_list =     [1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
    "    #                return: [[1, 2, 3, 8], [4, 5, 6], [8,9]]\"\n",
    "    #\n",
    "    #This is the function that was created and seems to work on the short lists, going to use for long lists\n",
    "    \n",
    "    result_sublists = []\n",
    "    sublist = []\n",
    "\n",
    "    for val, is_one in zip(original_list, ones_list):\n",
    "        if not is_one:\n",
    "            sublist.append(val)\n",
    "        elif sublist:\n",
    "            result_sublists.append(sublist)\n",
    "            sublist = []\n",
    "\n",
    "    # Add the last sublist (if any)\n",
    "    if sublist:\n",
    "        result_sublists.append(sublist)\n",
    "\n",
    "    return result_sublists\n",
    "\n",
    "def split_list_by_ones(original_list, ones_list):\n",
    "    # modified split_list_by_ones function to instead split by the zeros.\n",
    "    #\n",
    "    #\n",
    "    # Created with Bing AI support\n",
    "    #  1st request: \"python split list into chunks based on value\"\n",
    "    #  2nd request: \"I want to split the list based on the values in a second list.  Second list is all 1s and 0s.  I want all 0s removed, and each set of consequtive ones as its own item\"\n",
    "    #  3rd request: \"That is close.  Here is an example of the two lists, and what I would want returned: original_list = [1, 2, 3, 8, 7, 4, 5, 6, 4, 7, 8, 9]\n",
    "    #                ones_list =     [1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
    "    #                return: [[1, 2, 3, 8], [4, 5, 6], [8,9]]\"\n",
    "    #\n",
    "    #This is the function that was created and seems to work on the short lists, going to use for long lists\n",
    "    \n",
    "    result_sublists = []\n",
    "    sublist = []\n",
    "\n",
    "    for val, is_one in zip(original_list, ones_list):\n",
    "        if is_one:\n",
    "            sublist.append(val)\n",
    "        elif sublist:\n",
    "            result_sublists.append(sublist)\n",
    "            sublist = []\n",
    "\n",
    "    # Add the last sublist (if any)\n",
    "    if sublist:\n",
    "        result_sublists.append(sublist)\n",
    "\n",
    "    return result_sublists\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS, skips = Skips):\n",
    "    output = []\n",
    "    if len(values) > time_steps:\n",
    "        for i in range(int((len(values) - time_steps + skips)/skips)):\n",
    "            output.append(values[i*skips : (i*skips + time_steps)])\n",
    "        return np.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017225be-2cd9-42c3-b93e-ca6fa63274a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVelocity(Acceleration, Timestamps = 0.003, Squelch = [], corrected = 0):\n",
    "    velocity = np.zeros(len(Acceleration))\n",
    "    \n",
    "    Acceleration -= np.average(Acceleration)\n",
    "    \n",
    "    if len(Timestamps) == 1:\n",
    "        dTime = np.ones(len(Acceleration),dtype=float) * Timestamps\n",
    "    elif len(Timestamps) == len(Acceleration):\n",
    "        dTime = np.zeros(len(Timestamps), dtype=float)\n",
    "        dTime[0]=1\n",
    "        for i in range(len(Timestamps)-1):\n",
    "            j = i+1\n",
    "            if Timestamps[j] > Timestamps[i]:\n",
    "                dTime[j]=Timestamps[j]-Timestamps[i]\n",
    "            else:\n",
    "                dTime[j]=Timestamps[j]-Timestamps[i]+10000.0\n",
    "        dTime /= 10000.0\n",
    "\n",
    "    velocity[0] = Acceleration[0] * (dTime[0])\n",
    "\n",
    "    for i in range(len(Acceleration)-1):\n",
    "        j = i + 1\n",
    "        if corrected ==2:\n",
    "            if Squelch[j]==0:\n",
    "                velocity[j]=0\n",
    "            else:\n",
    "                velocity[j] = velocity[i] + Acceleration[j] * dTime[j]                \n",
    "        else:\n",
    "            velocity[j] = velocity[i] + Acceleration[j] * dTime[j]\n",
    "\n",
    "    if corrected == 1:\n",
    "        PointVairance = velocity[-1:] / len(velocity)\n",
    "        for i in range(len(velocity)):\n",
    "            velocity[i] -=  PointVairance * i\n",
    "    \n",
    "    velocity *= 9.81\n",
    "\n",
    "    return velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204baf55-a732-409c-85d2-2c2cf4d9d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=ti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aecb72c5-9654-4c39-910e-1e0cd5b94c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFolder = '/scratch/Recordings2/'\n",
    "files=['230704 recording4.csv',\n",
    "       '230421 recording1.csv',\n",
    "       '230420 recording2.csv',\n",
    "       ]\n",
    "file = files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeede09d-62b2-4cce-9ac7-6d7fc91a4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DataFolder+file, delimiter =\",\", header=None, engine='python',on_bad_lines='skip')\n",
    "\n",
    "\n",
    "dataset = dataset.rename(columns={0:\"Day\"})\n",
    "dataset = dataset.rename(columns={1:\"Second\"})\n",
    "dataset = dataset.rename(columns={2:\"FracSec\"})\n",
    "dataset = dataset.rename(columns={3:\"p\"})\n",
    "dataset = dataset.rename(columns={4:\"h\"})\n",
    "dataset = dataset.rename(columns={5:\"v\"})\n",
    "dataset = dataset.rename(columns={6:\"Sensor\"})\n",
    "\n",
    "#dataset['Second'].replace('',0)\n",
    "#dataset['FracSec'].replace('',0)\n",
    "#dataset.replace([np.nan, np.inf, -np.inf],0,inplace=True)\n",
    "\n",
    "#dataset[['Day','Second']] = dataset[['Day','Second']].apply(lambda x: x.astype(int).astype(str).str.zfill(6))\n",
    "#dataset[['FracSec']] = dataset[['FracSec']].apply(lambda x: x.astype(int).astype(str).str.zfill(4))\n",
    "\n",
    "#dataset[\"timestamp\"] = pd.to_datetime(dataset.Day+dataset.Second+dataset.FracSec,format='%y%m%d%H%M%S%f')\n",
    "#dataset[\"timestamps\"] = dataset[\"timestamp\"]\n",
    "\n",
    "dataset[\"p\"] = dataset.p - np.average(dataset.p)\n",
    "dataset[\"h\"] = dataset.h - np.average(dataset.h)\n",
    "dataset[\"v\"] = dataset.v - np.average(dataset.v)\n",
    "#dataset[\"r\"] = np.sqrt(dataset.p**2 + dataset.h**2 + dataset.v**2)\n",
    "\n",
    "#dataset.index = dataset.timestamp\n",
    "\n",
    "dataset[\"SmoothP\"] = denoise_wavelet(dataset.p, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "dataset[\"SmoothH\"] = denoise_wavelet(dataset.h, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "dataset[\"SmoothV\"] = denoise_wavelet(dataset.v, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "#dataset[\"SmoothR\"] = denoise_wavelet(dataset.r, method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "\n",
    "\n",
    "RawData = dataset.v\n",
    "SmoothData = dataset.SmoothV\n",
    "RollSize = 25\n",
    "\n",
    "Diffs = RawData - SmoothData\n",
    "\n",
    "Sqs = Diffs * Diffs\n",
    "\n",
    "Sqs = Sqs.tolist() \n",
    "\n",
    "Sqs.extend(np.zeros(RollSize))\n",
    "\n",
    "mSqs = np.matrix(Sqs)\n",
    "\n",
    "for i in range(RollSize):\n",
    "    Sqs.insert(0, Sqs.pop())\n",
    "    mSqs = np.concatenate((np.matrix(Sqs),mSqs))\n",
    "\n",
    "sVect = mSqs.sum(axis=0)\n",
    "eVect = (mSqs!=0).sum(axis=0)\n",
    "\n",
    "VarVect = sVect / eVect\n",
    "\n",
    "StdDevs = np.sqrt(VarVect)\n",
    "\n",
    "StdDevsZ = np.asarray(StdDevs)\n",
    "\n",
    "StdDevsZ=np.append(StdDevsZ,[0])\n",
    "\n",
    "StdDevsZ = np.asarray(StdDevsZ.T[:len(dataset.p)])\n",
    "\n",
    "print(\"Size StdDevsZ\", ti()-start, np.shape(StdDevsZ))\n",
    "\n",
    "StdDevsZ = np.nan_to_num(StdDevsZ)\n",
    "\n",
    "StdDevsZ[StdDevsZ == np.inf] = 0\n",
    "StdDevsZ[StdDevsZ == -np.inf] = 0\n",
    "\n",
    "SmoothDevZ = denoise_wavelet(StdDevsZ, method='VisuShrink', mode='soft', wavelet='sym2', rescale_sigma='True')\n",
    "\n",
    "print(\"denoise 1\", ti()-start, np.shape(StdDevsZ))\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.plot(SmoothDevZ)\n",
    "plt.show()\n",
    "\n",
    "SmoothDevZ[np.isnan(SmoothDevZ)]=0\n",
    "\n",
    "Max = np.max(SmoothDevZ)\n",
    "\n",
    "buckets = int(Max / 0.005) + 1\n",
    "bins = np.linspace(0,buckets*0.005,buckets+1)\n",
    "counts, bins = np.histogram(SmoothDevZ,bins=bins)\n",
    "\n",
    "CummCount = 0\n",
    "HalfWay = 0\n",
    "for i in range(len(counts)):\n",
    "    CummCount += counts[i]\n",
    "    if CummCount / len(SmoothDevZ) >= 0.5:\n",
    "        if HalfWay == 0:\n",
    "            HalfWay = i\n",
    "\n",
    "SquelchLevel = bins[HalfWay] \n",
    "\n",
    "\n",
    "dataset[\"IsMoving\"] = SquelchPattern(SmoothDevZ, 2000, 0.02, False)\n",
    "\n",
    "\n",
    "#velocity = getVelocity(dataset.p, dataset.FracSec, dataset.IsMoving, 2)\n",
    "\n",
    "df_pr = split_list_by_ones(dataset.p, dataset.IsMoving)\n",
    "df_hr = split_list_by_ones(dataset.h, dataset.IsMoving)\n",
    "df_vr = split_list_by_ones(dataset.v, dataset.IsMoving)\n",
    "\n",
    "df_ps = split_list_by_zeros(dataset.SmoothP, dataset.IsMoving)\n",
    "df_hs = split_list_by_zeros(dataset.SmoothH, dataset.IsMoving)\n",
    "df_vs = split_list_by_zeros(dataset.SmoothV, dataset.IsMoving)\n",
    "\n",
    "SmoothMove = []\n",
    "for i in range(len(df_pr)):\n",
    "    if len(df_pr[i])>TIME_STEPS:\n",
    "        tempP=create_sequences(df_pr[i])\n",
    "        tempH=create_sequences(df_hr[i])\n",
    "        tempV=create_sequences(df_vr[i])\n",
    "        for j in range(len(tempP)):\n",
    "            SmoothMove.append(np.vstack((tempP[j],tempH[j],tempV[j]))) #,df_rs[i])))\n",
    "\n",
    "SmoothStop = []\n",
    "for i in range(len(df_ps)):\n",
    "    if len(df_ps[i])>TIME_STEPS:\n",
    "        tempP=create_sequences(df_ps[i])\n",
    "        tempH=create_sequences(df_hs[i])\n",
    "        tempV=create_sequences(df_vs[i])\n",
    "        for j in range(len(tempP)):\n",
    "            SmoothStop.append(np.vstack((tempP[j],tempH[j],tempV[j]))) #,df_rs[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a7980e8-56c3-450d-a611-51dd93c77b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12368"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SmoothMove) #17600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab1448f5-0a1e-4700-a05f-140944291e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111242"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SmoothStop) #161000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
