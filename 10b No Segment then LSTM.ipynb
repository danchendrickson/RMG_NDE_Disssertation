{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at accelerometer data \n",
    "\n",
    "Finding Zero velocity times by rail axis acceleration noise levels, making summary statistics for the noise levels across the whole day files.  Spot check graphs to see what works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '-', '-', '-']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "\n",
    "from time import time as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CoreFunctions as cf\n",
    "from skimage.restoration import denoise_wavelet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Platform\n",
    "Working is beinging conducted on several computers, and author needs to be able to run code on all without rewriting..  This segment of determines which computer is being used, and sets the directories accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HostName = platform.node()\n",
    "\n",
    "if HostName == \"Server\":\n",
    "    Computer = \"Desktop\"   \n",
    "elif HostName[-6:] == 'wm.edu':\n",
    "    Computer = \"SciClone\"\n",
    "elif HostName == \"SchoolLaptop\":\n",
    "    Computer = \"LinLap\"\n",
    "elif HostName == \"WTC-TAB-512\":\n",
    "    Computer = \"PortLap\"\n",
    "else:\n",
    "    Computer = \"WinLap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/sciclone/scr10/dchendrickson01/Recordings2/'\n",
    "    imageFolder = '/sciclone/scr10/dchendrickson01/Move3Dprint/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'Recordings2/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'Recordings2\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saving = False\n",
    "location = folder\n",
    "Titles = True\n",
    "Ledgends = True\n",
    "\n",
    "f = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['230418 recording1.csv','230419 recording1.csv','230420 recording1.csv','230421 recording1.csv',\n",
    "         '230418 recording2.csv','230419 recording2.csv','230420 recording2.csv','230421 recording2.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BeforeTamping = ['221206 recording1.csv','221207 recording1.csv','221208 recording1.csv','221209 recording1.csv',\n",
    "         '221206 recording2.csv','221207 recording2.csv','221208 recording2.csv','221209 recording2.csv']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth = cf.Smoothing(ODataSet[:,3],2) #,50)\n",
    "def SmoothMoves(file):\n",
    "    #    if file[-3:] =='csv':\n",
    "    ODataSet = np.genfromtxt(open(folder+file,'r'), delimiter=',',skip_header=0,missing_values=0,invalid_raise=False)\n",
    "    SmoothX = denoise_wavelet(ODataSet[:,3], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothY = denoise_wavelet(ODataSet[:,4], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothZ = denoise_wavelet(ODataSet[:,5], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothX -= np.average(SmoothX)\n",
    "    SmoothY -= np.average(SmoothY)\n",
    "    SmoothZ -= np.average(SmoothZ)\n",
    "    MoveMatrix = np.matrix([SmoothX, SmoothY, SmoothZ])\n",
    "    return MoveMatrix\n",
    "    #else:\n",
    "    #    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoopFiles = 3\n",
    "loops = int(len(files) / LoopFiles) \n",
    "if len(files)%LoopFiles != 0:\n",
    "    loops += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['230418 recording1.csv',\n",
       " '230419 recording1.csv',\n",
       " '230420 recording1.csv',\n",
       " '230421 recording1.csv',\n",
       " '230418 recording2.csv',\n",
       " '230419 recording2.csv',\n",
       " '230420 recording2.csv',\n",
       " '230421 recording2.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.6526994466781617\n",
      "1 3.236815166473389\n",
      "2 4.3306843638420105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "st = ti()\n",
    "\n",
    "Moves = []\n",
    "\n",
    "for k in range(loops):\n",
    "    if k == loops -1:\n",
    "        tfiles = files[k*LoopFiles:]\n",
    "    else:\n",
    "        tfiles = files[k*LoopFiles:(k+1)*LoopFiles]\n",
    "    #Results = Parallel(n_jobs=LoopFiles)(delayed(DeviationVelocity)(file) for file in tfiles)\n",
    "    Results = Parallel(n_jobs=LoopFiles)(delayed(SmoothMoves)(file) for file in tfiles)\n",
    "    #Results =[]\n",
    "    #for file in tfiles:\n",
    "    #    Results.append(DeviationVelocity(file))\n",
    "    #    print(file, (ti()-st)/60.0)\n",
    "    for result in Results:\n",
    "        Moves.append(result)\n",
    "    print(k, (ti()-st)/60.0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LSTM Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeSteps = 250\n",
    "StepSize = 75\n",
    "Features = np.shape(Moves[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps, s_step = 1):\n",
    "    X, y = list(), list()\n",
    "    Steps_to_take = int(len(sequences) / s_step)\n",
    "    for j in range(Steps_to_take):\n",
    "        i = j * s_step\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequences = []\n",
    "Outputs = []\n",
    "for move in Moves:\n",
    "    Seq, Out = split_sequences(move.T,TimeSteps,StepSize)\n",
    "    Sequences.append(Seq)\n",
    "    Outputs.append(Out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoveSegments = []\n",
    "for seq in Sequences:\n",
    "    for mv in seq:\n",
    "        MoveSegments.append(mv)\n",
    "NextDataPoint = []\n",
    "for out in Outputs:\n",
    "    for pt in out:\n",
    "        NextDataPoint.append(np.reshape(pt,(1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713931"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MoveSegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 09:53:00.219319: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Masking\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class LSTM_Autoencoder:\n",
    "  def __init__(self, optimizer='adam', loss='mse'):\n",
    "    self.optimizer = optimizer\n",
    "    self.loss = loss\n",
    "    self.n_features = Features\n",
    "    self.timesteps = TimeSteps\n",
    "    \n",
    "  def build_model(self):\n",
    "    timesteps = self.timesteps\n",
    "    n_features = self.n_features\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Padding\n",
    "    #model.add(Masking(mask_value=0.0, input_shape=(timesteps, n_features)))\n",
    "\n",
    "    # Encoder\n",
    "    model.add(LSTM(timesteps, activation='relu', input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    model.add(LSTM(35, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(6, activation='relu'))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(LSTM(timesteps, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(35, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    \n",
    "    model.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    self.model = model\n",
    "    \n",
    "  def simple_model(self):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(150, input_shape=(self.timesteps, self.n_features)))\n",
    "    model.add(RepeatVector(n_timesteps_in))\n",
    "    model.add(LSTM(150, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    self.model = model\n",
    "    \n",
    "  def fit(self, X, epochs=3, batch_size=32):\n",
    "    #self.timesteps = np.shape(X)[0]\n",
    "    self.build_model()\n",
    "    \n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    self.model.fit(X, X, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "  def predict(self, X):\n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    output_X = self.model.predict(X)\n",
    "    reconstruction = np.squeeze(output_X)\n",
    "    return np.linalg.norm(X - reconstruction, axis=-1)\n",
    "  \n",
    "  def plot(self, scores, timeseries, threshold=0.95):\n",
    "    sorted_scores = sorted(scores)\n",
    "    threshold_score = sorted_scores[round(len(scores) * threshold)]\n",
    "    \n",
    "    plt.title(\"Reconstruction Error\")\n",
    "    plt.plot(scores)\n",
    "    plt.plot([threshold_score]*len(scores), c='r')\n",
    "    plt.show()\n",
    "    \n",
    "    anomalous = np.where(scores > threshold_score)\n",
    "    normal = np.where(scores <= threshold_score)\n",
    "    \n",
    "    plt.title(\"Anomalies\")\n",
    "    plt.scatter(normal, timeseries[normal][:,-1], s=3)\n",
    "    plt.scatter(anomalous, timeseries[anomalous][:,-1], s=5, c='r')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split = int(len(Moves)*.9)\n",
    "#Train_data = Moves[:split]\n",
    "#Test_data = Moves[split:]\n",
    "#Train_data = tf.ragged.constant(Train_data)\n",
    "#Test_data = tf.ragged.constant(Test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_autoencoder2 = LSTM_Autoencoder(optimizer='adam', loss='msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 09:53:03.873613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 09:53:03.883750: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 250, 250)          254000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 250, 35)           40040     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 6)                 1008      \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 250, 6)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 250, 250)          257000    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 250, 35)           40040     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 250, 3)           108       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 592,196\n",
      "Trainable params: 592,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_autoencoder2.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batches = 32\n",
    "NumbBatches = 1000\n",
    "\n",
    "SamplesPerSet = Batches * NumbBatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SamplesPerSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713931 536\n"
     ]
    }
   ],
   "source": [
    "SetsNeeded = int(len(MoveSegments) / SamplesPerSet)\n",
    "if  int(len(MoveSegments) / SamplesPerSet) != 0:\n",
    "    SetsNeeded += 1\n",
    "print(len(MoveSegments), SetsNeeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PercentPerSet = 1.0 / float(SetsNeeded)\n",
    "\n",
    "PercentHoldOutForNext=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 178s 2s/step - loss: 4.2503e-05 - accuracy: 0.3446\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 150s 2s/step - loss: 4.2431e-05 - accuracy: 0.3450\n",
      "1 of 536 5.498353819052379 48.935349625812634\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 4.7819e-05 - accuracy: 0.3391\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 4.7777e-05 - accuracy: 0.3385\n",
      "2 of 536 10.159175670146942 45.12367219924927\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 150s 2s/step - loss: 4.7601e-05 - accuracy: 0.3461\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 148s 1s/step - loss: 4.7511e-05 - accuracy: 0.3429\n",
      "3 of 536 15.158909130096436 44.80299834171931\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 130s 1s/step - loss: 4.6357e-05 - accuracy: 0.3428\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 163s 2s/step - loss: 4.5301e-05 - accuracy: 0.3459\n",
      "4 of 536 20.06973661184311 44.40429236766365\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 156s 2s/step - loss: 4.9866e-05 - accuracy: 0.3824\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 131s 1s/step - loss: 5.5487e-05 - accuracy: 0.3538\n",
      "5 of 536 24.89330456654231 43.9781715549363\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 133s 1s/step - loss: 4.9733e-05 - accuracy: 0.3562\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 170s 2s/step - loss: 4.9733e-05 - accuracy: 0.3562\n",
      "6 of 536 29.964521368344624 44.031199530661105\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 164s 2s/step - loss: 5.4135e-05 - accuracy: 0.3510\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 156s 2s/step - loss: 5.4135e-05 - accuracy: 0.3510\n",
      "7 of 536 35.3205156604449 44.402934137649005\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 157s 2s/step - loss: 5.1355e-05 - accuracy: 0.3554\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 140s 1s/step - loss: 5.1355e-05 - accuracy: 0.3554\n",
      "8 of 536 40.292604561646776 44.23792214366297\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 145s 1s/step - loss: 4.7734e-05 - accuracy: 0.3522\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 4.7734e-05 - accuracy: 0.3522\n",
      "9 of 536 44.97110673189163 43.8051892076819\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 5.1572e-05 - accuracy: 0.3553\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 5.1572e-05 - accuracy: 0.3553\n",
      "10 of 536 49.54755027294159 43.35410654740201\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 151s 2s/step - loss: 5.3987e-05 - accuracy: 0.3558\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 5.3987e-05 - accuracy: 0.3558\n",
      "11 of 536 54.34671210845311 43.14799578188646\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 123s 1s/step - loss: 5.0472e-05 - accuracy: 0.3527\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 133s 1s/step - loss: 5.0472e-05 - accuracy: 0.3527\n",
      "12 of 536 58.63794716993968 42.593953340103226\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 163s 2s/step - loss: 5.3205e-05 - accuracy: 0.3530\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 129s 1s/step - loss: 5.3205e-05 - accuracy: 0.3530\n",
      "13 of 536 63.52097296714783 42.51018965088914\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 5.2682e-05 - accuracy: 0.3525\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 157s 2s/step - loss: 5.2682e-05 - accuracy: 0.3525\n",
      "14 of 536 68.55567336877188 42.52084031677436\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 162s 2s/step - loss: 5.1816e-05 - accuracy: 0.3494\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 124s 1s/step - loss: 5.1816e-05 - accuracy: 0.3494\n",
      "15 of 536 73.3515512307485 42.380896298399676\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 5.2569e-05 - accuracy: 0.3515\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 5.2569e-05 - accuracy: 0.3515\n",
      "16 of 536 78.02400593757629 42.18172824820711\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 167s 2s/step - loss: 4.7911e-05 - accuracy: 0.3544\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 163s 2s/step - loss: 4.7911e-05 - accuracy: 0.3544\n",
      "17 of 536 83.54453161557515 42.427517075974954\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 4.8991e-05 - accuracy: 0.3524\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 162s 2s/step - loss: 4.8991e-05 - accuracy: 0.3524\n",
      "18 of 536 88.66982397635778 42.44657317250599\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 159s 2s/step - loss: 5.0802e-05 - accuracy: 0.3550\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 200s 2s/step - loss: 5.0802e-05 - accuracy: 0.3550\n",
      "19 of 536 94.6810830394427 42.855648151695384\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 153s 2s/step - loss: 5.0226e-05 - accuracy: 0.3466\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 183s 2s/step - loss: 5.0226e-05 - accuracy: 0.3466\n",
      "20 of 536 100.30364413261414 43.04698064232866\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 158s 2s/step - loss: 5.1537e-05 - accuracy: 0.3577\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.1537e-05 - accuracy: 0.3577\n",
      "21 of 536 105.28697541952133 42.95040111099601\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.0682e-05 - accuracy: 0.3574\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 5.0682e-05 - accuracy: 0.3574\n",
      "22 of 536 110.02747389475505 42.76067738947543\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 222s 2s/step - loss: 5.3313e-05 - accuracy: 0.3533\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 204s 2s/step - loss: 5.3313e-05 - accuracy: 0.3533\n",
      "23 of 536 117.15578249692916 43.46649325431834\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 191s 2s/step - loss: 5.1762e-05 - accuracy: 0.3538\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 179s 2s/step - loss: 5.1762e-05 - accuracy: 0.3538\n",
      "24 of 536 123.34765127499898 43.77128460219337\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 145s 1s/step - loss: 5.0746e-05 - accuracy: 0.3553\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 163s 2s/step - loss: 5.0746e-05 - accuracy: 0.3553\n",
      "25 of 536 128.51125040054322 43.69382518294123\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 167s 2s/step - loss: 4.7107e-05 - accuracy: 0.3558\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 4.7107e-05 - accuracy: 0.3558\n",
      "26 of 536 133.6887652317683 43.620244572368954\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 135s 1s/step - loss: 4.9576e-05 - accuracy: 0.3514\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 145s 1s/step - loss: 4.9576e-05 - accuracy: 0.3514\n",
      "27 of 536 138.37186299562455 43.39068298845134\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 135s 1s/step - loss: 4.6591e-05 - accuracy: 0.3534\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 4.6591e-05 - accuracy: 0.3534\n",
      "28 of 536 143.03440844217937 43.16574114740841\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 200s 2s/step - loss: 5.1484e-05 - accuracy: 0.3527\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 263s 3s/step - loss: 5.1484e-05 - accuracy: 0.3527\n",
      "29 of 536 150.76770068804424 43.84394056422729\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 160s 2s/step - loss: 5.1839e-05 - accuracy: 0.3544\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 147s 1s/step - loss: 5.1839e-05 - accuracy: 0.3544\n",
      "30 of 536 155.90735670725505 43.74067509370821\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 5.1001e-05 - accuracy: 0.3540\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 157s 2s/step - loss: 5.1001e-05 - accuracy: 0.3540\n",
      "31 of 536 160.81454303661982 43.57555361499282\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 135s 1s/step - loss: 5.1521e-05 - accuracy: 0.3494\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 5.1521e-05 - accuracy: 0.3494\n",
      "32 of 536 165.4779508392016 43.35177568077006\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 186s 2s/step - loss: 5.1160e-05 - accuracy: 0.3554\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 141s 1s/step - loss: 5.1160e-05 - accuracy: 0.3554\n",
      "33 of 536 170.94991360902787 43.341846800564916\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 158s 2s/step - loss: 4.9452e-05 - accuracy: 0.3560\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 152s 2s/step - loss: 4.9452e-05 - accuracy: 0.3560\n",
      "34 of 536 176.1261117021243 43.2545009784644\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 178s 2s/step - loss: 5.3650e-05 - accuracy: 0.3555\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 5.3650e-05 - accuracy: 0.3555\n",
      "35 of 536 181.48930064837137 43.211738262526566\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 171s 2s/step - loss: 5.1516e-05 - accuracy: 0.3545\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.1516e-05 - accuracy: 0.3545\n",
      "36 of 536 186.6713469306628 43.12453803574046\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 4.6839e-05 - accuracy: 0.3542\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 148s 1s/step - loss: 4.6839e-05 - accuracy: 0.3542\n",
      "37 of 536 191.3908847371737 42.933630913540775\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.2113e-05 - accuracy: 0.3545\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 155s 2s/step - loss: 5.2113e-05 - accuracy: 0.3545\n",
      "38 of 536 196.30518809954324 42.7910870745569\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 150s 1s/step - loss: 5.0632e-05 - accuracy: 0.3551\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 5.0632e-05 - accuracy: 0.3551\n",
      "39 of 536 201.19411997795106 42.64627502278215\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 5.1352e-05 - accuracy: 0.3499\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 5.1352e-05 - accuracy: 0.3499\n",
      "40 of 536 205.96470064719517 42.480219522772565\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 140s 1s/step - loss: 5.0043e-05 - accuracy: 0.3531\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 160s 2s/step - loss: 5.0043e-05 - accuracy: 0.3531\n",
      "41 of 536 210.99356531302135 42.37025259075449\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 4.9899e-05 - accuracy: 0.3550\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 160s 2s/step - loss: 4.9899e-05 - accuracy: 0.3550\n",
      "42 of 536 215.9876198410988 42.25472087473623\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 154s 2s/step - loss: 4.5902e-05 - accuracy: 0.3544\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 4.5902e-05 - accuracy: 0.3544\n",
      "43 of 536 220.9761788169543 42.13964343966132\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 170s 2s/step - loss: 5.1797e-05 - accuracy: 0.3541\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 5.1797e-05 - accuracy: 0.3541\n",
      "44 of 536 226.09172192017238 42.049634656495215\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 140s 1s/step - loss: 4.7204e-05 - accuracy: 0.3585\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 156s 2s/step - loss: 4.7204e-05 - accuracy: 0.3585\n",
      "45 of 536 231.04868083794912 41.93105690257785\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 148s 1s/step - loss: 5.0799e-05 - accuracy: 0.3524\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 5.0799e-05 - accuracy: 0.3524\n",
      "46 of 536 235.814541721344 41.780185121401495\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 164s 2s/step - loss: 5.1956e-05 - accuracy: 0.3504\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 150s 2s/step - loss: 5.1956e-05 - accuracy: 0.3504\n",
      "47 of 536 241.0724892457326 41.71750879194015\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 156s 2s/step - loss: 5.1164e-05 - accuracy: 0.3527\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 5.1164e-05 - accuracy: 0.3527\n",
      "48 of 536 245.95257265567778 41.58989684550989\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 154s 2s/step - loss: 5.3420e-05 - accuracy: 0.3532\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 135s 1s/step - loss: 5.3420e-05 - accuracy: 0.3532\n",
      "49 of 536 250.77951987981797 41.45539003487077\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 147s 1s/step - loss: 5.3045e-05 - accuracy: 0.3487\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 154s 2s/step - loss: 5.3045e-05 - accuracy: 0.3487\n",
      "50 of 536 255.81837291717528 41.35730363098118\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 135s 1s/step - loss: 5.4517e-05 - accuracy: 0.3486\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 136s 1s/step - loss: 5.4517e-05 - accuracy: 0.3486\n",
      "51 of 536 260.3677669127782 41.18235269355099\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 145s 1s/step - loss: 4.9497e-05 - accuracy: 0.3549\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 4.9497e-05 - accuracy: 0.3549\n",
      "52 of 536 265.10675222873687 41.04056453421967\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 4.9169e-05 - accuracy: 0.3540\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 4.9169e-05 - accuracy: 0.3540\n",
      "53 of 536 269.82624441782633 40.89819176965164\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 154s 2s/step - loss: 4.7720e-05 - accuracy: 0.3548\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 4.7720e-05 - accuracy: 0.3548\n",
      "54 of 536 274.7905335942904 40.79452058112425\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 157s 2s/step - loss: 5.0725e-05 - accuracy: 0.3583\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 146s 1s/step - loss: 5.0725e-05 - accuracy: 0.3583\n",
      "55 of 536 279.8465345104535 40.704950480852474\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 4.9886e-05 - accuracy: 0.3556\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 4.9886e-05 - accuracy: 0.3556\n",
      "56 of 536 284.51606410741806 40.56047462404602\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 5.0333e-05 - accuracy: 0.3533\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 5.0333e-05 - accuracy: 0.3533\n",
      "57 of 536 289.13745556672416 40.41160929461204\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 165s 2s/step - loss: 5.0903e-05 - accuracy: 0.3577\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 145s 1s/step - loss: 5.0903e-05 - accuracy: 0.3577\n",
      "58 of 536 294.31536442041397 40.34150254518707\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 5.1946e-05 - accuracy: 0.3525\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 174s 2s/step - loss: 5.1946e-05 - accuracy: 0.3525\n",
      "59 of 536 299.5252875328064 40.275151667776754\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 150s 1s/step - loss: 5.0676e-05 - accuracy: 0.3523\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 151s 2s/step - loss: 5.0676e-05 - accuracy: 0.3523\n",
      "60 of 536 304.5689554532369 40.18618163769996\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 4.8127e-05 - accuracy: 0.3533\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 4.8127e-05 - accuracy: 0.3533\n",
      "61 of 536 309.14860291481017 40.03727808928338\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 5.1481e-05 - accuracy: 0.3520\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 155s 2s/step - loss: 5.1481e-05 - accuracy: 0.3520\n",
      "62 of 536 314.1439886252085 39.94357705687751\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 4.9552e-05 - accuracy: 0.3538\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 157s 2s/step - loss: 4.9552e-05 - accuracy: 0.3538\n",
      "63 of 536 319.1064189314842 39.846092537215775\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 129s 1s/step - loss: 4.8877e-05 - accuracy: 0.3577\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 129s 1s/step - loss: 4.8877e-05 - accuracy: 0.3577\n",
      "64 of 536 323.4281730612119 39.670486858531625\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 133s 1s/step - loss: 5.3463e-05 - accuracy: 0.3503\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 5.3463e-05 - accuracy: 0.3503\n",
      "65 of 536 327.9623473683993 39.52366750824146\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 5.2736e-05 - accuracy: 0.3546\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 150s 1s/step - loss: 5.2736e-05 - accuracy: 0.3546\n",
      "66 of 536 332.87032548983893 39.42327845745215\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 131s 1s/step - loss: 5.2177e-05 - accuracy: 0.3509\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 5.2176e-05 - accuracy: 0.3509\n",
      "67 of 536 337.1798611680667 39.25377488872799\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.0386e-05 - accuracy: 0.3508\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 142s 1s/step - loss: 5.0386e-05 - accuracy: 0.3508\n",
      "68 of 536 341.8827112277349 39.13216327678826\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 4.9737e-05 - accuracy: 0.3510\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 163s 2s/step - loss: 4.9737e-05 - accuracy: 0.3510\n",
      "69 of 536 347.0193814754486 39.06063569947238\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 149s 1s/step - loss: 5.2468e-05 - accuracy: 0.3545\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 143s 1s/step - loss: 5.2468e-05 - accuracy: 0.3545\n",
      "70 of 536 351.9040570457776 38.96080632814339\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.2710e-05 - accuracy: 0.3540\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 144s 1s/step - loss: 5.2710e-05 - accuracy: 0.3540\n",
      "71 of 536 356.63775961001716 38.84505175617939\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 5.0441e-05 - accuracy: 0.3534\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 125s 1s/step - loss: 5.0441e-05 - accuracy: 0.3534\n",
      "72 of 536 361.0275158683459 38.69345830391771\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 5.1515e-05 - accuracy: 0.3508\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 183s 2s/step - loss: 5.1515e-05 - accuracy: 0.3508\n",
      "73 of 536 366.3300448854764 38.64029241168427\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 5.6515e-05 - accuracy: 0.3507\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 5.6515e-05 - accuracy: 0.3507\n",
      "74 of 536 370.87269437710444 38.507277508383396\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 4.9481e-05 - accuracy: 0.3528\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 141s 1s/step - loss: 4.9481e-05 - accuracy: 0.3528\n",
      "75 of 536 375.54916272163393 38.38946997245594\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 148s 1s/step - loss: 4.8946e-05 - accuracy: 0.3518\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 137s 1s/step - loss: 4.8946e-05 - accuracy: 0.3518\n",
      "76 of 536 380.3242614865303 38.28263948738053\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 4.9994e-05 - accuracy: 0.3524\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 134s 1s/step - loss: 4.9994e-05 - accuracy: 0.3524\n",
      "77 of 536 384.82163027127586 38.14898413603955\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 175s 2s/step - loss: 5.1571e-05 - accuracy: 0.3554\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 147s 1s/step - loss: 5.1571e-05 - accuracy: 0.3554\n",
      "78 of 536 390.20142372051873 38.10300227827666\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 146s 1s/step - loss: 4.8892e-05 - accuracy: 0.3561\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 152s 2s/step - loss: 4.8892e-05 - accuracy: 0.3561\n",
      "79 of 536 395.19343982934953 38.01860940931718\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 139s 1s/step - loss: 5.0971e-05 - accuracy: 0.3561\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 141s 1s/step - loss: 5.0971e-05 - accuracy: 0.3561\n",
      "80 of 536 399.8796247760455 37.90525610405952\n",
      "Epoch 1/2\n",
      " 98/100 [============================>.] - ETA: 4s - loss: 5.0195e-05 - accuracy: 0.3526"
     ]
    }
   ],
   "source": [
    "st = ti()\n",
    "\n",
    "for i in range(SetsNeeded-1):\n",
    "    PercentHoldOutForNext = 1.0 - (SamplesPerSet / len(MoveSegments))\n",
    "    seq_train, seq_test, out_train, out_test = train_test_split(MoveSegments, NextDataPoint, test_size=PercentHoldOutForNext, shuffle=True, random_state=0)\n",
    "    seq_train = np.asarray(seq_train)\n",
    "    lstm_autoencoder2.model.fit(seq_train, seq_train, epochs=2, batch_size=32, verbose=1)\n",
    "    MoveSegments = seq_test\n",
    "    NextDataPoint = out_test\n",
    "    print(str(i+1)+' of ' + str(SetsNeeded), (ti()-st)/60, ((ti()-st)/(i+1) * ( SetsNeeded -1) - (ti()-st))/60/60)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lstm_autoencoder2.model.save(\"LSTM_FullDays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_X = lstm_autoencoder2.model.predict(seq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = np.squeeze(output_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.linalg.norm(seq_train - reconstruction, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes = np.max(scores, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_autoencoder2.plot(maxes, seq_train, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoopFiles = 3\n",
    "loops = int(len(BeforeTamping) / LoopFiles) \n",
    "if len(files)%LoopFiles != 0:\n",
    "    loops += 1\n",
    "\n",
    "st = ti()\n",
    "\n",
    "Moves = []\n",
    "\n",
    "for k in range(loops):\n",
    "    if k == loops -1:\n",
    "        tfiles = BeforeTamping[k*LoopFiles:]\n",
    "    else:\n",
    "        tfiles = BeforeTamping[k*LoopFiles:(k+1)*LoopFiles]\n",
    "    #Results = Parallel(n_jobs=LoopFiles)(delayed(DeviationVelocity)(file) for file in tfiles)\n",
    "    Results = Parallel(n_jobs=LoopFiles)(delayed(SmoothMoves)(file) for file in tfiles)\n",
    "    #Results =[]\n",
    "    #for file in tfiles:\n",
    "    #    Results.append(DeviationVelocity(file))\n",
    "    #    print(file, (ti()-st)/60.0)\n",
    "    for result in Results:\n",
    "        Moves.append(result)\n",
    "    print(k, (ti()-st)/60.0)\n",
    "        \n",
    "Sequences = []\n",
    "Outputs = []\n",
    "for move in Moves:\n",
    "    Seq, Out = split_sequences(move.T,TimeSteps,StepSize)\n",
    "    Sequences.append(Seq)\n",
    "    Outputs.append(Out)\n",
    "MoveSegments = []\n",
    "for seq in Sequences:\n",
    "    for mv in seq:\n",
    "        MoveSegments.append(mv)\n",
    "NextDataPoint = []\n",
    "for out in Outputs:\n",
    "    for pt in out:\n",
    "        NextDataPoint.append(np.reshape(pt,(1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "178f6c3502586c94dc93af50f98dbd15c5205250cbf2345a6eb57380f8c77d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
