{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.eps'\n",
    "if not 'location' in locals():\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\n",
    "\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "#Standard cycle for collors and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special Header for package imports:\n",
    "import os\n",
    "from random import random\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    " \n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics as km\n",
    " \n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic for this program:\n",
    "1. Choose Random set from Repository\n",
    "1. Parse Name to get accepted output vector\n",
    "1. Train Models on data\n",
    "    * Data Prep:\n",
    "      * Try un smoothed\n",
    "      * Try smoothed with rolling average\n",
    "      * try smooth with kalman\n",
    "      * keep data trunkated with smoothing\n",
    "    * Model TypesVideo and Image\n",
    "      * Video:\n",
    "        * Rolling, 3x100, 3x changing frame sizes\n",
    "        * overlapping segments, 3x?? hoping down line\n",
    "        * rolling fingerprints\n",
    "          * Try many fingerprints\n",
    "          * look at Beta, and classification as it is going\n",
    "      * Image:\n",
    "        * Fingerprint\n",
    "        * 3 x 60k image\n",
    "1. Examine differences of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\Documents\\\\Dan\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danhe\\Code\\RMG_NDE_Disssertation\\TF-Video Classification.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m#SensorPositonFile = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39m#SensorPositonFile = 'C:\\\\Users\\\\danhe\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=2'>3</a>\u001b[0m SensorPositonFile \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mE:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDocuments\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDan\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mCode\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mRMG_NDE_Disssertation\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mSensorLocations.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=4'>5</a>\u001b[0m OutputVectors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(\u001b[39mopen\u001b[39;49m(SensorPositonFile,\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m), delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,skip_header\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,missing_values\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtruthVector\u001b[39m(Filename):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=7'>8</a>\u001b[0m     \u001b[39m# Parses the filename, and compares it against the record of sensor position on cranes\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=8'>9</a>\u001b[0m     \u001b[39m# inputs: filename\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=12'>13</a>\u001b[0m     \u001b[39m#Parsing the file name.  Assuming it is in the standard format\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000003?line=13'>14</a>\u001b[0m     sYear \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m20\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m Filename[\u001b[39m10\u001b[39m:\u001b[39m12\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\Documents\\\\Dan\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'"
     ]
    }
   ],
   "source": [
    "#SensorPositonFile = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\n",
    "#SensorPositonFile = 'C:\\\\Users\\\\danhe\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\n",
    "#SensorPositonFile = 'E:\\\\Documents\\\\Dan\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\n",
    "SensorPositonFile = 'D:\\\\SensorStatsSmall.csv'\n",
    "\n",
    "OutputVectors = np.genfromtxt(open(SensorPositonFile,'r'), delimiter=',',skip_header=1,missing_values=0)\n",
    "\n",
    "def truthVector(Filename):\n",
    "    # Parses the filename, and compares it against the record of sensor position on cranes\n",
    "    # inputs: filename\n",
    "    # outputs: truth vector\n",
    "\n",
    "\n",
    "    #Parsing the file name.  Assuming it is in the standard format\n",
    "    sYear = '20' + Filename[10:12]\n",
    "    sMonth = Filename[12:14]\n",
    "    sDay = Filename[14:16]\n",
    "    sHour = Filename[17:19]\n",
    "    sMin = Filename[19:21]\n",
    "    sSensor = Filename[23]\n",
    "    sDate = datetime.datetime.strptime(Filename[10:21],\"%Y%m%d-%H%M\")\n",
    "\n",
    "    mask = []\n",
    "\n",
    "    i=0\n",
    "    #loops through the known sensor movements, and creates a filter mask\n",
    "    for spf in OutputVectors:\n",
    "        \n",
    "        startDate = datetime.datetime.strptime(str(spf[0])+str(spf[1]).zfill(2)+str(spf[2]).zfill(2)\n",
    "            +str(spf[3]).zfill(2)+str(spf[4]).zfill(2),\"%Y%m%d%H%M\")\n",
    "        #datetime.date(int(spf[0]), int(spf[1]), int(spf[2])) + datetime.timedelta(hours=spf[3]) + datetime.timedelta(minutes=spf[4])\n",
    "        endDate = datetime.datetime.strptime(str(spf[5])+str(spf[6]).zfill(2)+str(spf[7]).zfill(2)\n",
    "            +str(spf[8]).zfill(2)+str(spf[9]).zfill(2),\"%Y%m%d%H%M\")\n",
    "        #datetime.date(int(spf[5]), int(spf[6]), int(spf[7])) + datetime.timedelta(hours=spf[8]) + datetime.timedelta(minutes=spf[9])\n",
    "        \n",
    "        if sDate >= startDate and sDate <= endDate and int(spf[10]) == int(sSensor):\n",
    "            mask.append(True)\n",
    "            i+=1\n",
    "        else:\n",
    "            mask.append(False)\n",
    "        \n",
    "    if i == 0: print('error ', Filename)\n",
    "\n",
    "    results = OutputVectors[mask,11:]\n",
    "\n",
    "    if i > 1: \n",
    "        print('Found Two ', Filename)\n",
    "        results = results[0,:]\n",
    "    #np.array(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "def makeFrames(input,sequ,frameLength):\n",
    "    frames=[] #np.array([],dtype=object,)\n",
    "    segmentGap = int((np.shape(input)[0]-frameLength)/sequ)\n",
    "    #print(segmentGap,sequ, frameLength)\n",
    "    for i in range(sequ):\n",
    "        start = i * segmentGap\n",
    "        imageMatrix = input[start:start+frameLength,:]\n",
    "        np.matrix(imageMatrix)\n",
    "        imageMatrix = imageMatrix.T\n",
    "        frames.append(imageMatrix)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sample data set with labels\n",
    "\n",
    "#Number of files to get for test\n",
    "n = 10\n",
    "img_height , img_width = 3, 100\n",
    "numberFrames = 600\n",
    "\n",
    "#folder = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\n",
    "#folder = 'C:\\\\Users\\\\danhe\\\\Code\\\\TestData\\\\'\n",
    "#folder = 'C:\\\\Users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\AccelData\\\\'\n",
    "folder = \"D:\\\\SmallCopy\\\\\"\n",
    "\n",
    "files = os.listdir(folder)\n",
    "#files = random.sample(files,n)\n",
    "\n",
    "DataSet = [] #np.array([],dtype=object,)\n",
    "\n",
    "ResultsSet = np.zeros((len(files),np.shape(OutputVectors[:,11:])[1])) #np.array([],dtype=object,)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 44)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ResultsSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Two  60kPoints-211118-0604-s1.csv\n",
      "Found Two  60kPoints-211118-0607-s1.csv\n",
      "Found Two  60kPoints-211118-0611-s1.csv\n",
      "Found Two  60kPoints-211118-0614-s1.csv\n",
      "Found Two  60kPoints-211118-0617-s1.csv\n",
      "Found Two  60kPoints-211118-0621-s1.csv\n",
      "Found Two  60kPoints-211118-0627-s1.csv\n",
      "Found Two  60kPoints-211118-0631-s1.csv\n",
      "Found Two  60kPoints-211118-0634-s1.csv\n",
      "Found Two  60kPoints-211206-1451-s1.csv\n",
      "Found Two  60kPoints-211206-1624-s1.csv\n",
      "Found Two  60kPoints-211206-1627-s1.csv\n",
      "Found Two  60kPoints-211206-1630-s1.csv\n",
      "Found Two  60kPoints-211206-1633-s1.csv\n",
      "Found Two  60kPoints-211206-1637-s1.csv\n",
      "ros\n",
      "old\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for filename in files:\n",
    "    if filename[-3:] == 'csv':\n",
    "        ResultsSet[i,:] = truthVector(filename)\n",
    "        fileData = np.genfromtxt(open(folder+filename,'r'), delimiter=',',skip_header=0,missing_values=0).T[2:5,:]\n",
    "        frames = makeFrames(fileData.T,numberFrames,img_width)\n",
    "        #print(np.shape(DataSet),np.shape(frames),1)\n",
    "        frames = np.asarray(frames)\n",
    "        DataSet.append(frames)\n",
    "        i+=1\n",
    "    else: print(filename[-3:])\n",
    "\n",
    "#ResultsSet = np.asarray(ResultsSet)\n",
    "DataSet = np.asarray(DataSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 600, 3, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(DataSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 44)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResultsSet = ResultsSet[0:np.shape(DataSet)[0],:]\n",
    "np.shape(ResultsSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(DataSet, ResultsSet, test_size=0.20, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 44)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 600, 3, 100)\n",
      "(28, 44)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 98, 64)         150016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 98, 64)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1605888   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 44)                11308     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,767,212\n",
      "Trainable params: 1,767,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 16s 5s/step - loss: nan - accuracy: 0.1364 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 26s 9s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 33s 11s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 36s 12s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 39s 13s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 42s 14s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 44s 15s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, \n",
    "            kernel_size = (3, 3), \n",
    "            return_sequences = False, \n",
    "            data_format = \"channels_last\", \n",
    "            input_shape = (numberFrames, img_height, img_width, 1)\n",
    "            )\n",
    "        )\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(np.shape(y_train)[1], activation = \"softmax\"))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "earlystop = EarlyStopping(patience=7)   \n",
    "callbacks = [earlystop]\n",
    "\n",
    "history = model.fit(x = X_train, y = y_train, epochs=40, batch_size = 8 , shuffle=False, validation_split=0.2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3/3 [==============================] - 44s 15s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 46s 15s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 47s 16s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 49s 16s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 50s 17s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 51s 17s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 52s 17s/step - loss: nan - accuracy: 0.2727 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24872/926534238.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "history = model.fit(x = X_train, y = y_train, epochs=40, batch_size = 8 , shuffle=False, validation_split=0.2, callbacks=callbacks)\n",
    " \n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    " \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72674e6928aeb149b17451b3afa2eccc8eb91630257127848cb7dabc56ce48f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
