{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.eps'\n",
    "if not 'location' in locals():\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\n",
    "\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "#Standard cycle for collors and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special Header for package imports:\n",
    "import os\n",
    "from random import random\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    " \n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics as km\n",
    " \n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic for this program:\n",
    "1. Choose Random set from Repository\n",
    "1. Parse Name to get accepted output vector\n",
    "1. Train Models on data\n",
    "    * Data Prep:\n",
    "      * Try un smoothed\n",
    "      * Try smoothed with rolling average\n",
    "      * try smooth with kalman\n",
    "      * keep data trunkated with smoothing\n",
    "    * Model TypesVideo and Image\n",
    "      * Video:\n",
    "        * Rolling, 3x100, 3x changing frame sizes\n",
    "        * overlapping segments, 3x?? hoping down line\n",
    "        * rolling fingerprints\n",
    "          * Try many fingerprints\n",
    "          * look at Beta, and classification as it is going\n",
    "      * Image:\n",
    "        * Fingerprint\n",
    "        * 3 x 60k image\n",
    "1. Examine differences of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SensorPositonFile = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\n",
    "SensorPositonFile = 'C:\\\\Users\\\\danhe\\\\Code\\\\RMG_NDE_Disssertation\\\\SensorLocations.csv'\n",
    "OutputVectors = np.genfromtxt(open(SensorPositonFile,'r'), delimiter=',',skip_header=1,missing_values=0)\n",
    "\n",
    "\n",
    "\n",
    "def truthVector(Filename):\n",
    "    # Parses the filename, and compares it against the record of sensor position on cranes\n",
    "    # inputs: filename\n",
    "    # outputs: truth vector\n",
    "\n",
    "\n",
    "    #Parsing the file name.  Assuming it is in the standard format\n",
    "    sYear = '20' + Filename[10:12]\n",
    "    sMonth = Filename[12:14]\n",
    "    sDay = Filename[14:16]\n",
    "    sHour = Filename[17:19]\n",
    "    sMin = Filename[19:21]\n",
    "    sSensor = Filename[23]\n",
    "\n",
    "    mask = []\n",
    "\n",
    "\n",
    "    #loops through the known sensor movements, and creates a filter mask\n",
    "    for spf in OutputVectors:\n",
    "        startDate = datetime.date(int(spf[0]), int(spf[1]), int(spf[2])) + datetime.timedelta(hours=spf[3]) + datetime.timedelta(minutes=spf[4])\n",
    "        endDate = datetime.date(int(spf[5]), int(spf[6]), int(spf[7])) + datetime.timedelta(hours=spf[8]) + datetime.timedelta(minutes=spf[9])\n",
    "        sDate = datetime.date(int(sYear), int(sMonth), int(sDay)) + datetime.timedelta(hours=int(sHour)) + datetime.timedelta(minutes=int(sMin))\n",
    "\n",
    "        if sDate >= startDate and sDate <= endDate and int(spf[10]) == int(sSensor):\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "\n",
    "    return np.nan_to_num(OutputVectors[mask,11:])\n",
    "\n",
    "def makeFrames(input,sequ,frameLength):\n",
    "    frames=[]\n",
    "    segmentGap = int((np.shape(input)[0]-frameLength)/sequ)\n",
    "    for i in range(segmentGap):\n",
    "        start = i * segmentGap\n",
    "        frames.append(input[start:start+frameLength,:])\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sample data set with labels\n",
    "\n",
    "#Number of files to get for test\n",
    "n = 10\n",
    "img_height , img_width = 3, 100\n",
    "seq_len = 600\n",
    "\n",
    "#folder = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\n",
    "folder = 'C:\\\\Users\\\\danhe\\\\Code\\\\TestData\\\\'\n",
    "files = os.listdir(folder)\n",
    "#files = random.sample(files,n)\n",
    "\n",
    "DataSet = []\n",
    "ResultsSet = []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danhe\\AppData\\Local\\Temp\\ipykernel_19136\\1722620075.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ResultsSet = np.asarray(ResultsSet)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in files:\n",
    "    ResultsSet.append(truthVector(filename))\n",
    "    frames = makeFrames(np.genfromtxt(open(folder+filename,'r'), delimiter=',',skip_header=1,missing_values=0)[:,2:5].T,seq_len,img_width)\n",
    "    DataSet.append(frames)\n",
    "\n",
    "ResultsSet = np.asarray(ResultsSet)\n",
    "DataSet = np.asarray(DataSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 1, 98, 64)         150016    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 98, 64)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               1605888   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,757,446\n",
      "Trainable params: 1,757,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danhe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danhe\\Code\\RMG_NDE_Disssertation\\TF-Video Classification.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000006?line=15'>16</a>\u001b[0m earlystop \u001b[39m=\u001b[39m EarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000006?line=16'>17</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [earlystop]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000006?line=18'>19</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x \u001b[39m=\u001b[39;49m X_train, y \u001b[39m=\u001b[39;49m y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m8\u001b[39;49m , shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000006?line=20'>21</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred, axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danhe/Code/RMG_NDE_Disssertation/TF-Video%20Classification.ipynb#ch0000006?line=21'>22</a>\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_test, axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/constant_op.py?line=99'>100</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/constant_op.py?line=100'>101</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> <a href='file:///c%3A/Users/danhe/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/constant_op.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(DataSet, ResultsSet, test_size=0.20, shuffle=True, random_state=0)\n",
    " \n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (seq_len, img_height, img_width, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation = \"softmax\"))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "opt = tf.keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "earlystop = EarlyStopping(patience=7)\n",
    "callbacks = [earlystop]\n",
    " \n",
    "history = model.fit(x = X_train, y = y_train, epochs=40, batch_size = 8 , shuffle=True, validation_split=0.2, callbacks=callbacks)\n",
    " \n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    " \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72674e6928aeb149b17451b3afa2eccc8eb91630257127848cb7dabc56ce48f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
