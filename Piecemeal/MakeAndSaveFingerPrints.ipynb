{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from pywt._extensions._pywt import (DiscreteContinuousWavelet, ContinuousWavelet,\n",
    "                                Wavelet, _check_dtype)\n",
    "from pywt._functions import integrate_wavelet, scale2frequency\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "rootfolder = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "folder=rootfolder+\"SmallCopy\\\\\"\n",
    "wavelt = 'gaus2'\n",
    "scales = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwt_fixed(data, scales, wavelet, sampling_period=1.):\n",
    "    \"\"\"\n",
    "    COPIED AND FIXED FROM pywt.cwt TO BE ABLE TO USE WAVELET FAMILIES SUCH\n",
    "    AS COIF AND DB\n",
    "\n",
    "    COPIED From Spenser Kirn\n",
    "    \n",
    "    All wavelet work except bior family, rbio family, haar, and db1.\n",
    "    \n",
    "    cwt(data, scales, wavelet)\n",
    "\n",
    "    One dimensional Continuous Wavelet Transform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Input signal\n",
    "    scales : array_like\n",
    "        scales to use\n",
    "    wavelet : Wavelet object or name\n",
    "        Wavelet to use\n",
    "    sampling_period : float\n",
    "        Sampling period for frequencies output (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coefs : array_like\n",
    "        Continous wavelet transform of the input signal for the given scales\n",
    "        and wavelet\n",
    "    frequencies : array_like\n",
    "        if the unit of sampling period are seconds and given, than frequencies\n",
    "        are in hertz. Otherwise Sampling period of 1 is assumed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Size of coefficients arrays depends on the length of the input array and\n",
    "    the length of given scales.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pywt\n",
    "    >>> import numpy as np\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> x = np.arange(512)\n",
    "    >>> y = np.sin(2*np.pi*x/32)\n",
    "    >>> coef, freqs=pywt.cwt(y,np.arange(1,129),'gaus1')\n",
    "    >>> plt.matshow(coef) # doctest: +SKIP\n",
    "    >>> plt.show() # doctest: +SKIP\n",
    "    ----------\n",
    "    >>> import pywt\n",
    "    >>> import numpy as np\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "    >>> sig  = np.cos(2 * np.pi * 7 * t) + np.real(np.exp(-7*(t-0.4)**2)*np.exp(1j*2*np.pi*2*(t-0.4)))\n",
    "    >>> widths = np.arange(1, 31)\n",
    "    >>> cwtmatr, freqs = pywt.cwt(sig, widths, 'mexh')\n",
    "    >>> plt.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "    ...            vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "    >>> plt.show() # doctest: +SKIP\n",
    "    \"\"\"\n",
    "\n",
    "    # accept array_like input; make a copy to ensure a contiguous array\n",
    "    dt = _check_dtype(data)\n",
    "    data = np.array(data, dtype=dt)\n",
    "    if not isinstance(wavelet, (ContinuousWavelet, Wavelet)):\n",
    "        wavelet = DiscreteContinuousWavelet(wavelet)\n",
    "    if np.isscalar(scales):\n",
    "        scales = np.array([scales])\n",
    "    if data.ndim == 1:\n",
    "        try:\n",
    "            if wavelet.complex_cwt:\n",
    "                out = np.zeros((np.size(scales), data.size), dtype=complex)\n",
    "            else:\n",
    "                out = np.zeros((np.size(scales), data.size))\n",
    "        except AttributeError:\n",
    "            out = np.zeros((np.size(scales), data.size))\n",
    "        for i in np.arange(np.size(scales)):\n",
    "            precision = 10\n",
    "            int_psi, x = integrate_wavelet(wavelet, precision=precision)\n",
    "            step = x[1] - x[0]\n",
    "            j = np.floor(\n",
    "                np.arange(scales[i] * (x[-1] - x[0]) + 1) / (scales[i] * step))\n",
    "            if np.max(j) >= np.size(int_psi):\n",
    "                j = np.delete(j, np.where((j >= np.size(int_psi)))[0])\n",
    "            coef = - np.sqrt(scales[i]) * np.diff(\n",
    "                np.convolve(data, int_psi[j.astype(int)][::-1]))\n",
    "            d = (coef.size - data.size) / 2.\n",
    "            out[i, :] = coef[int(np.floor(d)):int(-np.ceil(d))]\n",
    "        frequencies = scale2frequency(wavelet, scales, precision)\n",
    "        if np.isscalar(frequencies):\n",
    "            frequencies = np.array([frequencies])\n",
    "        for i in np.arange(len(frequencies)):\n",
    "            frequencies[i] /= sampling_period\n",
    "        return out, frequencies\n",
    "    else:\n",
    "        raise ValueError(\"Only dim == 1 supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThumbprint(data, wvt, ns=500, numslices=5, slicethickness=0.12, \n",
    "                  valleysorpeaks='both', normconstant=1, plot=True):\n",
    "    '''\n",
    "    STarted with Spenser Kirn's code, modifed by DCH\n",
    "    Updated version of the DWFT function above that allows plotting of just\n",
    "    valleys or just peaks or both. To plot just valleys set valleysorpeaks='valleys'\n",
    "    to plot just peaks set valleysorpeaks='peaks' or 'both' to plot both.\n",
    "    '''\n",
    "    # First take the wavelet transform and then normalize to one\n",
    "    cfX, freqs = cwt_fixed(data, np.arange(1,ns+1), wvt)\n",
    "    cfX = np.true_divide(cfX, abs(cfX).max()*normconstant)\n",
    "    \n",
    "    fp = np.zeros((len(data), ns), dtype=int)\n",
    "    \n",
    "    # Create the list of locations between -1 and 1 to preform slices. Valley\n",
    "    # slices will all be below 0 and peak slices will all be above 0.\n",
    "    if valleysorpeaks == 'both':\n",
    "        slicelocations1 = np.arange(-1 ,0.0/numslices, 1.0/numslices)\n",
    "        slicelocations2 = np.arange(1.0/numslices, 1+1.0/numslices, 1.0/numslices)\n",
    "        slicelocations = np.array(np.append(slicelocations1,slicelocations2))\n",
    "        \n",
    "    for loc in slicelocations:\n",
    "        for y in range(0, ns):\n",
    "            for x in range(0, len(data)):\n",
    "                if cfX[y, x]>=(loc-(slicethickness/2)) and cfX[y,x]<= (loc+(slicethickness/2)):\n",
    "                    fp[x,y] = 1\n",
    "                    \n",
    "    fp = np.transpose(fp[:,:ns])\n",
    "    return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smoothing(RawData): #, SmoothType = 1, SmoothDistance=15):\n",
    "\n",
    "    if SmoothType == 0:\n",
    "        SmoothedData = RawData\n",
    "    elif SmoothType ==1:\n",
    "        SmoothedData = RawData\n",
    "        if np.shape(np.shape(RawData))== 2:\n",
    "            for i in range(SmoothDistance-1):\n",
    "                for j in range(3):\n",
    "                    SmoothedData[j,i+1]=np.average(RawData[j,0:i+1])\n",
    "            for i in range(np.shape(RawData)[0]-SmoothDistance):\n",
    "                for j in range(3):\n",
    "                    SmoothedData[j,i+SmoothDistance]=np.average(RawData[j,i:i+SmoothDistance])\n",
    "        elif np.shape(np.shape(RawData))== 1:\n",
    "            for i in range(SmoothDistance-1):\n",
    "                SmoothedData[i+1]=np.average(RawData[0:i+1])\n",
    "            for i in range(np.shape(RawData)[0]-SmoothDistance):\n",
    "                SmoothedData[i+SmoothDistance]=np.average(RawData[i:i+SmoothDistance])\n",
    "\n",
    "    return SmoothedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRAcceleration(Data):\n",
    "    rVals = []\n",
    "    for i in range(np.shape(Data)[0]):\n",
    "        rVals.append(np.sqrt(Data[i,0]**2+Data[i,1]**2+Data[i,2]**2))\n",
    "    return rVals\n",
    "\n",
    "def getAcceleration(FileName):\n",
    "    try:\n",
    "        DataSet = np.genfromtxt(open(folder+FileName,'r'), delimiter=',',skip_header=0)\n",
    "        rData = getRAcceleration(DataSet[:,2:5])\n",
    "        rSmoothed = Smoothing(rData)\n",
    "        #return [[FileName,'x',DataSet[:,2]],[FileName,'y',DataSet[:,3]],[FileName,'z',DataSet[:,4]],[FileName,'r',rData]]\n",
    "        return [FileName, 'r', rSmoothed]\n",
    "    except:\n",
    "        return [False,FileName,False]\n",
    "\n",
    "def makePrints(DataArray):\n",
    "    #try:\n",
    "        FingerPrint = getThumbprint(DataArray[2],'gaus2')\n",
    "        #FingerPrint = np.ones((60000,500),dtype=int) * DataArray[2]\n",
    "        return [DataArray[0],DataArray[1],FingerPrint]\n",
    "    #except:\n",
    "    #    return [DataArray[0], 'Fail', np.zeros((60000,500),dtype=int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SavePrints(DataWithMeta):\n",
    "    \n",
    "    ReturnedPrint = makePrints(DataWithMeta)\n",
    "    filename = ReturnedPrint[0][:-4]+ReturnedPrint[1]+'.fpobj'\n",
    "    fullFN = rootfolder + wavelt + '//' + filename\n",
    "    filehandler = open(fullFN, 'wb')\n",
    "\n",
    "    pickle.dump(ReturnedPrint[2], filehandler)\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have Data 1 1\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "DoSomeFiles = True\n",
    "NumberOfFiles = 1\n",
    "SmoothType = 1  # 0 = none, 1 = rolling average, 2 = rolling StdDev\n",
    "SmoothDistance = 15\n",
    "num_cores = multiprocessing.cpu_count() -1\n",
    "\n",
    "files = os.listdir(folder)\n",
    "if DoSomeFiles: files = random.sample(files,NumberOfFiles)\n",
    "\n",
    "GroupSize = num_cores * 2\n",
    "\n",
    "if np.size(files) % GroupSize == 0:\n",
    "    batches = int(np.size(files)/GroupSize)\n",
    "else:\n",
    "    batches = int(float(np.size(files))/float(GroupSize))+1\n",
    "\n",
    "AllFingers = [] #np.asarray(dtype=object)\n",
    "\n",
    "for i in range(batches):\n",
    "    AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(file) for file in files[i*GroupSize:((i+1)*GroupSize)])\n",
    "    Flattened = []\n",
    "    for j in range(np.shape(AllAccels)[0]):\n",
    "        if AllAccels[j][0] == False:\n",
    "            print(j,AllAccels[j][1])\n",
    "        else: \n",
    "            Flattened.append(AllAccels[j])\n",
    "    print('Have Data',i+1,batches)\n",
    "    Fingers =  Parallel(n_jobs=num_cores)(delayed(SavePrints)(datas) for datas in Flattened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SavePrints(Flattened[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c81fa076aeee1253ea90d918e51bf8233268ffae4e578373f00cbeda6d65c3b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
