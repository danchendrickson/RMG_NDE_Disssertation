{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at accelerometer data \n",
    "\n",
    "Finding Zero velocity times by rail axis acceleration noise levels, making summary statistics for the noise levels across the whole day files.  Spot check graphs to see what works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '-', '-', '-']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "\n",
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "\n",
    "from time import time as ti\n",
    "\n",
    "import CoreFunctions as cf\n",
    "from skimage.restoration import denoise_wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HostName = platform.node()\n",
    "\n",
    "if HostName == \"Server\":\n",
    "    Computer = \"Desktop\"   \n",
    "elif HostName[-6:] == 'wm.edu':\n",
    "    Computer = \"SciClone\"\n",
    "elif HostName == \"SchoolLaptop\":\n",
    "    Computer = \"LinLap\"\n",
    "elif HostName == \"WTC-TAB-512\":\n",
    "    Computer = \"PortLap\"\n",
    "else:\n",
    "    Computer = \"WinLap\"\n",
    "\n",
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'\n",
    "\n",
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/sciclone/scr10/dchendrickson01/Recordings2/'\n",
    "    imageFolder = '/sciclone/scr10/dchendrickson01/Move3Dprint/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'Recordings2/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'Recordings2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saving = False\n",
    "location = folder\n",
    "Titles = True\n",
    "Ledgends = True\n",
    "\n",
    "f = 0\n",
    "\n",
    "\n",
    "files = ['230418 recording1.csv','230419 recording1.csv','230420 recording1.csv','230421 recording1.csv']#,\n",
    "#         '230418 recording2.csv','230419 recording2.csv','230420 recording2.csv','230421 recording2.csv']\n",
    "\n",
    "#Smooth = cf.Smoothing(ODataSet[:,3],2) #,50)\n",
    "def SmoothMoves(file):\n",
    "    #    if file[-3:] =='csv':\n",
    "    ODataSet = np.genfromtxt(open(folder+file,'r'), delimiter=',',skip_header=0,missing_values=0,invalid_raise=False)\n",
    "    SmoothX = denoise_wavelet(ODataSet[:,3], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothY = denoise_wavelet(ODataSet[:,4], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothZ = denoise_wavelet(ODataSet[:,5], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothX -= np.average(SmoothX)\n",
    "    SmoothY -= np.average(SmoothY)\n",
    "    SmoothZ -= np.average(SmoothZ)\n",
    "    MoveMatrix = np.matrix([SmoothX, SmoothY, SmoothZ])\n",
    "    return MoveMatrix\n",
    "    #else:\n",
    "    #    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8429263512293497\n"
     ]
    }
   ],
   "source": [
    "LoopFiles = 8\n",
    "loops = int(len(files) / LoopFiles) \n",
    "if len(files)%LoopFiles != 0:\n",
    "    loops += 1\n",
    "\n",
    "\n",
    "\n",
    "st = ti()\n",
    "\n",
    "Moves = []\n",
    "\n",
    "for k in range(loops):\n",
    "    if k == loops -1:\n",
    "        tfiles = files[k*LoopFiles:]\n",
    "    else:\n",
    "        tfiles = files[k*LoopFiles:(k+1)*LoopFiles]\n",
    "    #Results = Parallel(n_jobs=LoopFiles)(delayed(DeviationVelocity)(file) for file in tfiles)\n",
    "    Results = Parallel(n_jobs=LoopFiles)(delayed(SmoothMoves)(file) for file in tfiles)\n",
    "    #Results =[]\n",
    "    #for file in tfiles:\n",
    "    #    Results.append(DeviationVelocity(file))\n",
    "    #    print(file, (ti()-st)/60.0)\n",
    "    for result in Results:\n",
    "        Moves.append(result)\n",
    "    print(k, (ti()-st)/60.0)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "TimeSteps = 500\n",
    "StepSize = 12\n",
    "PredictSize = 25\n",
    "Features = 3\n",
    "#Features = np.shape(Moves[0])[0]\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps, s_step = 1, y_steps = 1):\n",
    "    X, y = list(), list()\n",
    "    Steps_to_take = int((len(sequences)-TimeSteps-PredictSize) / s_step)-1\n",
    "    for j in range(Steps_to_take):\n",
    "        i = j * s_step\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequences[i:end_ix, :]\n",
    "        seq_y = sequences[end_ix:end_ix+y_steps,:]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    print(np.shape(y))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1554882, 25, 3)\n",
      "(1574784, 25, 3)\n",
      "(1591982, 25, 3)\n",
      "(1580635, 25, 3)\n",
      "Move Segments  6302283 3.1508456587791445\n"
     ]
    }
   ],
   "source": [
    "Sequences = []\n",
    "Outputs = []\n",
    "for move in Moves:\n",
    "    Seq, Out = split_sequences(move.T,TimeSteps,StepSize,PredictSize)\n",
    "    Sequences.append(Seq)\n",
    "    Outputs.append(Out)\n",
    "    \n",
    "\n",
    "MoveSegments = []\n",
    "for seq in Sequences:\n",
    "    for mv in seq:\n",
    "        MoveSegments.append(mv)\n",
    "NextDataPoint = []\n",
    "for out in Outputs:\n",
    "    for pt in out:\n",
    "        NextDataPoint.append(pt) #np.reshape(pt,(PredictSize,3)))\n",
    "\n",
    "print('Move Segments ', len(MoveSegments),(ti()-st)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(NextDataPoint[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 18:08:09.828521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Masking, Lambda\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder:\n",
    "  def __init__(self, optimizer='adam', loss='mse'):\n",
    "    self.optimizer = optimizer\n",
    "    self.loss = loss\n",
    "    self.n_features = Features\n",
    "    self.timesteps = TimeSteps\n",
    "    \n",
    "  def build_model(self):\n",
    "    timesteps = self.timesteps\n",
    "    n_features = self.n_features\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Padding\n",
    "    #model.add(Masking(mask_value=0.0, input_shape=(timesteps, n_features)))\n",
    "\n",
    "    # Encoder\n",
    "    model.add(LSTM(timesteps, activation='relu', input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(12, activation='relu'))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(LSTM(timesteps, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    \n",
    "    model.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    self.model = model\n",
    "    \n",
    "  def simple_model(self):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(250, input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    #model.add(RepeatVector(TimeSteps))\n",
    "    #model.add(RepeatVector(PredictSize))\n",
    "    \n",
    "    #model.add(LSTM(25, return_sequences=True))\n",
    "    \n",
    "    model.add(Lambda(lambda x: x[:, -PredictSize:, :])) #Select last N from output  \n",
    "    #https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras?noredirect=1&lq=1\n",
    "    \n",
    "    model.add(TimeDistributed(Dense( self.n_features, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    self.model = model\n",
    "    \n",
    "  def fit(self, X, epochs=3, batch_size=32):\n",
    "    #self.timesteps = np.shape(X)[0]\n",
    "    self.build_model()\n",
    "    \n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    self.model.fit(X, X, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "  def predict(self, X):\n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    output_X = self.model.predict(X)\n",
    "    reconstruction = np.squeeze(output_X)\n",
    "    return np.linalg.norm(X - reconstruction, axis=-1)\n",
    "  \n",
    "  def plot(self, scores, timeseries, threshold=0.95):\n",
    "    sorted_scores = sorted(scores)\n",
    "    threshold_score = sorted_scores[round(len(scores) * threshold)]\n",
    "    \n",
    "    plt.title(\"Reconstruction Error\")\n",
    "    plt.plot(scores)\n",
    "    plt.plot([threshold_score]*len(scores), c='r')\n",
    "    plt.show()\n",
    "    \n",
    "    anomalous = np.where(scores > threshold_score)\n",
    "    normal = np.where(scores <= threshold_score)\n",
    "    \n",
    "    plt.title(\"Anomalies\")\n",
    "    plt.scatter(normal, timeseries[normal][:,-1], s=3)\n",
    "    plt.scatter(anomalous, timeseries[anomalous][:,-1], s=5, c='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 18:08:49.362434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 18:08:49.368296: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 500, 250)          254000    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 25, 250)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 25, 3)            753       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,753\n",
      "Trainable params: 254,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_autoencoder2 = LSTM_Autoencoder(optimizer='adam', loss='mse')\n",
    "\n",
    "#lstm_autoencoder2.build_model()\n",
    "lstm_autoencoder2.simple_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6302283 1970\n"
     ]
    }
   ],
   "source": [
    "Batches = 32\n",
    "NumbBatches = 100\n",
    "\n",
    "SamplesPerSet = Batches * NumbBatches\n",
    "\n",
    "SetsNeeded = int(len(MoveSegments) / SamplesPerSet)\n",
    "if  int(len(MoveSegments) / SamplesPerSet) != 0:\n",
    "    SetsNeeded += 1\n",
    "print(len(MoveSegments), SetsNeeded)\n",
    "\n",
    "PercentPerSet = 1.0 / float(SetsNeeded)\n",
    "\n",
    "PercentHoldOutForNext=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.0016 - accuracy: 0.3251\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 105s 1s/step - loss: -3.8400e-04 - accuracy: 0.3052\n",
      "1 of 1970 3.7206953605016073 122.03880964888467\n",
      "2 of 1970 7.896191596984863 129.43174196134012\n",
      "3 of 1970 10.989204319318135 120.02653331297414\n",
      "4 of 1970 14.459159755706787 118.38437115006977\n",
      "5 of 1970 16.592797017097475 108.62751246492068\n",
      "6 of 1970 22.271860365072886 121.44350624300814\n",
      "7 of 1970 26.574706717332205 124.1418446445938\n",
      "8 of 1970 28.737721423308056 117.40556638915506\n",
      "9 of 1970 31.68787608941396 115.01525448735114\n",
      "10 of 1970 34.64844627777735 113.12717762854365\n",
      "11 of 1970 37.15985237757365 110.24089565734069\n",
      "12 of 1970 39.74639852046967 108.03291955977126\n",
      "13 of 1970 42.186608795324965 105.79103455252627\n",
      "14 of 1970 45.94340363740921 106.92780273474871\n",
      "15 of 1970 50.278004316488904 109.15913402261117\n",
      "16 of 1970 53.567851305007935 108.97709767594105\n",
      "17 of 1970 56.163560422261554 107.48163737482105\n",
      "18 of 1970 60.29335115750631 108.91882247995447\n",
      "19 of 1970 63.76120665868123 109.0652220584391\n",
      "20 of 1970 67.24910357793172 109.22375263275372\n",
      "21 of 1970 70.68871550162633 109.28699840484157\n",
      "22 of 1970 75.02905186017354 110.6678516222371\n",
      "23 of 1970 77.2286230524381 108.90355126493219\n",
      "24 of 1970 79.55743192036947 107.4577814536266\n",
      "25 of 1970 82.61096553405126 107.06381144984827\n",
      "26 of 1970 85.29611361424128 106.23740316490586\n",
      "27 of 1970 87.72060850858688 105.15643355766687\n",
      "28 of 1970 92.24637559254964 106.57750904400672\n",
      "29 of 1970 94.71908631722133 105.60633771062584\n",
      "30 of 1970 97.70332435766856 105.24819228118659\n",
      "31 of 1970 99.93661153316498 104.1275017766414\n",
      "32 of 1970 102.59206348260244 103.50043079921768\n",
      "33 of 1970 105.62343157927195 103.27624428815311\n",
      "34 of 1970 109.70898938179016 104.06220334022848\n",
      "35 of 1970 112.4262344678243 103.53920840574446\n",
      "36 of 1970 114.98478355407715 102.90073461227212\n",
      "37 of 1970 118.43584220409393 103.07119248025947\n",
      "38 of 1970 123.16824587583542 104.31486095819383\n",
      "39 of 1970 126.32153016328812 104.18827067646885\n",
      "40 of 1970 129.94948277076085 104.44689685312079\n",
      "41 of 1970 133.5613343199094 104.67733851071294\n",
      "42 of 1970 136.784729830424 104.59689466594232\n",
      "43 of 1970 140.0139169216156 104.52201711268388\n",
      "44 of 1970 142.2661363085111 103.73572445786661\n",
      "45 of 1970 144.76655495166779 103.15957477560455\n",
      "46 of 1970 148.8584550579389 103.7155105926766\n",
      "47 of 1970 152.09245100418727 103.660174117876\n",
      "48 of 1970 155.64001274903615 103.81405027607249\n",
      "49 of 1970 159.1101973573367 103.90870046510989\n",
      "50 of 1970 163.08436454137166 104.31963190454509\n",
      "51 of 1970 166.3454826394717 104.2649136875164\n",
      "52 of 1970 170.47932131290435 104.74642922079715\n",
      "53 of 1970 172.78359030882518 104.10482992914487\n",
      "54 of 1970 175.83625299533207 103.9279089066791\n",
      "55 of 1970 178.98387345075608 103.81064665642049\n",
      "56 of 1970 181.95566097100576 103.59558920155797\n",
      "57 of 1970 184.3748285929362 103.07738960310729\n",
      "58 of 1970 188.10245819091796 103.29419476305273\n",
      "59 of 1970 191.22525576353073 103.1752086605258\n",
      "60 of 1970 196.50983680884045 104.2047996603946\n",
      "61 of 1970 199.31016422510146 103.9026758443267\n"
     ]
    }
   ],
   "source": [
    "st = ti()\n",
    "\n",
    "for i in range(SetsNeeded-1):\n",
    "    PercentHoldOutForNext = 1.0 - (SamplesPerSet / len(MoveSegments))\n",
    "    seq_train, seq_test, out_train, out_test = train_test_split(MoveSegments, NextDataPoint, test_size=PercentHoldOutForNext, shuffle=True, random_state=0)\n",
    "    seq_train = np.asarray(seq_train)\n",
    "    out_train = np.asarray(out_train)\n",
    "    if i == 0:\n",
    "        vb = 1\n",
    "    else:\n",
    "        vb = 0\n",
    "    lstm_autoencoder2.model.fit(seq_train, out_train, epochs=2, batch_size=32, verbose=vb)\n",
    "    MoveSegments = seq_test\n",
    "    NextDataPoint = out_test\n",
    "    print(str(i+1)+' of ' + str(SetsNeeded), (ti()-st)/60, (((ti()-st)/(i+1) * ( SetsNeeded -1) - (ti()-st) )/60/60))\n",
    "\n",
    "\n",
    "lstm_autoencoder2.model.save(\"LSTM_predict_full_500p25\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "178f6c3502586c94dc93af50f98dbd15c5205250cbf2345a6eb57380f8c77d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
