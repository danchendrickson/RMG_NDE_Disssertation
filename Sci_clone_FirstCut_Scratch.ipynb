{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    " \n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics as km\n",
    "  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "SensorPositonFile = 'D:\\\\SensorStatsSmall.csv'\n",
    "folder = 'D:\\\\CraneData\\\\'\n",
    "SaveModelFolder = 'D:\\\\SavedModel\\\\'\n",
    "\n",
    "img_height , img_width = 3, 100\n",
    "FrameLength = img_width\n",
    "numberFrames = 600\n",
    "NumberOfFiles = 250\n",
    "DataSmoothing = 1 # 0 = none, 1 = rolling average, 2 = rolling StdDev\n",
    "num_cores = multiprocessing.cpu_count() -1\n",
    "\n",
    "OutputVectors = np.genfromtxt(open(SensorPositonFile,'r'), delimiter=',',skip_header=1,dtype=int, missing_values=0)\n",
    "\n",
    "\n",
    "def truthVector(Filename):\n",
    "    # Parses the filename, and compares it against the record of sensor position on cranes\n",
    "    # inputs: filename\n",
    "    # outputs: truth vector\n",
    "\n",
    "\n",
    "    #Parsing the file name.  Assuming it is in the standard format\n",
    "    sSensor = Filename[23]\n",
    "    sDate = datetime.datetime.strptime('20'+Filename[10:21],\"%Y%m%d-%H%M\")\n",
    "\n",
    "    mask = []\n",
    "\n",
    "    i=0\n",
    "    #loops through the known sensor movements, and creates a filter mask\n",
    "    for spf in OutputVectors:\n",
    "        \n",
    "        startDate = datetime.datetime.strptime(str(spf[0])+str(spf[1]).zfill(2)+str(spf[2]).zfill(2)\n",
    "            +str(spf[3]).zfill(2)+str(spf[4]).zfill(2),\"%Y%m%d%H%M\")\n",
    "        #datetime.date(int(spf[0]), int(spf[1]), int(spf[2])) + datetime.timedelta(hours=spf[3]) + datetime.timedelta(minutes=spf[4])\n",
    "        endDate = datetime.datetime.strptime(str(spf[5])+str(spf[6]).zfill(2)+str(spf[7]).zfill(2)\n",
    "            +str(spf[8]).zfill(2)+str(spf[9]).zfill(2),\"%Y%m%d%H%M\")\n",
    "        #datetime.date(int(spf[5]), int(spf[6]), int(spf[7])) + datetime.timedelta(hours=spf[8]) + datetime.timedelta(minutes=spf[9])\n",
    "        \n",
    "        if sDate >= startDate and sDate <= endDate and int(spf[10]) == int(sSensor):\n",
    "            mask.append(True)\n",
    "            i+=1\n",
    "        else:\n",
    "            mask.append(False)\n",
    "        \n",
    "    if i != 1: print('error ', i, Filename)\n",
    "\n",
    "    results = OutputVectors[mask,11:]\n",
    "\n",
    "    if i > 1: \n",
    "        print('Found Two ', Filename)\n",
    "        results = results[0,:]\n",
    "    #np.array(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "def makeFrames(input): #,sequ,frameLength):\n",
    "    frames=[] #np.array([],dtype=object,)\n",
    "    segmentGap = int((np.shape(input)[0]-FrameLength)/numberFrames)\n",
    "    #print(segmentGap,sequ, frameLength)\n",
    "    for i in range(numberFrames):\n",
    "        start = i * segmentGap\n",
    "        imageMatrix = input[start:start+FrameLength,:]\n",
    "        np.matrix(imageMatrix)\n",
    "        imageMatrix = imageMatrix.T\n",
    "        frames.append(imageMatrix)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def Smoothing(RawData, SmoothType = 1, SmoothDistance=15):\n",
    "\n",
    "    if SmoothType == 0:\n",
    "        SmoothedData = RawData\n",
    "    elif SmoothType ==1:\n",
    "        SmoothedData = RawData\n",
    "        for i in range(SmoothDistance-1):\n",
    "            for j in range(3):\n",
    "                SmoothedData[j,i+1]=np.average(RawData[j,0:i+1])\n",
    "        for i in range(np.shape(RawData)[0]-SmoothDistance):\n",
    "            for j in range(3):\n",
    "                SmoothedData[j,i+SmoothDistance]=np.average(RawData[j,i:i+SmoothDistance])\n",
    "\n",
    "\n",
    "    return SmoothedData\n",
    "\n",
    "def ParseFile(Filename):\n",
    "\n",
    "    print(Filename)\n",
    "    Results = truthVector(Filename)\n",
    "    \n",
    "    fileData = np.genfromtxt(open(folder+Filename,'r'), delimiter=',',skip_header=0,missing_values=0).T[2:5,:]\n",
    "\n",
    "    print('Have Data', Filename)\n",
    "\n",
    "    smoothData = Smoothing(fileData)\n",
    "\n",
    "    print('Data Smoothed',Filename)\n",
    "\n",
    "    frames = makeFrames(smoothData.T) #,numberFrames,img_width)\n",
    "    frames = np.asarray(frames)\n",
    "    \n",
    "    return frames, Results\n",
    "\n",
    "\n",
    "files = os.listdir(folder)\n",
    "files = random.sample(files,NumberOfFiles)\n",
    "\n",
    "print('Sample Created')\n",
    "\n",
    "DataSet = [] \n",
    "\n",
    "ResultsSet = np.zeros((len(files),np.shape(OutputVectors[:,11:])[1]))\n",
    "\n",
    "\n",
    "Data = Parallel(n_jobs=num_cores)(delayed(ParseFile)(file) for file in files)\n",
    "#Data = []\n",
    "#for file in files:\n",
    "#    Data.append(ParseFile(file))\n",
    "\n",
    "DataSet = [] \n",
    "i=0\n",
    "for datum in Data:\n",
    "    DataSet.append(datum[0])\n",
    "    ResultsSet[i]=datum[1][0]\n",
    "    i+=1\n",
    "\n",
    "DataSet = np.asarray(DataSet)\n",
    "\n",
    "print('Data Parsed')\n",
    "\n",
    "\n",
    "#ResultsSet = ResultsSet[0:np.shape(DataSet)[0],:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(DataSet, ResultsSet, test_size=0.20, shuffle=True, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, \n",
    "            kernel_size = (3, 3), \n",
    "            return_sequences = False, \n",
    "            data_format = \"channels_last\", \n",
    "            input_shape = (numberFrames, img_height, img_width, 1)\n",
    "            )\n",
    "        )\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(np.shape(y_train)[1], activation = \"softmax\"))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "earlystop = EarlyStopping(patience=7)   \n",
    "callbacks = [earlystop]\n",
    "\n",
    "history = model.fit(x = X_train, y = y_train, epochs=40, batch_size = 8 , shuffle=False, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "model.save(SaveModelFolder)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('D:\\\\ModelAccuracy.png')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('D:\\\\ModelLoss.png')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c81fa076aeee1253ea90d918e51bf8233268ffae4e578373f00cbeda6d65c3b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
