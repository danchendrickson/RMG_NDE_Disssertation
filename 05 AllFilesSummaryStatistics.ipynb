{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ASC Accelerometer analysis via Summary Statistics \r\n",
    "\r\n",
    "FDeveloping moving average acceleration and moving Standard Deviation for each data set.\r\n",
    "\r\n",
    "Can run through a whole folder, or through random selections from the folder\r\n",
    "\r\n",
    "Currently brute Force Method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#Standard Header used on the projects\r\n",
    "\r\n",
    "#first the major packages used for math and graphing\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from cycler import cycler\r\n",
    "import scipy.special as sp\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "#Custome graph format style sheet\r\n",
    "plt.style.use('Prospectus.mplstyle')\r\n",
    "\r\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\r\n",
    "#otherwise set what is needed\r\n",
    "if not 'Saving' in locals():\r\n",
    "    Saving = False\r\n",
    "if not 'Titles' in locals():\r\n",
    "    Titles = True\r\n",
    "if not 'Ledgends' in locals():\r\n",
    "    Ledgends = True\r\n",
    "if not 'FFormat' in locals():\r\n",
    "    FFormat = '.png'\r\n",
    "if not 'location' in locals():\r\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\r\n",
    "    #location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\Prospectus\\\\Document\\\\Figures\\\\'\r\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\r\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Phd\\\\Play\\\\'\r\n",
    "\r\n",
    "#Standard cycle for collors and line styles\r\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\r\n",
    "plt.rc('axes', prop_cycle=default_cycler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Extra Headers:\r\n",
    "import DWFT as fp\r\n",
    "import os as os\r\n",
    "import pywt as py\r\n",
    "import statistics as st\r\n",
    "import os as os\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "import multiprocessing\r\n",
    "from joblib import Parallel, delayed\r\n",
    "from pywt._extensions._pywt import (DiscreteContinuousWavelet, ContinuousWavelet,\r\n",
    "                                Wavelet, _check_dtype)\r\n",
    "from pywt._functions import integrate_wavelet, scale2frequency\r\n",
    "import time\r\n",
    "\r\n",
    "my_cmap = plt.get_cmap('gray')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#DataSet = np.genfromtxt(open('./Data/Jeep SD 10.txt','r'), delimiter=',',skip_header=4)\r\n",
    "Header = np.array(['T', 'X','Y','Z','R','Theta','Phi'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "def getAcceleration(FileName):\r\n",
    "    try:\r\n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\r\n",
    "        if FileName[64:69] == 'Accel':\r\n",
    "            return [[FileName[61:],'x',DataSet[:,2]],[FileName[61:],'y',DataSet[:,3]],[FileName[61:],'z',DataSet[:,4]]]\r\n",
    "        else:\r\n",
    "            return [False,FileName,False]\r\n",
    "    except:\r\n",
    "        return [False,FileName,False]\r\n",
    "\r\n",
    "\r\n",
    "def makeStats(DataArray):\r\n",
    "    try:\r\n",
    "        Arange = 50\r\n",
    "        length = np.shape(DataArray[2])[0]\r\n",
    "        StdDev = np.zeros(length)\r\n",
    "        for j in range(length-Arange):\r\n",
    "            k = (length-1)-j\r\n",
    "            DataArray[2][k] = np.average(DataArray[2][k-Arange:k])\r\n",
    "            StdDev[k]=st.stdev(DataArray[2][k-Arange:k])\r\n",
    "        return [DataArray[0],DataArray[1],max(DataArray[2]),max(StdDev)]\r\n",
    "    except:\r\n",
    "        return ['','','','']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "num_cores = multiprocessing.cpu_count()\r\n",
    "folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\r\n",
    "folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\r\n",
    "\r\n",
    "files = os.listdir(folder2)\r\n",
    "\r\n",
    "GroupSize = 100\r\n",
    "if np.shape(files)[0] < GroupSize:\r\n",
    "    GroupSize = np.shape(files)[0]\r\n",
    "\r\n",
    "Groups = 0\r\n",
    "\r\n",
    "if Groups !=0:\r\n",
    "    files = random.sample(files,GroupSize*Groups-1)\r\n",
    "\r\n",
    "loops = int(float(np.size(files))/float(GroupSize))+1\r\n",
    "\r\n",
    "start = time.time()\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    AllEvents=[]\r\n",
    "    Fails = []\r\n",
    "    for i in range(loops):\r\n",
    "        \r\n",
    "        AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder2+file) for file in files[i*GroupSize:((i+1)*GroupSize)])\r\n",
    "        Flattened = []\r\n",
    "        for j in range(np.shape(AllAccels)[0]):\r\n",
    "            if AllAccels[j][0] == False :\r\n",
    "                if AllAccels[j][1][4:9] =='Accel':\r\n",
    "                    print(j,AllAccels[j][1])\r\n",
    "            else: \r\n",
    "                for k in range(3):\r\n",
    "                    Flattened.append(AllAccels[j][k])\r\n",
    "        Events =  Parallel(n_jobs=num_cores)(delayed(makeStats)(DataArrays) for DataArrays in Flattened)\r\n",
    "        Events = np.matrix(Events)\r\n",
    "        if AllEvents ==[]:\r\n",
    "            AllEvents=Events\r\n",
    "        else:\r\n",
    "            try:\r\n",
    "                AllEvents=np.concatenate((AllEvents,Events), axis=0)\r\n",
    "            except:\r\n",
    "                Fails.append(Events)\r\n",
    "        print(str(i+1)+' of '+str(loops),'Time: '+ str((time.time()-start)/60.0))\r\n",
    "    \r\n",
    "    df = pd.DataFrame(data=AllEvents)\r\n",
    "    df.to_csv(folder1 + 'StatisticsReport.csv', sep=',', index = False, header=False,quotechar='\"')\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 of 106 Time: 12.736191813151041\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-72-ed63557f2cf0>:36: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if AllEvents ==[]:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 of 106 Time: 25.564891465504964\n",
      "3 of 106 Time: 38.24235859711965\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "df = pd.DataFrame(data=AllEvents)\r\n",
    "df.to_csv(folder1 + 'StatisticsReport.csv', sep=',', index = False, header=False,quotechar='\"')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}