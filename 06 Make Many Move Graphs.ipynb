{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "import pandas as pd\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = True\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "Computer = \"SciClone\"   # \"SciClone\"    \"WinLap\"  \"LinLap\"   \"Desktop\"  \"PortLap\"\n",
    "\n",
    "#Standard cycle for collors and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "PlotWidthIn = 11\n",
    "PlotHeightIn = 3.75\n",
    "PlotDPI = 120\n",
    "\n",
    "Groups = 1\n",
    "GroupSize = 15\n",
    "\n",
    "\n",
    "RollingSize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import pywt\n",
    "from pywt._extensions._pywt import (DiscreteContinuousWavelet, ContinuousWavelet,\n",
    "                                Wavelet, _check_dtype)\n",
    "from pywt._functions import integrate_wavelet, scale2frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'\n",
    "    \n",
    "\n",
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/sciclone/scr10/dchendrickson01/CraneData/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"SmallCopy\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"SmallCopy\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'SmallCopy/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'SmallCopy\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import statistics as st\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns names for a file with all 6 dimmensions\n",
    "Header = np.array(['t', 's','x','y','z','s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(data_in, wvt='sym2', dets_to_remove=5, levels=None):\n",
    "    '''\n",
    "    Function to filter out high frequency noise from a data signal. Usually \n",
    "    perform this before running the DWFT on the signal.\n",
    "    \n",
    "    data_in: input signal\n",
    "    \n",
    "    wvt: mother wavelet\n",
    "\n",
    "    levels: number of levels to take in transformation\n",
    "\n",
    "    dets_to_remove: details to remove in filter\n",
    "    '''\n",
    "    # vector needs to have an even length, so just zero pad if length is odd.\n",
    "    if len(data_in) % 2 != 0:\n",
    "        data_in = np.append(data_in, 0)\n",
    "    \n",
    "    coeffs = pywt.swt(data_in, wvt, level=levels)\n",
    "    \n",
    "    if levels is None:\n",
    "        levels = len(coeffs)\n",
    "    \n",
    "    for i in range(dets_to_remove):\n",
    "        dets = np.asarray(coeffs[(levels-1)-i][1])\n",
    "        dets[:] = 0\n",
    "    \n",
    "    filtered_signal = pywt.iswt(coeffs,wvt)\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primelist(upper):\n",
    "    result=[]\n",
    "    for cp in range(2,upper+1):\n",
    "        for i in range(2,cp):\n",
    "            if cp%i ==0:\n",
    "                break\n",
    "        else:\n",
    "            result.append(cp)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwt_fixed(data, scales, wavelet, scalespace =1, sampling_period=1.):\n",
    "    \"\"\"\n",
    "    COPIED AND FIXED FROM pywt.cwt TO BE ABLE TO USE WAVELET FAMILIES SUCH\n",
    "    AS COIF AND DB\n",
    "\n",
    "    COPIED From Spenser Kirn\n",
    "    \n",
    "    All wavelet work except bior family, rbio family, haar, and db1.\n",
    "    \n",
    "    cwt(data, scales, wavelet)\n",
    "\n",
    "    One dimensional Continuous Wavelet Transform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Input signal\n",
    "    scales : array_like\n",
    "        scales to use\n",
    "    wavelet : Wavelet object or name\n",
    "        Wavelet to use\n",
    "    sampling_period : float\n",
    "        Sampling period for frequencies output (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coefs : array_like\n",
    "        Continous wavelet transform of the input signal for the given scales\n",
    "        and wavelet\n",
    "    frequencies : array_like\n",
    "        if the unit of sampling period are seconds and given, than frequencies\n",
    "        are in hertz. Otherwise Sampling period of 1 is assumed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Size of coefficients arrays depends on the length of the input array and\n",
    "    the length of given scales.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pywt\n",
    "    >>> import numpy as np\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> x = np.arange(512)\n",
    "    >>> y = np.sin(2*np.pi*x/32)\n",
    "    >>> coef, freqs=pywt.cwt(y,np.arange(1,129),'gaus1')\n",
    "    >>> plt.matshow(coef) # doctest: +SKIP\n",
    "    >>> plt.show() # doctest: +SKIP\n",
    "    ----------\n",
    "    >>> import pywt\n",
    "    >>> import numpy as np\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "    >>> sig  = np.cos(2 * np.pi * 7 * t) + np.real(np.exp(-7*(t-0.4)**2)*np.exp(1j*2*np.pi*2*(t-0.4)))\n",
    "    >>> widths = np.arange(1, 31)\n",
    "    >>> cwtmatr, freqs = pywt.cwt(sig, widths, 'mexh')\n",
    "    >>> plt.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "    ...            vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "    >>> plt.show() # doctest: +SKIP\n",
    "    \"\"\"\n",
    "    \n",
    "    scales = get_primelist(10000)\n",
    "    \n",
    "    # accept array_like input; make a copy to ensure a contiguous array\n",
    "    dt = _check_dtype(data)\n",
    "    data = np.array(data, dtype=dt)\n",
    "    if not isinstance(wavelet, (ContinuousWavelet, Wavelet)):\n",
    "        wavelet = DiscreteContinuousWavelet(wavelet)\n",
    "    if np.isscalar(scales):\n",
    "        scales = np.r_[1:scales+1] * scalespace\n",
    "    if data.ndim == 1:\n",
    "        try:\n",
    "            if wavelet.complex_cwt:\n",
    "                out = np.zeros((np.size(scales), data.size), dtype=complex)\n",
    "            else:\n",
    "                out = np.zeros((np.size(scales), data.size))\n",
    "        except AttributeError:\n",
    "            out = np.zeros((np.size(scales), data.size))\n",
    "        precision = 10\n",
    "        int_psi, x = integrate_wavelet(wavelet, precision=precision)\n",
    "        step = x[1] - x[0]\n",
    "        for i in np.arange(np.size(scales)):\n",
    "            j = np.floor(\n",
    "                np.arange(scales[i] * (x[-1] - x[0]) + 1) / (scales[i] * step))\n",
    "            if np.max(j) >= np.size(int_psi):\n",
    "                j = np.delete(j, np.where((j >= np.size(int_psi)))[0])\n",
    "            coef = - np.sqrt(scales[i]) * np.diff(np.convolve(data, int_psi[j.astype(int)][::-1]))\n",
    "            d = (coef.size - data.size) / 2.\n",
    "            out[i, :] = coef[int(np.floor(d)):int(-np.ceil(d))]\n",
    "        #frequencies = scale2frequency(wavelet, scales, precision)\n",
    "        #if np.isscalar(frequencies):\n",
    "        #    frequencies = np.array([frequencies])\n",
    "        #for i in np.arange(len(frequencies)):\n",
    "        #    frequencies[i] /= sampling_period\n",
    "        return out\n",
    "    else:\n",
    "        raise ValueError(\"Only dim == 1 supported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaveletToUse = 'gaus2'\n",
    "#scales = np.linspace(0,2000,1001, dtype=int)\n",
    "scales = 500\n",
    "spacer = 10\n",
    "    \n",
    "\n",
    "\n",
    "def getThumbprint(data, wvt=WaveletToUse, ns=scales, scalespace = spacer, numslices=5, slicethickness=0.12, \n",
    "                  valleysorpeaks='both', normconstant=1, plot=False):\n",
    "    '''\n",
    "    Updated version of the DWFT function above that allows plotting of just\n",
    "    valleys or just peaks or both. To plot just valleys set valleysorpeaks='valleys'\n",
    "    to plot just peaks set valleysorpeaks='peaks' or 'both' to plot both.\n",
    "    '''\n",
    "    # First take the wavelet transform and then normalize to one\n",
    "    if np.shape(data)[0] == 2:\n",
    "        wvt = data[1]\n",
    "        data = data[0]\n",
    "    \n",
    "    try:\n",
    "        cfX = cwt_fixed(data, ns, wvt,scalespace)\n",
    "        cfX = np.true_divide(cfX, abs(cfX).max()*normconstant)\n",
    "        \n",
    "        ns = np.shape(cfX)[0]\n",
    "        \n",
    "        fp = np.zeros((len(data), ns), dtype=int)\n",
    "\n",
    "        # Create the list of locations between -1 and 1 to preform slices. Valley\n",
    "        # slices will all be below 0 and peak slices will all be above 0.\n",
    "        if valleysorpeaks == 'both':\n",
    "            slicelocations1 = np.arange(-1 ,0.0/numslices, 1.0/numslices)\n",
    "            slicelocations2 = np.arange(1.0/numslices, 1+1.0/numslices, 1.0/numslices)\n",
    "            slicelocations = np.array(np.append(slicelocations1,slicelocations2))\n",
    "\n",
    "        if valleysorpeaks == 'peaks':\n",
    "            slicelocations = np.arange(1.0/numslices, 1+1.0/numslices, 1.0/numslices)\n",
    "\n",
    "        if valleysorpeaks == 'valleys':\n",
    "            slicelocations = np.arange(-1, 0.0/numslices, 1.0/numslices)\n",
    "\n",
    "        for loc in slicelocations:\n",
    "            for y in range(0, ns):\n",
    "                for x in range(0, len(data)):\n",
    "                    if cfX[y, x]>=(loc-(slicethickness/2)) and cfX[y,x]<= (loc+(slicethickness/2)):\n",
    "                        fp[x,y] = 1\n",
    "\n",
    "        fp = np.transpose(fp[:,:ns])\n",
    "    except:\n",
    "        fp = 'fail'\n",
    "    \n",
    "    return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getThumbprint2(data, wvt=WaveletToUse, ns=scales, scalespace = spacer, numslices=5, slicethickness=0.12, \n",
    "                  valleysorpeaks='both', normconstant=1, plot=False):\n",
    "    '''Attempt to speed code where the comparisons happen too many times too slowly\n",
    "    '''\n",
    "    \n",
    "        # First take the wavelet transform and then normalize to one\n",
    "    if np.shape(data)[0] == 2:\n",
    "        wvt = data[1]\n",
    "        data = data[0]\n",
    "    \n",
    "    #try:\n",
    "    cfX = cwt_fixed(data, ns, wvt,scalespace)\n",
    "\n",
    "    fp = np.zeros((len(data), ns), dtype=int)\n",
    "\n",
    "    minVal = min(cfX)\n",
    "    maxVal = max(cfX)\n",
    "    rangeVal = maxVal - minVal#\n",
    "\n",
    "    cfX -= minVal\n",
    "    cfX /= rangeVal\n",
    "\n",
    "    cfX *= float(numslices +1)\n",
    "    \n",
    "    cfX += 0.5\n",
    "\n",
    "    cfX = int(cfX)\n",
    "\n",
    "    cfX = np.mod(cfX, 2)\n",
    "\n",
    "\n",
    "    rangeScale = rangeVal / numslices\n",
    "\n",
    "    fp = np.transpose(fp[:,:ns])\n",
    "    #except:\n",
    "    \n",
    "    #fp = 'fail'\n",
    "    \n",
    "    return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScalesOnly(data, wvt=WaveletToUse, ns=scales, scalespace = spacer, numslices=5, slicethickness=0.12, \n",
    "                  valleysorpeaks='both', normconstant=1, plot=False):\n",
    "    '''Attempt to speed code where the comparisons happen too many times too slowly\n",
    "    '''\n",
    "    if np.shape(data)[0] == 2:\n",
    "        wvt = data[1]\n",
    "        data = data[0]\n",
    "    \n",
    "    #try:\n",
    "    cfX = cwt_fixed(data, ns, wvt,scalespace)\n",
    "\n",
    "    return cfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotFingerPrint(Input):\n",
    "    \n",
    "    #FpScat=fp.getLabeledThumbprint(data, FP,scales,slices)\n",
    "    #print(np.shape(data)[1], scales)\n",
    "\n",
    "    \n",
    "    data = Input[0]\n",
    "    title = Input[1]\n",
    "    \n",
    "    scales = np.shape(data)[0]\n",
    "    trim=0\n",
    "    slices = 3\n",
    "    Show = False\n",
    "    \n",
    "    xName = np.arange(0,np.shape(data)[1]-2*trim,1)\n",
    "    \n",
    "    if trim == 0:\n",
    "        Al,Ms  = np.meshgrid(xName,np.linspace(1,scales,scales))\n",
    "    else:\n",
    "        Al,Ms  = np.meshgrid(xName,np.linspace(1,scales,scales))\n",
    "\n",
    "    \n",
    "\n",
    "    fig1 = plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "    ax1 = plt.axes()\n",
    "    if trim == 0:\n",
    "        cs1 = ax1.contourf(Al,Ms, data[:,:],cmap=my_cmap,levels=slices)\n",
    "    else:\n",
    "        cs1 = ax1.contourf(Al,Ms, data[:,trim:-trim],cmap=my_cmap,levels=slices)\n",
    "\n",
    "    if Titles: plt.title(title)\n",
    "    if Saving: plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\").replace(\".txt\",\"\")+FFormat)\n",
    "\n",
    "    if Show: plt.show()\n",
    "    else: plt.close()\n",
    "        \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotColorScales(Input):\n",
    "    \n",
    "    #FpScat=fp.getLabeledThumbprint(data, FP,scales,slices)\n",
    "    #print(np.shape(data)[1], scales)\n",
    "\n",
    "    \n",
    "    data = Input[0]\n",
    "    title = Input[1]\n",
    "    \n",
    "    scales = np.shape(data)[0]\n",
    "    trim=0\n",
    "    #slices = 3\n",
    "    Show = False\n",
    "    \n",
    "    xName = np.arange(0,np.shape(data)[1]-2*trim,1)\n",
    "    \n",
    "    if trim == 0:\n",
    "        Al,Ms  = np.meshgrid(xName,np.linspace(1,scales,scales))\n",
    "    else:\n",
    "        Al,Ms  = np.meshgrid(xName,np.linspace(1,scales,scales))\n",
    "\n",
    "    \n",
    "\n",
    "    fig1 = plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "    ax1 = plt.axes()\n",
    "    if trim == 0:\n",
    "        cs1 = ax1.contourf(Al,Ms, data[:,:],cmap='jet',levels=256)\n",
    "    else:\n",
    "        cs1 = ax1.contourf(Al,Ms, data[:,trim:-trim],cmap='jet',levels=256)\n",
    "\n",
    "    if Titles: plt.title(title)\n",
    "    if Saving: plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\").replace(\".txt\",\"\")+FFormat)\n",
    "\n",
    "    if Show: plt.show()\n",
    "    else: plt.close()\n",
    "        \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opens all files in a folder and returns the 3 axis acceleration in one array\n",
    "# made to run in parallel\n",
    "\n",
    "def getAcceleration(FileName):\n",
    "    \n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\n",
    "        JustFileName = FileName.rsplit('/', 1)[-1]\n",
    "        if FileName[-20:-16] == 'Gyro':\n",
    "            return [False,FileName,False]\n",
    "        else:\n",
    "            if FileName[-6:-5] == 's':\n",
    "                FileDate = FileName[-18:-7]\n",
    "                sensor = FileName[-5:-4]\n",
    "            elif FileName[-21:-16] == 'Accel':\n",
    "                FileDate = FileName[-15:-4]\n",
    "                sensor = 1\n",
    "            else:\n",
    "                FileDate = FileName[-20:-4]\n",
    "                sensor = 1\n",
    "            return [[FileDate, 'x',DataSet[:,2], sensor,JustFileName],[FileDate,'y',DataSet[:,3],sensor,JustFileName],[FileDate,'z',DataSet[:,4],sensor,JustFileName]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KalmanFilterDenoise(data, rate=1):\n",
    "\n",
    "    #https://jamwheeler.com/college-productivity/how-to-denoise-a-1-d-signal-with-a-kalman-filter-with-python/\n",
    "    #\n",
    "\n",
    "    def oavar(data, rate, numpoints=30):\n",
    "\n",
    "        x = np.cumsum(data)\n",
    "\n",
    "        max_ratio = 1/9\n",
    "        num_points = 30\n",
    "        ms = np.unique(\n",
    "            np.logspace(0, np.log10(len(x) * max_ratio), numpoints\n",
    "           ).astype(int))        \n",
    "\n",
    "        oavars = np.empty(len(ms))\n",
    "        for i, m in enumerate(ms):\n",
    "            oavars[i] = (\n",
    "                (x[2*m:] - 2*x[m:-m] + x[:-2*m])**2\n",
    "            ).mean() / (2*m**2)\n",
    "\n",
    "        return ms / rate, oavars\n",
    "\n",
    "    def ln_NKfit(ln_tau, ln_N, ln_K):\n",
    "        tau = np.exp(ln_tau)\n",
    "        N, K = np.exp([ln_N, ln_K])\n",
    "        oadev = N**2 / tau + K**2 * (tau/3)\n",
    "        return np.log(oadev)\n",
    "\n",
    "    def get_NK(data, rate):\n",
    "        taus, oavars = oavar(data, rate)\n",
    "\n",
    "        ln_params, ln_varmatrix = (\n",
    "            curve_fit(ln_NKfit, np.log(taus), np.log(oavars))\n",
    "        )\n",
    "        return np.exp(ln_params)    \n",
    "\n",
    "    # Initialize state and uncertainty\n",
    "    state = data[0]\n",
    "    output = np.empty(len(data))\n",
    "\n",
    "    #rate = 1 # We can set this to 1, if we're calculating N, K internally\n",
    "    # N and K will just be scaled relative to the sampling rate internally\n",
    "    dt = 1/rate\n",
    "\n",
    "    N, K = get_NK(data, rate)\n",
    "\n",
    "    process_noise = K**2 * dt\n",
    "    measurement_noise = N**2 / dt\n",
    "\n",
    "    covariance = measurement_noise\n",
    "\n",
    "    for index, measurement in enumerate(data):\n",
    "        # 1. Predict state using system's model\n",
    "\n",
    "        covariance += process_noise\n",
    "\n",
    "        # Update\n",
    "        kalman_gain = covariance / (covariance + measurement_noise)\n",
    "\n",
    "        state += kalman_gain * (measurement - state)\n",
    "        covariance = (1 - kalman_gain) * covariance\n",
    "\n",
    "        output[index] = state\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs:\n",
    "#folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\n",
    "#folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\n",
    "#folder = \"E:\\\\Documents\\\\Dan\\\\Port Work\\\\OneDrive\\OneDrive - The Port of Virginia\\\\Shared with Everyone\\\\Crane Data\\\\\"\n",
    "#folder = \"C:\\\\Users\\\\Dan\\\\Desktop\\\\TempData\\\\\"\n",
    "\n",
    "\n",
    "files = os.listdir(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Calculations\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()-1\n",
    "\n",
    "if np.shape(files)[0] < GroupSize:\n",
    "    GroupSize = np.shape(files)[0]\n",
    "\n",
    "if Groups !=0:\n",
    "    files = random.sample(files,GroupSize*Groups)\n",
    "\n",
    "loops = int(float(np.size(files))/float(GroupSize))+1\n",
    "start = time.time()\n",
    "\n",
    "inverseRollingSize = 1 / RollingSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllAccels = np.asarray([],dtype=object)\n",
    "for file in files:\n",
    "    print(file)\n",
    "    temp = getAcceleration(folder + file)\n",
    "    if np.size(AllAccels)==0:\n",
    "        AllAccels = temp\n",
    "    else:\n",
    "        AllAccels = np.concatenate((AllAccels,temp), axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder+file) for file in files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "MetaData = []  #np.asarray([],dtype=object)\n",
    "DataOnlyMatrix = np.asarray([],dtype=object)\n",
    "for j in range(np.shape(AllAccels)[0]):\n",
    "    if AllAccels[j][0] == False :\n",
    "        if AllAccels[j][1][4:9] =='Accel':\n",
    "            print(j,AllAccels[j][1])\n",
    "    else: \n",
    "        for k in range(3):\n",
    "            MetaData.append([AllAccels[j][k][0], AllAccels[j][k][1], AllAccels[j][k][3], AllAccels[j][k][4]])\n",
    "            if np.size(DataOnlyMatrix) == 0:\n",
    "                    DataOnlyMatrix =np.matrix(AllAccels[j][k][2])\n",
    "            else:\n",
    "                    DataOnlyMatrix = np.concatenate((DataOnlyMatrix,np.matrix(AllAccels[j][k][2])),axis=0)\n",
    "\n",
    "MetaData = np.matrix(MetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "waveFiltered = np.asarray([],dtype=object)\n",
    "waveFiltered = Parallel(n_jobs=num_cores)(delayed(low_pass_filter)(np.asarray(data).flatten()) for data in DataOnlyMatrix)\n",
    "waveFiltered = np.matrix(waveFiltered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length = np.shape(waveFiltered)[0]\n",
    "justifier = np.ones((length, np.shape(waveFiltered)[1]))\n",
    "average = np.zeros(length)\n",
    "for i in range(length):\n",
    "    average[i]= np.average(waveFiltered[i][:])\n",
    "justifier = justifier.T * average.T\n",
    "waveFiltered = waveFiltered - justifier.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    }
   ],
   "source": [
    "waveKalmaned = np.asarray([],dtype=object)\n",
    "waveKalmaned = Parallel(n_jobs=num_cores)(delayed(KalmanFilterDenoise)(np.asarray(data).flatten()) for data in DataOnlyMatrix)\n",
    "waveKalmaned = np.matrix(waveKalmaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.shape(waveKalmaned)[0]\n",
    "justifier = np.ones((length, np.shape(waveKalmaned)[1]))\n",
    "average = np.zeros(length)\n",
    "for i in range(length):\n",
    "    average[i]= np.average(waveKalmaned[i][:])\n",
    "justifier = justifier.T * average.T\n",
    "waveKalmaned = waveKalmaned - justifier.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataOnlyMatrix = np.matrix(DataOnlyMatrix)\n",
    "\n",
    "length = np.shape(DataOnlyMatrix)[1]\n",
    "halfLength = int(length / 2)\n",
    "\n",
    "Weights1 = np.zeros((halfLength,halfLength))\n",
    "Weights2 = np.zeros((halfLength,halfLength+RollingSize-1))\n",
    "\n",
    "for j in range(halfLength):\n",
    "    r = j+1\n",
    "\n",
    "    if r < RollingSize:\n",
    "        ir = 1/ r\n",
    "        for k in range(r):\n",
    "            Weights1[k,j] = ir\n",
    "    else:\n",
    "        for k in range(RollingSize):\n",
    "            Weights1[r-RollingSize+k, j] = inverseRollingSize\n",
    "    for k in range(RollingSize):\n",
    "        Weights2[j,j+k] = inverseRollingSize\n",
    "\n",
    "FirstBit = np.dot(DataOnlyMatrix[:,:halfLength], Weights1)\n",
    "Weights1 = []\n",
    "\n",
    "if length % 2 == 1: halfLength += 1\n",
    "Weights2=Weights2[:,:halfLength]\n",
    "SecondBit = np.dot(DataOnlyMatrix[:,halfLength:], Weights2)\n",
    "\n",
    "Weights2 = [] \n",
    "\n",
    "Weights3 = np.zeros((halfLength,halfLength))\n",
    "for j in range(RollingSize-1):\n",
    "    for k in range(RollingSize-j-1):\n",
    "        Weights3[halfLength-k-1,j] = inverseRollingSize\n",
    "\n",
    "SecondBit = SecondBit + np.dot(DataOnlyMatrix[:,halfLength:], Weights3)\n",
    "Weights3 = []\n",
    "\n",
    "Averages = np.concatenate((FirstBit, SecondBit), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=4\n",
    "s=0\n",
    "e=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length = np.shape(Averages)[0]\n",
    "justifier = np.ones((length, np.shape(Averages)[1]))\n",
    "average = np.zeros(length)\n",
    "for i in range(length):\n",
    "    average[i]= np.average(Averages[i,:])\n",
    "justifier = justifier.T * average.T\n",
    "Averages = Averages - justifier.T\n",
    "DataOnlyMatrix = DataOnlyMatrix - justifier.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "9\n",
      "12\n",
      "18\n",
      "27\n",
      "30\n",
      "36\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "maxes = np.amax(waveKalmaned[:,500:], axis = 1)\n",
    "mins = np.amin(waveKalmaned[:,500:], axis = 1)\n",
    "\n",
    "Keep = np.zeros(mins.size)\n",
    "for i in range(mins.size):\n",
    "    if i % 3 == 0:\n",
    "        if maxes[i] > 0.01 and mins[i] < -0.01:\n",
    "            Keep[i]=1\n",
    "            #Keep[i+1]=1\n",
    "            #Keep[i+2]=1\n",
    "            print(i)\n",
    "            \n",
    "\n",
    "Keep = np.array(Keep, dtype='bool')\n",
    "            \n",
    "waveKalmaned = waveKalmaned[Keep,:]\n",
    "MetaData = MetaData[Keep,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if e ==0: e = 60\n",
    "s=s*1000\n",
    "e=e*1000\n",
    "for j in range(np.shape(waveKalmaned)[0]):\n",
    "    if j %3 ==0:\n",
    "        fig = plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "        #plt.plot(DataOnlyMatrix[j,s:e].T)\n",
    "        #plt.plot(Averages[j,s:e].T)\n",
    "        #plt.plot(waveFiltered[j][s:e].T)\n",
    "        plt.plot(waveKalmaned[j][s:e].T)\n",
    "        title = str(MetaData[j,0]) + '  ' + str(MetaData[j,1])+ '    ' +str(j)\n",
    "        plt.title(title)\n",
    "        plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\")+FFormat)\n",
    "        plt.close(fig)\n",
    "\n",
    "#del DataOnlyMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([['220602-0353', 'x', '4', '60kPoints-220602-0353-s4.csv']],\n",
       "       dtype='<U28')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetaData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FPs = Parallel(n_jobs=num_cores)(delayed(getThumbprint)(motion) for motion in Averages)\n",
    "#del Averages\n",
    "\n",
    "#ToPlot=[]\n",
    "#for i in range(np.shape(FPs)[0]):\n",
    "#    if MetaData[i][1] == 'x':\n",
    "#        title = 'FP-'+MetaData[i][0]+'  ' + MetaData[i][1]+ '    ' +str(i)\n",
    "#        ToPlot.append([FPs[i], title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FPs = Parallel(n_jobs=num_cores)(delayed(PlotFingerPrint)(FP) for FP in ToPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "WvltFam = pywt.families()\n",
    "Wvlts = []\n",
    "for Fam in WvltFam:\n",
    "    temp = pywt.wavelist(Fam)\n",
    "    for wvlt in temp:\n",
    "        Wvlts.append(wvlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bestmove = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_838/2466737927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBestmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What movement? '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "Bestmove = input('What movement? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Wvlts = np.asarray(Wvlts)\n",
    "Wvlts = Wvlts.flatten()\n",
    "#AvgChoosen = np.asarray(Averages[int(Bestmove)]).flatten()\n",
    "#AvgChoosen = np.asarray(waveFiltered[int(Bestmove)]).flatten()\n",
    "AvgChoosen = np.asarray(waveKalmaned[int(Bestmove)]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = AvgChoosen\n",
    "wvt=WaveletToUse\n",
    "ns=scales\n",
    "scalespace = spacer\n",
    "numslices=5\n",
    "slicethickness=0.12\n",
    "valleysorpeaks='both'\n",
    "normconstant=1\n",
    "plot=False\n",
    "if np.shape(data)[0] == 2:\n",
    "    wvt = data[1]\n",
    "    data = data[0]\n",
    "#try:\n",
    "cfX, freqs = cwt_fixed(data, ns, wvt,scalespace)\n",
    "fp = np.zeros((len(data), ns), dtype=int)\n",
    "\n",
    "minVal = np.min(cfX)\n",
    "maxVal = np.max(cfX)\n",
    "rangeVal = maxVal - minVal#\n",
    "\n",
    "cfX -= minVal\n",
    "cfX /= rangeVal\n",
    "\n",
    "cfX *= float(numslices +1)\n",
    "cfX = cfX.astype(int)\n",
    "\n",
    "cfx = np.mod(cfX, 2)\n",
    "\n",
    "\n",
    "rangeScale = rangeVal / numslices\n",
    "\n",
    "fp = np.transpose(fp[:,:ns])\n",
    "H = getThumbprint2(AvgChoosen, 'gaus2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Allfingers = np.asarray([], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_838/1905438522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mAllFingers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetThumbprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAvgChoosen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwave\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWvlts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3-2021.11/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#AllFingers = Parallel(n_jobs=num_cores)(delayed(getThumbprint)([np.asarray(wave).flatten(), 'haar']) for wave in waveKalmaned)\n",
    "\n",
    "\n",
    "AllFingers = Parallel(n_jobs=num_cores)(delayed(getThumbprint)([AvgChoosen, wave]) for wave in Wvlts[0:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AllFingers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_838/2056962203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllFingers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mAllFingers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'fail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAllFingers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWvlts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AllFingers' is not defined"
     ]
    }
   ],
   "source": [
    "plots=[]\n",
    "i=0\n",
    "for j in range(np.shape(AllFingers)[0]):\n",
    "    if AllFingers[j] != 'fail':\n",
    "        plots.append([AllFingers[j], Wvlts[j]])\n",
    "    else:\n",
    "        print('fail',i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = Parallel(n_jobs=num_cores)(delayed(PlotFingerPrint)(FP) for FP in plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AllCWT = Parallel(n_jobs=num_cores)(delayed(getScalesOnly)([np.asarray(wave).flatten(), 'haar']) for wave in waveKalmaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(AllCWT[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(AllCWT[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots=[]\n",
    "#for j in range(np.shape(AllFingers)[0]):\n",
    "#    if AllFingers[j] != 'fail':\n",
    "#        k = PlotColorScales([AllCWT[j], str(MetaData[j,0]) + '  ' + str(MetaData[j,1]) + ' with haar 500x10 full collor'])\n",
    "#    else:\n",
    "#        print('fail',i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for j in range(np.shape(AllFingers)[0]):\n",
    "    if j % 3 ==0:\n",
    "            fig=plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "            plt.plot(AllCWT[j][200,:], label = 'Scale 200')\n",
    "            plt.plot(AllCWT[j][300,:], label = 'Scale 300')\n",
    "            title = 'CWT Scale for Cut ' + str(MetaData[j,0]) + '  ' + str(MetaData[j,1]) \n",
    "            plt.title(title)\n",
    "            plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\")+FFormat)\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SegmentMove(movement, CheckRange = 750):\n",
    "    \n",
    "    DataLength = np.size(movement)\n",
    "    Segments = np.zeros(DataLength)\n",
    "\n",
    "    for i in range(DataLength):\n",
    "        if i < 100:\n",
    "            cval = 0\n",
    "        elif i<CheckRange:\n",
    "            cval = sum(movement[0:i])\n",
    "        else:\n",
    "            cval = sum(movement[i-CheckRange:i+CheckRange])\n",
    "        if cval > 50:\n",
    "                Segments[i]=2\n",
    "    return Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j in range(np.shape(AllFingers)[0]):\n",
    "#    if j % 3 ==0:\n",
    "#            fig=plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "#            plt.plot(SegmentMove(AllFingers[j][400,:]), label = 'Segment at Scale 400')\n",
    "#            #plt.plot(AllFingers[j][200,:], label = 'Scale 200')\n",
    "#            plt.plot(AllFingers[j][400,:], label = 'Scale 400')\n",
    "#            fig.legend()\n",
    "#            title = 'FP Scale 400 Seg Cut ' + str(MetaData[j,0]) + '  ' + str(MetaData[j,1]) \n",
    "#            plt.title(title)\n",
    "#            plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\")+FFormat)\n",
    "#            plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(np.shape(AllFingers)[0]):\n",
    "    if j % 3 ==0:\n",
    "            fig=plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "            y = SegmentMove(AllFingers[j][400,:],750)\n",
    "            plt.plot(y, label = 'Segment at Scale 400')\n",
    "            #plt.plot(AllFingers[j][200,:], label = 'Scale 200')\n",
    "            plt.fill_between(np.linspace(0,np.size(y),np.size(y)), y, color='yellow')\n",
    "            fig.legend()\n",
    "            title = 'FP Scale 400 Seg fill ' + str(MetaData[j,0]) + '  ' + str(MetaData[j,1]) \n",
    "            plt.title(title)\n",
    "            plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\")+FFormat)\n",
    "            plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range figures = Parallel(n_jobs=num_cores)(delayed(PlotColorScales)(FP) for FP in plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters = [[np.asarray(DataOnlyMatrix[int(Bestmove)]).flatten(),'No Filter'],\n",
    "           [np.asarray(Averages[int(Bestmove)]).flatten(), 'Rolling Average'],\n",
    "           [np.asarray(waveFiltered[int(Bestmove)]).flatten(), 'Low Pass Filter'],\n",
    "           [np.asarray(waveKalmaned[int(Bestmove)]).flatten(), 'Kalman filter']]\n",
    "spacer = 15\n",
    "\n",
    "Compare = Parallel(n_jobs=num_cores)(delayed(getThumbprint)([signal[0], 'dmey']) for signal in Filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plots=[]\n",
    "i=0\n",
    "for finger in Compare:\n",
    "    if finger != 'fail':\n",
    "        plots.append([finger, Filters[i][1]])\n",
    "    else:\n",
    "        print('fail',i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figures = Parallel(n_jobs=num_cores)(delayed(PlotFingerPrint)(FP) for FP in plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(3):\n",
    "    fig=plt.figure(figsize=(PlotWidthIn,PlotHeightIn),dpi=PlotDPI)\n",
    "    plt.plot(Filters[0][0])\n",
    "    plt.plot(Filters[i][0])\n",
    "    title = 'Raw Data vs ' + Filters[i][1]\n",
    "    plt.title(title)\n",
    "    plt.savefig(location+title.replace(\" \", \"\").replace(\":\", \"\").replace(\",\", \"\")+FFormat)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11c16a051206f53cf7fe024f12cacb318023d916d0a5509b7bf3391ee4b4163a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
