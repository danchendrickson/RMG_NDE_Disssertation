{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab68e127",
   "metadata": {},
   "source": [
    "# Trying PyTorch for LSTM Encoder / Decoder\n",
    "borrowed from interwebs\n",
    "https://github.com/lkulowski/LSTM_encoder_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016dd97",
   "metadata": {},
   "source": [
    "## Standard header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3674bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '-', '-', '-']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fad782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "\n",
    "from time import time as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7693c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import CoreFunctions as cf\n",
    "from skimage.restoration import denoise_wavelet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43eb88e",
   "metadata": {},
   "source": [
    "## Choosing platfrom and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c695da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HostName = platform.node()\n",
    "\n",
    "if HostName == \"Server\":\n",
    "    Computer = \"Desktop\"   \n",
    "elif HostName[-6:] == 'wm.edu':\n",
    "    Computer = \"SciClone\"\n",
    "elif HostName == \"SchoolLaptop\":\n",
    "    Computer = \"LinLap\"\n",
    "elif HostName == \"WTC-TAB-512\":\n",
    "    Computer = \"PortLap\"\n",
    "else:\n",
    "    Computer = \"WinLap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5a3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484fbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/sciclone/scr10/dchendrickson01/Recordings2/'\n",
    "    imageFolder = '/sciclone/scr10/dchendrickson01/Move3Dprint/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'Recordings2/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'Recordings2\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7dd29f",
   "metadata": {},
   "source": [
    "## Start Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0cdb2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_60005/3906319707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlstm_encoder_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/RMG_NDE_Disssertation/lstm_encoder_decoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Author: Laura Kulowski\n",
    "\n",
    "'''\n",
    "Example of using a LSTM encoder-decoder to model a synthetic time series \n",
    "https://github.com/lkulowski/LSTM_encoder_decoder\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import sys\n",
    "\n",
    "import lstm_encoder_decoder\n",
    "import plotting \n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 17})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(t, y, split = 0.8):\n",
    "\n",
    "  '''\n",
    "  \n",
    "  split time series into train/test sets\n",
    "  \n",
    "  : param t:                      time array\n",
    "  : para y:                       feature array\n",
    "  : para split:                   percent of data to include in training set \n",
    "  : return t_train, y_train:      time/feature training and test sets;  \n",
    "  :        t_test, y_test:        (shape: [# samples, 1])\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  indx_split = int(split * len(y))\n",
    "  indx_train = np.arange(0, indx_split)\n",
    "  indx_test = np.arange(indx_split, len(y))\n",
    "  \n",
    "  t_train = t[indx_train]\n",
    "  y_train = y[indx_train]\n",
    "  y_train = y_train.reshape(-1, 1)\n",
    "  \n",
    "  t_test = t[indx_test]\n",
    "  y_test = y[indx_test]\n",
    "  y_test = y_test.reshape(-1, 1)\n",
    "  \n",
    "  return t_train, y_train, t_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(y, input_window = 5, output_window = 1, stride = 1, num_features = 1):\n",
    "  \n",
    "    '''\n",
    "    create a windowed dataset\n",
    "    \n",
    "    : param y:                time series feature (array)\n",
    "    : param input_window:     number of y samples to give model \n",
    "    : param output_window:    number of future y samples to predict  \n",
    "    : param stide:            spacing between windows   \n",
    "    : param num_features:     number of features (i.e., 1 for us, but we could have multiple features)\n",
    "    : return X, Y:            arrays with correct dimensions for LSTM\n",
    "    :                         (i.e., [input/output window size # examples, # features])\n",
    "    '''\n",
    "  \n",
    "    L = y.shape[0]\n",
    "    num_samples = (L - input_window - output_window) // stride + 1\n",
    "\n",
    "    X = np.zeros([input_window, num_samples, num_features])\n",
    "    Y = np.zeros([output_window, num_samples, num_features])    \n",
    "    \n",
    "    for ff in np.arange(num_features):\n",
    "        for ii in np.arange(num_samples):\n",
    "            start_x = stride * ii\n",
    "            end_x = start_x + input_window\n",
    "            X[:, ii, ff] = y[start_x:end_x, ff]\n",
    "\n",
    "            start_y = stride * ii + input_window\n",
    "            end_y = start_y + output_window \n",
    "            Y[:, ii, ff] = y[start_y:end_y, ff]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05864bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    '''\n",
    "    convert numpy array to PyTorch tensor\n",
    "    \n",
    "    : param Xtrain:                           windowed training input data (input window size, # examples, # features); np.array\n",
    "    : param Ytrain:                           windowed training target data (output window size, # examples, # features); np.array\n",
    "    : param Xtest:                            windowed test input data (input window size, # examples, # features); np.array\n",
    "    : param Ytest:                            windowed test target data (output window size, # examples, # features); np.array\n",
    "    : return X_train_torch, Y_train_torch,\n",
    "    :        X_test_torch, Y_test_torch:      all input np.arrays converted to PyTorch tensors \n",
    "\n",
    "    '''\n",
    "    \n",
    "    X_train_torch = torch.from_numpy(Xtrain).type(torch.Tensor)\n",
    "    Y_train_torch = torch.from_numpy(Ytrain).type(torch.Tensor)\n",
    "\n",
    "    X_test_torch = torch.from_numpy(Xtest).type(torch.Tensor)\n",
    "    Y_test_torch = torch.from_numpy(Ytest).type(torch.Tensor)\n",
    "    \n",
    "    return X_train_torch, Y_train_torch, X_test_torch, Y_test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmoothMoves(file):\n",
    "    #    if file[-3:] =='csv':\n",
    "    ODataSet = np.genfromtxt(open(folder+file,'r'), delimiter=',',skip_header=0,missing_values=0,invalid_raise=False)\n",
    "    SmoothX = denoise_wavelet(ODataSet[:,3], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    #SmoothY = denoise_wavelet(ODataSet[:,4], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    #SmoothZ = denoise_wavelet(ODataSet[:,5], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothX -= np.average(SmoothX)\n",
    "    Time = []\n",
    "    for r in ODataSet:\n",
    "        t = int(r[1][:2])*3600 + int(r[1][2:4])*60+int(r[1][4:])+float(r[2])/10000.0\n",
    "        Time.append(t)\n",
    "    #SmoothY -= np.average(SmoothY)\n",
    "    #SmoothZ -= np.average(SmoothZ)\n",
    "    #MoveMatrix = np.matrix([SmoothX, SmoothY, SmoothZ])\n",
    "    return SmoothX, Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------\n",
    "# generate dataset for LSTM\n",
    "t, y = SmoothMoves('/sciclone/scr10/dchendrickson01/Recordings2/230418 recording1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train, y_train, t_test, y_test = train_test_split(t, y, split = 0.8)\n",
    "\n",
    "# plot time series \n",
    "plt.figure(figsize = (18, 6))\n",
    "plt.plot(t, y, color = 'k', linewidth = 2)\n",
    "plt.xlim([t[0], t[-1]])\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('Synthetic Time Series')\n",
    "plt.savefig('plots/synthetic_time_series.png')\n",
    "\n",
    "# plot time series with train/test split\n",
    "plt.figure(figsize = (18, 6))\n",
    "plt.plot(t_train, y_train, color = '0.4', linewidth = 2, label = 'Train') \n",
    "plt.plot(np.concatenate([[t_train[-1]], t_test]), np.concatenate([[y_train[-1]], y_test]),\n",
    "         color = (0.74, 0.37, 0.22), linewidth = 2, label = 'Test')\n",
    "plt.xlim([t[0], t[-1]])\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title('Time Series Split into Train and Test Sets')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout\n",
    "plt.savefig('plots/train_test_split.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d921c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------\n",
    "# window dataset\n",
    "\n",
    "# set size of input/output windows \n",
    "iw = 80 \n",
    "ow = 20 \n",
    "s = 5\n",
    "\n",
    "# generate windowed training/test datasets\n",
    "Xtrain, Ytrain= windowed_dataset(y_train, input_window = iw, output_window = ow, stride = s)\n",
    "Xtest, Ytest = windowed_dataset(y_test, input_window = iw, output_window = ow, stride = s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5269fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example of windowed data  \n",
    "plt.figure(figsize = (10, 6)) \n",
    "plt.plot(np.arange(0, iw), Xtrain[:, 0, 0], 'k', linewidth = 2.2, label = 'Input')\n",
    "plt.plot(np.arange(iw - 1, iw + ow), np.concatenate([[Xtrain[-1, 0, 0]], Ytrain[:, 0, 0]]),\n",
    "         color = (0.2, 0.42, 0.72), linewidth = 2.2, label = 'Target')\n",
    "plt.xlim([0, iw + ow - 1])\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title('Example of Windowed Training Data')\n",
    "plt.legend(bbox_to_anchor=(1.3, 1))\n",
    "plt.tight_layout() \n",
    "plt.savefig('plots/windowed_data.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cea0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------\n",
    "# LSTM encoder-decoder\n",
    "\n",
    "# convert windowed data from np.array to PyTorch tensor\n",
    "X_train, Y_train, X_test, Y_test = generate_dataset.numpy_to_torch(Xtrain, Ytrain, Xtest, Ytest)\n",
    "\n",
    "# specify model parameters and train\n",
    "model = lstm_encoder_decoder.lstm_seq2seq(input_size = X_train.shape[2], hidden_size = 15)\n",
    "loss = model.train_model(X_train, Y_train, n_epochs = 50, target_len = ow, batch_size = 5, training_prediction = 'mixed_teacher_forcing', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = False)\n",
    "\n",
    "# plot predictions on train/test data\n",
    "plotting.plot_train_test_results(model, Xtrain, Ytrain, Xtest, Ytest)\n",
    "\n",
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
