{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASC Accelerometer analysis via Summary Statistics \n",
    "\n",
    "FDeveloping moving average acceleration and moving Standard Deviation for each data set.\n",
    "\n",
    "Can run through a whole folder, or through random selections from the folder\n",
    "\n",
    "## This is attempting a slicker method using matrix multiplication.  With that can then attempt GPU parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "import pandas as pd\n",
    "\n",
    "#Custome graph format style sheet\n",
    "plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "if not 'location' in locals():\n",
    "    #save location.  First one is for running on home PC, second for running on the work laptop.  May need to make a global change\n",
    "    #location = 'E:\\\\Documents\\\\Dan\\\\Code\\\\Prospectus\\\\Document\\\\Figures\\\\'\n",
    "    #location = 'C:\\\\Users\\\\dhendrickson\\\\Documents\\\\github\\\\FigsAndPlots\\\\FigsAndPlotsDocument\\\\Figures\\\\'\n",
    "    location = 'E:\\\\Documents\\\\Dan\\\\Phd\\\\Play\\\\'\n",
    "\n",
    "#Standard cycle for collors and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import statistics as st\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns names for a file with all 6 dimmensions\n",
    "Header = np.array(['T', 'X','Y','Z','R','Theta','Phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opens all files in a folder and returns the 3 axis acceleration in one array\n",
    "# made to run in parallel\n",
    "\n",
    "def getAcceleration(FileName):\n",
    "    try:\n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\n",
    "        if FileName[-25:-20] == 'Point':\n",
    "            return [[FileName[-18:-4],'x',DataSet[:,2]],[FileName[-18:-4],'y',DataSet[:,3]],[FileName[-18:-4],'z',DataSet[:,4]]]\n",
    "        else:\n",
    "            return [False,FileName,False]\n",
    "    except:\n",
    "        return [False,FileName,False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first attempt at making stats by brute force, very slow\n",
    "def makeStats(DataArray):\n",
    "    try:\n",
    "        Arange = 50\n",
    "        length = np.shape(DataArray[2])[0]\n",
    "        StdDev = np.zeros(length)\n",
    "        for j in range(length-Arange):\n",
    "            k = (length-1)-j\n",
    "            DataArray[2][k] = np.average(DataArray[2][k-Arange:k])\n",
    "            StdDev[k]=st.stdev(DataArray[2][k-Arange:k])\n",
    "        return [DataArray[0],DataArray[1],max(DataArray[2]),max(StdDev)]\n",
    "    except:\n",
    "        return ['','','','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses matrixes and numpy to calculate the standard deviations of each row simultaneously.\n",
    "# designed to run each time step independently\n",
    "# can be run in parallel\n",
    "\n",
    "def MatStdDev(MoveMatrix, AvgVector):\n",
    "    width = np.shape(MoveMatrix)[1]\n",
    "\n",
    "    AvgMatrix = np.concatenate((AvgVector,AvgVector),axis=1)\n",
    "    for i in range(width-2):\n",
    "        AvgMatrix = np.concatenate((AvgMatrix,AvgVector),axis=1)\n",
    "    AvgVector = []\n",
    "\n",
    "    Deltas = MoveMatrix - AvgMatrix\n",
    "    AvgMatrix = []\n",
    "    MoveMatrix = []\n",
    "\n",
    "    SquareDifference = np.power(Deltas,2)\n",
    "    Deltas = []\n",
    "\n",
    "    one = np.ones((width))\n",
    "\n",
    "    SumSquares = SquareDifference.dot(one)\n",
    "    SquareDifference = []\n",
    "\n",
    "    StdDev = np.power(SumSquares, 0.5) / width\n",
    "    SumSquares = []\n",
    "\n",
    "    return StdDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs:\n",
    "folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\n",
    "folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\n",
    "\n",
    "folder1 = \"D:\\\\\"\n",
    "folder2 = \"D:\\\\SmallCopy\\\\\"\n",
    "\n",
    "files = os.listdir(folder2)\n",
    "\n",
    "Groups = 0\n",
    "GroupSize = 50\n",
    "\n",
    "RollingSize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Calculations\n",
    "\n",
    "num_cores = multiprocessing.cpu_count() - 1\n",
    "if np.shape(files)[0] < GroupSize:\n",
    "    GroupSize = np.shape(files)[0]\n",
    "\n",
    "if Groups !=0:\n",
    "    files = random.sample(files,GroupSize*Groups-1)\n",
    "\n",
    "if np.size(files) % GroupSize ==0:\n",
    "    loops = int(np.size(files)/GroupSize)\n",
    "else:\n",
    "    loops = int(float(np.size(files))/float(GroupSize))+1\n",
    "start = time.time()\n",
    "\n",
    "inverseRollingSize = 1 / RollingSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 of 2.  Total time is 0.6782371441523234 min\n",
      "Loop 2 of 2.  Total time is 1.1063858350118 min\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    AllEvents=[]\n",
    "    Fails = []\n",
    "    for i in range(loops):\n",
    "        \n",
    "        AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder2+file) for file in files[i*GroupSize:((i+1)*GroupSize)])\n",
    "        MetaData = []\n",
    "        DataOnlyMatrix = []\n",
    "        for j in range(np.shape(AllAccels)[0]):\n",
    "            if AllAccels[j][0] == False :\n",
    "                if AllAccels[j][1][4:9] =='Point':\n",
    "                    print(j,AllAccels[j][1])\n",
    "            else: \n",
    "                for k in range(3):\n",
    "                    MetaData.append([AllAccels[j][k][0], AllAccels[j][k][1]])\n",
    "                    if np.shape(np.matrix(AllAccels[j][k][2]))[1] < 60000:\n",
    "                        temp = np.pad(np.matrix(AllAccels[j][k][2]),(60000-np.shape(np.matrix(AllAccels[j][k][2]))[1],0))[0]\n",
    "                        temp=np.matrix(temp)\n",
    "                        if np.size(DataOnlyMatrix) == 0:\n",
    "                            DataOnlyMatrix =np.matrix(temp)\n",
    "                            temp=[]\n",
    "                        else:\n",
    "                            DataOnlyMatrix = np.concatenate((DataOnlyMatrix,temp),axis=0)\n",
    "                            temp=[]\n",
    "                    else:\n",
    "                        if np.size(DataOnlyMatrix) == 0:\n",
    "                            DataOnlyMatrix =np.matrix(AllAccels[j][k][2])\n",
    "                        else:\n",
    "                            DataOnlyMatrix = np.concatenate((DataOnlyMatrix,np.matrix(AllAccels[j][k][2])),axis=0)\n",
    "        \n",
    "        DataOnlyMatrix = np.matrix(DataOnlyMatrix)\n",
    "        \n",
    "        length = np.shape(DataOnlyMatrix)[1]\n",
    "        halfLength = int(length / 2)\n",
    "        \n",
    "        Weights1 = np.zeros((halfLength,halfLength))\n",
    "        Weights2 = np.zeros((halfLength,halfLength+RollingSize-1))\n",
    "                \n",
    "        for j in range(halfLength):\n",
    "            r = j+1\n",
    "            \n",
    "            if r < RollingSize:\n",
    "               ir = 1/ r\n",
    "               for k in range(r):\n",
    "                    Weights1[k,j] = ir\n",
    "            else:\n",
    "                for k in range(RollingSize):\n",
    "                    Weights1[r-RollingSize+k, j] = inverseRollingSize\n",
    "            for k in range(RollingSize):\n",
    "                Weights2[j,j+k] = inverseRollingSize\n",
    "                \n",
    "        FirstBit = np.dot(DataOnlyMatrix[:,:halfLength], Weights1)\n",
    "        Weights1 = []\n",
    "\n",
    "        if length % 2 == 1: halfLength += 1\n",
    "        Weights2=Weights2[:,:halfLength]\n",
    "        SecondBit = np.dot(DataOnlyMatrix[:,halfLength:], Weights2)\n",
    "        \n",
    "        Weights2 = [] \n",
    "\n",
    "        Weights3 = np.zeros((halfLength,halfLength))\n",
    "        for j in range(RollingSize-1):\n",
    "            for k in range(RollingSize-j-1):\n",
    "                Weights3[halfLength-k-1,j] = inverseRollingSize\n",
    "\n",
    "        SecondBit = SecondBit + np.dot(DataOnlyMatrix[:,halfLength:], Weights3)\n",
    "        Weights3 = []\n",
    "\n",
    "        Averages = np.concatenate((FirstBit, SecondBit), axis=1)\n",
    "        FirstBit = []\n",
    "        SecondBit = []\n",
    "        \n",
    "        # Calculating the Standard Devation by square\n",
    "        AllStdDevs = Parallel(n_jobs=num_cores)(delayed(MatStdDev)(DataOnlyMatrix[:,i:RollingSize+i],Averages[:,RollingSize+i] ) for i in range(length-RollingSize))\n",
    "        AllStdDevs=np.squeeze(AllStdDevs)\n",
    "        AllStdDevs = np.concatenate( (np.zeros((RollingSize,np.shape(AllStdDevs)[1])), AllStdDevs),axis=0)\n",
    "\n",
    "        one = np.ones((length))\n",
    "        AvgVector = Averages.dot(one) / np.shape(Averages)[0]\n",
    "        Averages = []\n",
    "        \n",
    "        AllStdDevs = np.transpose(AllStdDevs)\n",
    "        StdDevVector = AllStdDevs.dot(one) / np.shape(AllStdDevs)[0]\n",
    "        AllStdDevs = []\n",
    "\n",
    "        if np.size(AllEvents) == 0:\n",
    "            temp = np.concatenate((MetaData, AvgVector.transpose()), axis=1)\n",
    "            AllEvents = np.concatenate((temp, np.matrix(StdDevVector).transpose()),axis = 1)\n",
    "        else:\n",
    "            temp = np.concatenate((MetaData, AvgVector.transpose()), axis=1)\n",
    "            temp = np.concatenate((temp, np.matrix(StdDevVector).transpose()),axis = 1)\n",
    "            AllEvents = np.concatenate((AllEvents,temp),axis=0)\n",
    "            temp=[]\n",
    "        print('Loop ' + str(i+1) + ' of ' + str(loops) + '.  Total time is ' + str((time.time() - start) / 60) + ' min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=AllEvents)\n",
    "df.to_csv(folder1 + 'StatisticsReport2.csv', sep=',', index = False, header=False,quotechar='\"')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
