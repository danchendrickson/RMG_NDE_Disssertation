{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9d0b12-ce15-4b4b-b97b-174edd0d2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86c39270-d8fa-41a5-9f66-4334ca6215c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc129420-477f-4d06-a7c7-345ab9ebe7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5703d6d6-7b2f-4b88-bbf3-b4f36df40aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0ea20b-8b6f-4e37-833b-7ab3172dbb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722ac4b7-43c3-4f36-817c-42edcf3c49e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 09:06:29.616691: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 09:06:29.632626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-21 09:06:29.650431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-21 09:06:29.655562: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 09:06:29.669451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ea0f94-f1f2-4d7f-8128-5c962054eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 09:06:35.381191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:19:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb314d8-d003-4749-be5c-b888cc7f9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '-', '-', '-']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "\n",
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "import random\n",
    "\n",
    "\n",
    "from time import time as ti\n",
    "\n",
    "import CoreFunctions as cf\n",
    "#from skimage.restoration import denoise_wavelet\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# currently running pid 4010813\n",
    "\n",
    "HostName = platform.node()\n",
    "\n",
    "location = '/sciclone/home/dchendrickson01/image/'\n",
    "rootfolder = '/sciclone/home/dchendrickson01/'\n",
    "folder = '/scratch/RecordingsSplit/xFold/'\n",
    "\n",
    "def Openfile(file):\n",
    "    try:\n",
    "        ff = open(folder+file,'rb')\n",
    "        dump = pickle.load(ff)\n",
    "    \n",
    "        return dump[0], dump[1]\n",
    "    except:\n",
    "        print(\"bad file \",file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f1188-8bef-4dfd-87b3-9442b503a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = folder\n",
    "Titles = True\n",
    "Ledgends = True\n",
    "\n",
    "FileBatch = 20000\n",
    "\n",
    "TimeSteps = 350\n",
    "PredictSize = 25\n",
    "Features = 3\n",
    "MiddleLayerSize = 500\n",
    "\n",
    "num_cores = 30\n",
    "num_gpus = 2\n",
    "\n",
    "files = os.listdir(folder)\n",
    "print('files: ', len(files))\n",
    "\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e310c-1753-4f47-9f86-4d9e1055fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40915f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Masking, Lambda\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a28a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder:\n",
    "  def __init__(self, optimizer='adam', loss='mse'):\n",
    "    self.optimizer = optimizer\n",
    "    self.loss = loss\n",
    "    self.n_features = Features\n",
    "    self.timesteps = TimeSteps\n",
    "    \n",
    "  def build_model(self):\n",
    "    timesteps = self.timesteps\n",
    "    n_features = self.n_features\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Padding\n",
    "    #model.add(Masking(mask_value=0.0, input_shape=(timesteps, n_features)))\n",
    "\n",
    "    # Encoder\n",
    "    model.add(LSTM(timesteps, activation='relu', input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(12, activation='relu'))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(LSTM(timesteps, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    \n",
    "    model.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    self.model = model\n",
    "    \n",
    "  def simple_model(self):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential(name='DanModel')\n",
    "    model.add(LSTM(MiddleLayerSize, input_shape=(TimeSteps * Features,1), return_sequences=True,name='danLSTM'))\n",
    "    #model.add(RepeatVector(TimeSteps))\n",
    "    #model.add(RepeatVector(PredictSize))\n",
    "    \n",
    "    #model.add(LSTM(25, return_sequences=True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense( MiddleLayerSize, activation='softmax',name='DanDense')))\n",
    "\n",
    "    model.add(Lambda(lambda x: x[:, -PredictSize * Features:,1], name='DanLambda')) #Select last N from output  \n",
    "    #https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras?noredirect=1&lq=1\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    self.model = model\n",
    "    \n",
    "  def fit(self, X, epochs=3, batch_size=32):\n",
    "    #self.timesteps = np.shape(X)[0]\n",
    "    #self.build_model()\n",
    "    \n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    self.model.fit(X, X, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "  def predict(self, X):\n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    output_X = self.model.predict(X)\n",
    "    reconstruction = np.squeeze(output_X)\n",
    "    return np.linalg.norm(X - reconstruction, axis=-1)\n",
    "  \n",
    "  def plot(self, scores, timeseries, threshold=0.95):\n",
    "    sorted_scores = sorted(scores)\n",
    "    threshold_score = sorted_scores[round(len(scores) * threshold)]\n",
    "    \n",
    "    plt.title(\"Reconstruction Error\")\n",
    "    plt.plot(scores)\n",
    "    plt.plot([threshold_score]*len(scores), c='r')\n",
    "    plt.show()\n",
    "    \n",
    "    anomalous = np.where(scores > threshold_score)\n",
    "    normal = np.where(scores <= threshold_score)\n",
    "    \n",
    "    plt.title(\"Anomalies\")\n",
    "    plt.scatter(normal, timeseries[normal][:,-1], s=3)\n",
    "    plt.scatter(anomalous, timeseries[anomalous][:,-1], s=5, c='r')\n",
    "    plt.show()\n",
    "\n",
    "lstm_autoencoder2 = LSTM_Autoencoder(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                        inter_op_parallelism_threads=num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : num_cores,\n",
    "                                        'GPU' : num_gpus}\n",
    "                       )\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_autoencoder2.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859f035-bef6-4b2c-b495-6a03eeca7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datas = Openfile(files[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c86a6-5929-4bc0-83c8-2f07e6a2ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(Datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d80cb-77ce-44bb-bd8b-632db6cb6898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87cd396-b50b-4274-b638-1f39b1e12c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79170ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalMoves=0\n",
    "Loops=int(len(files)/FileBatch)+1\n",
    "\n",
    "\n",
    "random.shuffle(files)\n",
    "\n",
    "k=0\n",
    "print(\"Starting Loop \"+str(k+1)+\" of \"+str(Loops+1))\n",
    "\n",
    "start = k * FileBatch\n",
    "\n",
    "Results = Parallel(n_jobs=2)(delayed(Openfile)(file) for file in files[start:start+FileBatch])\n",
    "\n",
    "Moves = []\n",
    "Names = []\n",
    "for result in Results:\n",
    "    try:\n",
    "        for j in range(len(result[0])):\n",
    "            Moves.append(result[0][j,:,:])\n",
    "            Names.append(result[1]+str(i).zfill(5))\n",
    "            i+=1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "del Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66063d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19030a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = list(), list()\n",
    "for move in Moves:\n",
    "    X.append(move[:TimeSteps,:].flatten())\n",
    "    y.append(move[TimeSteps:TimeSteps+PredictSize,:].flatten())\n",
    "    X.append(move[TimeSteps+PredictSize:2*TimeSteps+PredictSize,:].flatten())\n",
    "    y.append(move[2*TimeSteps+PredictSize:,:].flatten())\n",
    "    TotalMoves+=1\n",
    "\n",
    "Batches = 32\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    X = tf.convert_to_tensor(X, np.float32)\n",
    "    y = tf.convert_to_tensor(y, np.float32)\n",
    "\n",
    "lstm_autoencoder2.model.fit(X, y, epochs=4, batch_size=Batches, verbose=2)\n",
    "\n",
    "lstm_autoencoder2.model.save(\"LSTM_AtOnce_350p25\")\n",
    "\n",
    "print('Total Moves ',TotalMoves)\n",
    "\n",
    "del X, y, Moves, Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28fa44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05198a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.extend(np.zeros(5))\n",
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.matrix(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.insert(0, Test.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate((np.matrix(Test),test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c926c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sVect = test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1517295",
   "metadata": {},
   "outputs": [],
   "source": [
    "sVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a557f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eVect = (test!=0).sum(axis=0)\n",
    "eVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VarVect = sVect / eVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "StdDev = np.sqrt(VarVect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c171294",
   "metadata": {},
   "outputs": [],
   "source": [
    "StdDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077eb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "StdDev = np.asarray(StdDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(StdDev,[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae171101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.average(test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad30ece-aa51-40d2-b1bb-7caa351f2840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97944be-9d20-4570-875c-730de047d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "/local/scr/dchendrickson01/1000Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f6bfc-cbdc-4733-a8a7-d994d1fdfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76202d0d-6d8a-4a25-9643-3c289aa2c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder = '/scratch/1000Input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eba703-988b-4706-b8a3-1f949edbbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_list = [\n",
    "    os.path.join(Folder,file)\n",
    "    for file in os.listdir(Folder) if file.endswith('Data.csv') and file.startswith('2')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a4de-e9b4-4bd3-9797-b974733073f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb666606-8beb-4c9c-ba5a-72c6a47707b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc71536-312f-4804-a04e-0fe853f263d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_list = glob.glob(os.path.join(Folder, '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bdf38-afbf-4482-8d5c-3f439d08895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82074aee-1004-4f87-b947-4897a69bb5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FileListAsOf08111226.txt', 'w') as file:\n",
    "    for item in file_list:\n",
    "        # Write each item on a new line\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eeaa8e-cc64-4402-8aa8-31903228c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_files(directory):\n",
    "    csv_files = []\n",
    "    with os.scandir(directory) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file() and entry.name.endswith('Data.csv'):\n",
    "                csv_files.append(entry.path)\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c8321-f04b-4428-8c95-b15a847a8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_files = list_csv_files(Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42030e30-01f1-4fe3-9ecf-5dcd6c5679b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e2151-ae82-4ce1-b173-2b6a0126e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FileListAsOf0812-0805.txt', 'w') as file:\n",
    "    for item in csv_files:\n",
    "        # Write each item on a new line\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d989a6-e783-4344-b48a-c2deb078d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/FileListAsOf0811-1612.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba95282-2c09-41ed-9941-702bebfff4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in csv_files:\n",
    "        # Write each item on a new line\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9eeb17-2deb-4f99-8f6c-c93e22c0a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0d1a6-4bba-468d-b535-b6e42c0b248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97176c87-7a01-4391-8c3b-63805bf2ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(p) for p in Path(directory).iterdir() if p.is_file() and ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043a908-a18d-4bae-91f3-efa0bcdd494a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8dade5-29b0-43e7-96ce-dda691027e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192cee6-9d5c-44d8-81e9-86dc5e3f1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639a0f2-8c78-40a6-9273-ef5fa1951e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    shutil.copy(file_list[i],'/scratch/1000Sm/')\n",
    "    shutil.copy(file_list[i][:-8]+'Outs.csv','/scratch/1000Sm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa7cc6-287d-44f9-b1d0-26a832d626a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9881cc-9c25-489a-8867-437d9f0193b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac5c89-3afc-4709-a0c2-3c40a92b87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FileListAsOf0812-0805.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    AllLines = file.readlines()\n",
    "\n",
    "# Optionally, strip newline characters from each line\n",
    "AllLines = [line.strip() for line in AllLines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267776b9-b6f9-4573-86c2-d9cfb7deebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45efcf-a7e7-4d04-890c-4f22ad32e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(AllLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a5588-84f0-4ccb-a6ba-ffaa1f1500f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ['a','b','c','d','e','f','g','h','i','j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04086f-6588-4e26-b1fb-8854e91761a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b275a2-8f6a-4dec-91da-10ddeba5791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for let, i in enumerate(j):\n",
    "    print(let, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7dc30-d9aa-40f9-a63f-a0ad659d0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, let in enumerate(j):\n",
    "    lines = AllLines[i::10]\n",
    "    with open('FileListAsOf0812-'+let+'.txt', 'w') as file:\n",
    "        for item in lines:\n",
    "            # Write each item on a new line\n",
    "            file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cf37b-824e-4211-8505-50f53496f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8d943-8aa2-4655-9ec8-e50a182ea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f13a8d-c4b0-42af-a128-78351cab2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "for i in range(1000):\n",
    "    sizes.append(os.path.getsize(lines[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fea73-677b-4a2c-b09d-6ae1c8b1aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff555a-fbbf-4a70-8c86-2131a3d6c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b52ef7-44a8-43f5-b640-078832501e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)*np.average(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c4ae6-ee79-4de5-b955-b9f52eccb09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0af84a-0736-4b24-b672-bc1c18f1540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11863ac9-817c-4969-9188-22f5453fb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decoded content has been written to 'decoded_lambda_code.bin'.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "# Your config JSON data\n",
    "config_data = {\n",
    "    \"code\": \"4wEAAAAAAAAAAAAAAAUAAAATAAAA8ygAAACXAHwAZABkAIUCdAAAAAAAAAAAAAsAZACFAmQAZACF\\nAmYDGQAAAFMAqQFOKQHaC1ByZWRpY3RTaXplKQHaAXhzAQAAACD6Iy90bXAvaXB5a2VybmVsXzkz\\nNzExMS8zNDU4NDUyNDc0LnB5+gg8bGFtYmRhPvovTFNUTV9BdXRvZW5jb2Rlci5zaW1wbGVfbW9k\\nZWwuPGxvY2Fscz4uPGxhbWJkYT4pAAAAcxYAAACAAJhxohGkW6BMoU2yMdAhNNEfNYAA8wAAAAA=\\n\",\n",
    "    \"defaults\": None,\n",
    "    \"closure\": None\n",
    "}\n",
    "\n",
    "# Decode the base64 encoded string\n",
    "decoded_code = base64.b64decode(config_data['code'])\n",
    "\n",
    "# Write the decoded content to a binary file\n",
    "with open('decoded_lambda_code.bin', 'wb') as file:\n",
    "    file.write(decoded_code)\n",
    "\n",
    "print(\"The decoded content has been written to 'decoded_lambda_code.bin'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6586e07e-75ae-43be-ae2f-57ed5984a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The config has been updated with the edited Lambda function.\n"
     ]
    }
   ],
   "source": [
    "# Read the edited content from the text file\n",
    "with open('decoded_lambda_code.bin', 'rb') as file:\n",
    "    edited_code = file.read()\n",
    "\n",
    "# Encode the edited content back to base64\n",
    "encoded_code = base64.b64encode(edited_code).decode('utf-8')\n",
    "\n",
    "# Update the config data\n",
    "config_data['code'] = encoded_code\n",
    "\n",
    "# Optionally, write the updated config back to a file\n",
    "with open('updated_config.json', 'w') as file:\n",
    "    json.dump(config_data, file)\n",
    "\n",
    "print(\"The config has been updated with the edited Lambda function.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a410ff2-6571-42ac-a6be-ef091b0ef4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cf373-a511-4cc0-a512-0cad7bee3f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
