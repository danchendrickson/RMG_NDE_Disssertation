{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122e4c28-59f4-4a64-b51f-14b36e5aa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '-', '-', '-']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "\n",
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "import random\n",
    "\n",
    "\n",
    "from time import time as ti\n",
    "\n",
    "import CoreFunctions as cf\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# currently running pid 4010813\n",
    "\n",
    "HostName = platform.node()\n",
    "\n",
    "if HostName == \"Server\":\n",
    "    Computer = \"Desktop\"   \n",
    "elif HostName[-6:] == 'wm.edu':\n",
    "    Computer = \"SciClone\"\n",
    "elif HostName == \"SchoolLaptop\":\n",
    "    Computer = \"LinLap\"\n",
    "elif HostName == \"WTC-TAB-512\":\n",
    "    Computer = \"PortLap\"\n",
    "else:\n",
    "    Computer = \"WinLap\"\n",
    "\n",
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'\n",
    "\n",
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/scratch/RecordingsSplit/xFold/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'Recordings2/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'Recordings2\\\\'\n",
    "\n",
    "def Openfile(file):\n",
    "    try:\n",
    "        ff = open(folder+file,'rb')\n",
    "        dump = pickle.load(ff)\n",
    "    \n",
    "        return dump[0], dump[1]\n",
    "    except:\n",
    "        print(\"bad file \",file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c10f1b-528d-4c7b-b11b-0984c4d9b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = folder\n",
    "Titles = True\n",
    "Ledgends = True\n",
    "\n",
    "FileBatch = 20000\n",
    "\n",
    "TimeSteps = 700\n",
    "PredictSize = 50\n",
    "Features = 3\n",
    "MiddleLayerSize = 500\n",
    "\n",
    "num_cores = 32\n",
    "num_gpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f85c81-661c-4960-a85b-91f107be624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files:  678618\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(folder)\n",
    "print('files: ', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b5a4b1-d52a-4504-8c55-af8535b580c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4df619e-efda-44ea-835c-157026475e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 21:58:52.819095: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-11 21:58:52.873116: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 21:58:54.744162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Masking, Lambda\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979b3684-cc68-45e3-82dc-7ff27c91e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder:\n",
    "  def __init__(self, optimizer='adam', loss='mse'):\n",
    "    self.optimizer = optimizer\n",
    "    self.loss = loss\n",
    "    self.n_features = Features\n",
    "    self.timesteps = TimeSteps\n",
    "    \n",
    "  def build_model(self):\n",
    "    timesteps = self.timesteps\n",
    "    n_features = self.n_features\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Padding\n",
    "    #model.add(Masking(mask_value=0.0, input_shape=(timesteps, n_features)))\n",
    "\n",
    "    # Encoder\n",
    "    model.add(LSTM(timesteps, activation='relu', input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(12, activation='relu'))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(LSTM(timesteps, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    \n",
    "    model.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    self.model = model\n",
    "    \n",
    "  def simple_model(self):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(MiddleLayerSize, input_shape=(TimeSteps * Features,1), return_sequences=True))\n",
    "    #model.add(RepeatVector(TimeSteps))\n",
    "    #model.add(RepeatVector(PredictSize))\n",
    "    \n",
    "    #model.add(LSTM(25, return_sequences=True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense( MiddleLayerSize, activation='softmax')))\n",
    "\n",
    "    model.add(Lambda(lambda x: x[:, -PredictSize * Features:,1])) #Select last N from output  \n",
    "    #https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras?noredirect=1&lq=1\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    self.model = model\n",
    "    \n",
    "  def fit(self, X, epochs=3, batch_size=32):\n",
    "    #self.timesteps = np.shape(X)[0]\n",
    "    #self.build_model()\n",
    "    \n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    self.model.fit(X, X, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "  def predict(self, X):\n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    output_X = self.model.predict(X)\n",
    "    reconstruction = np.squeeze(output_X)\n",
    "    return np.linalg.norm(X - reconstruction, axis=-1)\n",
    "  \n",
    "  def plot(self, scores, timeseries, threshold=0.95):\n",
    "    sorted_scores = sorted(scores)\n",
    "    threshold_score = sorted_scores[round(len(scores) * threshold)]\n",
    "    \n",
    "    plt.title(\"Reconstruction Error\")\n",
    "    plt.plot(scores)\n",
    "    plt.plot([threshold_score]*len(scores), c='r')\n",
    "    plt.show()\n",
    "    \n",
    "    anomalous = np.where(scores > threshold_score)\n",
    "    normal = np.where(scores <= threshold_score)\n",
    "    \n",
    "    plt.title(\"Anomalies\")\n",
    "    plt.scatter(normal, timeseries[normal][:,-1], s=3)\n",
    "    plt.scatter(anomalous, timeseries[anomalous][:,-1], s=5, c='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47b3195-1091-4f9e-b18f-bca9ec20681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_autoencoder2 = LSTM_Autoencoder(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37c39f1-5579-4890-8d29-c0d8b853f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                        inter_op_parallelism_threads=num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : num_cores,\n",
    "                                        'GPU' : 0}\n",
    "                       )\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d9e65f-4dae-4aea-9474-2ec02e656d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 21:58:58.372273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:19:00.0, compute capability: 8.0\n",
      "/sciclone/home/dchendrickson01/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,004,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2100\u001b[0m, \u001b[38;5;34m500\u001b[0m)      │     \u001b[38;5;34m1,004,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2100\u001b[0m, \u001b[38;5;34m500\u001b[0m)      │       \u001b[38;5;34m250,500\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,254,500</span> (4.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,254,500\u001b[0m (4.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,254,500</span> (4.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,254,500\u001b[0m (4.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_autoencoder2.simple_model()\n",
    "#lstm_autoencoder2.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02714eb0-ff20-45a7-bbd6-20bfbb5cfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalMoves=0\n",
    "Loops=int(len(files)/FileBatch)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a17c04-3ea8-4430-bfe0-8b03e0aaa4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in range(Loops):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c884047-bfdd-49a3-8494-7b92f2c2e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb263042-a286-4a86-a4b1-6e729ba579d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(Results[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f69d0e-7003-4836-8c10-73bb1c3dbe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "041bef76-6af3-4af6-84c9-ddbb47204485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop 1 of 35\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Loop \"+str(k+1)+\" of \"+str(Loops+1))\n",
    "\n",
    "start = k * FileBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "310661f6-e03a-4354-889b-68f1410e48c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sciclone/home/dchendrickson01/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "Results = Parallel(n_jobs=32)(delayed(Openfile)(file) for file in files[start:start+FileBatch])\n",
    "\n",
    "#print('Results in from Parallel', len(Results))\n",
    "\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a73679-3d10-4c1d-8609-d36d6123c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Moves = []\n",
    "Names = []\n",
    "for result in Results:\n",
    "    try:\n",
    "        for j in range(len(result[0])):\n",
    "            Moves.append(result[0][j,:,:])\n",
    "            Names.append(result[1]+str(i).zfill(5))\n",
    "            i+=1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06bf8c8-a264-44cd-88ef-c0074c5e17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b819a39c-e5ae-4a24-bcc7-de20f5e6ed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6380241\n",
      "Results parsed  None\n"
     ]
    }
   ],
   "source": [
    "print('Results parsed ', print(len(Moves)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3311e284-c628-416c-b4d3-c0a2bbdaeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = list(), list()\n",
    "for move in Moves:\n",
    "    X.append(move[:TimeSteps,:].flatten())\n",
    "    y.append(move[TimeSteps:,:].flatten())\n",
    "    TotalMoves+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b677ccf-ceac-4f98-bc61-ecff8cd78309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6380241, 150)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8699783c-9bff-42cb-8b9b-851d8dfd6444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6380241, 2100)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776bdc76-33f9-4442-8579-d373236e4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8bf9147-c8a6-47f1-93f7-46be0318543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batches = 32\n",
    "#NumbBatches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a85905-1ca5-439e-af4d-8fda0ac04344",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "   X = tf.convert_to_tensor(X, np.float32)\n",
    "   y = tf.convert_to_tensor(y, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9dae8-782b-4d92-91ef-ac1df083873b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_autoencoder2.model.fit(X, y, epochs=4, batch_size=Batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54af17-cad8-4545-88b2-300c5727b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_autoencoder2.model.save(\"LSTM_AtOnce_700p52\"+str(k).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42ec70-3eca-496e-a6d5-eefc943e8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Moves ',TotalMoves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cdda79-9a51-48ec-b98a-8b00f1a21c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "st = ti()\n",
    "SamplesPerSet = Batches * NumbBatches\n",
    "\n",
    "SetsNeeded = int(len(X) / SamplesPerSet)\n",
    "if  int(len(X) / SamplesPerSet) != 0:\n",
    "    SetsNeeded += 1\n",
    "print(len(X), SetsNeeded)\n",
    "\n",
    "PercentPerSet = 1.0 / float(SetsNeeded)\n",
    "\n",
    "PercentHoldOutForNext=1.0\n",
    "for i in range(SetsNeeded-1):\n",
    "    PercentHoldOutForNext = 1.0 - (SamplesPerSet / len(X))\n",
    "    seq_train, seq_test, out_train, out_test = train_test_split(X, y, test_size=PercentHoldOutForNext, shuffle=True, random_state=0)\n",
    "    seq_train = np.asarray(seq_train)\n",
    "    out_train = np.asarray(out_train)\n",
    "    if i == 0:\n",
    "        vb = 1\n",
    "    else:\n",
    "        vb = 0\n",
    "    lstm_autoencoder2.model.fit(seq_train, out_train, epochs=2, batch_size=Batches, verbose=vb)\n",
    "    MoveSegments = seq_test\n",
    "    NextDataPoint = out_test\n",
    "    print(str(i+1)+' of ' + str(SetsNeeded), (int(ti()-st)/6)/10, (int(((ti()-st)/(i+1) * ( SetsNeeded -1) - (ti()-st) )/6)/10))\n",
    "\n",
    "\n",
    "lstm_autoencoder2.model.save(\"LSTM_predict_full_700p50\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
