{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at accelerometer data \n",
    "\n",
    "Finding Zero velocity times by rail axis acceleration noise levels, making summary statistics for the noise levels across the whole day files.  Spot check graphs to see what works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = False\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "\n",
    "#Standard cycle to make black and white images and dashed and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '-', '-', '-']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')\n",
    "\n",
    "#Extra Headers:\n",
    "import os as os\n",
    "import pywt as py\n",
    "import statistics as st\n",
    "import os as os\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "\n",
    "from time import time as ti\n",
    "\n",
    "#import CoreFunctions as cf\n",
    "from skimage.restoration import denoise_wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HostName = platform.node()\n",
    "\n",
    "if HostName == \"Server\":\n",
    "    Computer = \"Desktop\"   \n",
    "elif HostName[-6:] == 'wm.edu':\n",
    "    Computer = \"SciClone\"\n",
    "elif HostName == \"SchoolLaptop\":\n",
    "    Computer = \"LinLap\"\n",
    "elif HostName == \"WTC-TAB-512\":\n",
    "    Computer = \"PortLap\"\n",
    "else:\n",
    "    Computer = \"WinLap\"\n",
    "\n",
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "elif Computer == 'PortLap':\n",
    "    location = 'C:\\\\users\\\\dhendrickson\\\\Desktop\\\\AccelData\\\\'\n",
    "\n",
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/scratch/Recordings2/'\n",
    "    imageFolder = '/scratch/Move3Dprint/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"Recordings2\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'Recordings2/'\n",
    "elif Computer =='PortLap':\n",
    "    rootfolder = location \n",
    "    folder = rootfolder + 'Recordings2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saving = False\n",
    "location = folder\n",
    "Titles = True\n",
    "Ledgends = True\n",
    "\n",
    "f = 0\n",
    "\n",
    "\n",
    "files = ['230418 recording1.csv','230419 recording1.csv','230420 recording1.csv','230421 recording1.csv'] #,\n",
    "#         '230418 recording2.csv','230419 recording2.csv','230420 recording2.csv','230421 recording2.csv']\n",
    "\n",
    "#Smooth = cf.Smoothing(ODataSet[:,3],2) #,50)\n",
    "def SmoothMoves(file):\n",
    "    #    if file[-3:] =='csv':\n",
    "    ODataSet = np.genfromtxt(open(folder+file,'r'), delimiter=',',skip_header=0,missing_values=0,invalid_raise=False)\n",
    "    SmoothX = denoise_wavelet(ODataSet[:,3], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothY = denoise_wavelet(ODataSet[:,4], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothZ = denoise_wavelet(ODataSet[:,5], method='VisuShrink', mode='soft', wavelet_levels=3, wavelet='sym2', rescale_sigma='True')\n",
    "    SmoothX -= np.average(SmoothX)\n",
    "    SmoothY -= np.average(SmoothY)\n",
    "    SmoothZ -= np.average(SmoothZ)\n",
    "    MoveMatrix = np.matrix([SmoothX, SmoothY, SmoothZ])\n",
    "    return MoveMatrix\n",
    "    #else:\n",
    "    #    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4675503373146057\n"
     ]
    }
   ],
   "source": [
    "LoopFiles = 8\n",
    "loops = int(len(files) / LoopFiles) \n",
    "if len(files)%LoopFiles != 0:\n",
    "    loops += 1\n",
    "\n",
    "\n",
    "\n",
    "st = ti()\n",
    "\n",
    "Moves = []\n",
    "\n",
    "for k in range(loops):\n",
    "    if k == loops -1:\n",
    "        tfiles = files[k*LoopFiles:]\n",
    "    else:\n",
    "        tfiles = files[k*LoopFiles:(k+1)*LoopFiles]\n",
    "    #Results = Parallel(n_jobs=LoopFiles)(delayed(DeviationVelocity)(file) for file in tfiles)\n",
    "    Results = Parallel(n_jobs=LoopFiles)(delayed(SmoothMoves)(file) for file in tfiles)\n",
    "    #Results =[]\n",
    "    #for file in tfiles:\n",
    "    #    Results.append(SmoothMoves(file))\n",
    "    #    print(file, (ti()-st)/60.0)\n",
    "    for result in Results:\n",
    "        Moves.append(result)\n",
    "    print(k, (ti()-st)/60.0)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "TimeSteps = 500\n",
    "StepSize = 12\n",
    "PredictSize = 25\n",
    "Features = 3\n",
    "#Features = np.shape(Moves[0])[0]\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps, s_step = 1, y_steps = 1):\n",
    "    X, y = list(), list()\n",
    "    Steps_to_take = int((len(sequences)-TimeSteps-PredictSize) / s_step)-1\n",
    "    for j in range(Steps_to_take):\n",
    "        i = j * s_step\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequences[i:end_ix, :]\n",
    "        seq_y = sequences[end_ix:end_ix+y_steps,:]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    print(np.shape(y))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1554882, 25, 3)\n",
      "(1574784, 25, 3)\n",
      "(1591982, 25, 3)\n",
      "(1580635, 25, 3)\n",
      "Move Segments  6302283 2.954521056016286\n"
     ]
    }
   ],
   "source": [
    "Sequences = []\n",
    "Outputs = []\n",
    "for move in Moves:\n",
    "    Seq, Out = split_sequences(move.T,TimeSteps,StepSize,PredictSize)\n",
    "    Sequences.append(Seq)\n",
    "    Outputs.append(Out)\n",
    "    \n",
    "\n",
    "MoveSegments = []\n",
    "for seq in Sequences:\n",
    "    for mv in seq:\n",
    "        MoveSegments.append(mv)\n",
    "NextDataPoint = []\n",
    "for out in Outputs:\n",
    "    for pt in out:\n",
    "        NextDataPoint.append(pt) #np.reshape(pt,(PredictSize,3)))\n",
    "\n",
    "print('Move Segments ', len(MoveSegments),(ti()-st)/60.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(NextDataPoint[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:23:10.984034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-27 09:23:11.384052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-27 09:23:11.488490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-27 09:23:12.352582: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Masking, Lambda\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder:\n",
    "  def __init__(self, optimizer='adam', loss='mse'):\n",
    "    self.optimizer = optimizer\n",
    "    self.loss = loss\n",
    "    self.n_features = Features\n",
    "    self.timesteps = TimeSteps\n",
    "    \n",
    "  def build_model(self):\n",
    "    timesteps = self.timesteps\n",
    "    n_features = self.n_features\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Padding\n",
    "    #model.add(Masking(mask_value=0.0, input_shape=(timesteps, n_features)))\n",
    "\n",
    "    # Encoder\n",
    "    model.add(LSTM(timesteps, activation='relu', input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(12, activation='relu'))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(LSTM(timesteps, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(Lambda(lambda x: x[:, -PredictSize:, :])) #Select last N from output  \n",
    "    model.add(TimeDistributed(Dense( self.n_features, activation='softmax')))\n",
    "    \n",
    "    model.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    self.model = model\n",
    "    \n",
    "  def simple_model(self):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(250, input_shape=(TimeSteps, Features), return_sequences=True))\n",
    "    #model.add(RepeatVector(TimeSteps))\n",
    "    #model.add(RepeatVector(PredictSize))\n",
    "    \n",
    "    #model.add(LSTM(25, return_sequences=True))\n",
    "    \n",
    "    model.add(Lambda(lambda x: x[:, -PredictSize:, :])) #Select last N from output  \n",
    "    #https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras?noredirect=1&lq=1\n",
    "    \n",
    "    model.add(TimeDistributed(Dense( self.n_features, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    self.model = model\n",
    "    \n",
    "  def fit(self, X, epochs=3, batch_size=32):\n",
    "    #self.timesteps = np.shape(X)[0]\n",
    "    self.build_model()\n",
    "    \n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    self.model.fit(X, X, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "  def predict(self, X):\n",
    "    #input_X = np.expand_dims(X, axis=1)\n",
    "    output_X = self.model.predict(X)\n",
    "    reconstruction = np.squeeze(output_X)\n",
    "    return np.linalg.norm(X - reconstruction, axis=-1)\n",
    "  \n",
    "  def plot(self, scores, timeseries, threshold=0.95):\n",
    "    sorted_scores = sorted(scores)\n",
    "    threshold_score = sorted_scores[round(len(scores) * threshold)]\n",
    "    \n",
    "    plt.title(\"Reconstruction Error\")\n",
    "    plt.plot(scores)\n",
    "    plt.plot([threshold_score]*len(scores), c='r')\n",
    "    plt.show()\n",
    "    \n",
    "    anomalous = np.where(scores > threshold_score)\n",
    "    normal = np.where(scores <= threshold_score)\n",
    "    \n",
    "    plt.title(\"Anomalies\")\n",
    "    plt.scatter(normal, timeseries[normal][:,-1], s=3)\n",
    "    plt.scatter(anomalous, timeseries[anomalous][:,-1], s=5, c='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:23:30.095499: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 09:23:30.095587: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: hi06.sciclone.wm.edu\n",
      "2024-12-27 09:23:30.095598: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: hi06.sciclone.wm.edu\n",
      "2024-12-27 09:23:30.095703: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got \"1\"\n",
      "2024-12-27 09:23:30.095733: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 555.58.2\n",
      "/sciclone/home/dchendrickson01/miniconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,008,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m500\u001b[0m)       │     \u001b[38;5;34m1,008,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │       \u001b[38;5;34m110,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m3,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m500\u001b[0m)       │     \u001b[38;5;34m1,026,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │       \u001b[38;5;34m110,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │           \u001b[38;5;34m153\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,577</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,257,577\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,577</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,257,577\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_autoencoder2 = LSTM_Autoencoder(optimizer='adam', loss='mse')\n",
    "\n",
    "lstm_autoencoder2.build_model()\n",
    "#lstm_autoencoder2.simple_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6302283 493\n"
     ]
    }
   ],
   "source": [
    "Batches = 64\n",
    "NumbBatches = 200\n",
    "\n",
    "SamplesPerSet = Batches * NumbBatches\n",
    "\n",
    "SetsNeeded = int(len(MoveSegments) / SamplesPerSet)\n",
    "if  int(len(MoveSegments) / SamplesPerSet) != 0:\n",
    "    SetsNeeded += 1\n",
    "print(len(MoveSegments), SetsNeeded)\n",
    "\n",
    "PercentPerSet = 1.0 / float(SetsNeeded)\n",
    "\n",
    "PercentHoldOutForNext=0.01\n",
    "\n",
    "MoveSegments, Input_Test, NextDataPoint, Output_test = train_test_split(MoveSegments, NextDataPoint, test_size=PercentHoldOutForNext, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 14s/step - accuracy: 0.3297 - loss: 0.1113\n",
      "Epoch 2/2\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 13s/step - accuracy: 0.3940 - loss: 0.1113\n",
      "1 of 493 6.240180961290995 51.06548112637467\n",
      "2 of 493 11.970000660419464 48.877503263950345\n",
      "3 of 493 17.649823971589406 47.94868857430087\n",
      "4 of 493 23.209422663847604 47.19249282207754\n",
      "5 of 493 28.768751446406046 46.701273425857224\n",
      "6 of 493 34.415794893105826 46.46132316946983\n",
      "7 of 493 40.01597680648168 46.2089256479059\n",
      "8 of 493 45.692525160312655 46.07329626689354\n",
      "9 of 493 51.057055898507436 45.66770003654338\n",
      "10 of 493 56.485560278097786 45.376733521567445\n",
      "11 of 493 61.85286984443665 45.07762183646964\n",
      "12 of 493 67.19483055671056 44.796553748647376\n",
      "13 of 493 72.68485139211019 44.635953635247354\n",
      "14 of 493 78.21078082720439 44.505658651486264\n",
      "15 of 493 83.78893273671468 44.4081343730953\n",
      "16 of 493 89.3103548248609 44.28305095513662\n",
      "17 of 493 94.89931254784265 44.19330734110736\n",
      "18 of 493 100.65122021834055 44.17470223250213\n",
      "19 of 493 106.45689446131388 44.170272893260794\n",
      "20 of 493 112.32720872163773 44.1820354578495\n",
      "21 of 493 118.24383444388708 44.20067147005172\n",
      "22 of 493 124.25509488979975 44.242344414489445\n",
      "23 of 493 130.3373660683632 44.29581500936245\n",
      "24 of 493 136.38126047054928 44.323909679518806\n",
      "25 of 493 142.1890208562215 44.26818183938398\n",
      "26 of 493 147.7445412993431 44.13394632960997\n",
      "27 of 493 153.03636542161306 43.92710490021441\n",
      "28 of 493 159.05567755699158 43.92966333564311\n",
      "29 of 493 164.31364777882894 43.72253962769134\n",
      "30 of 493 169.6155472755432 43.5346571539243\n",
      "31 of 493 174.91032246748605 43.35142939501125\n",
      "32 of 493 180.4223937312762 43.22619850894643\n",
      "33 of 493 185.81111646493275 43.0743951880691\n",
      "34 of 493 191.22864027818045 42.93270454411024\n",
      "35 of 493 196.6331236720085 42.79111311450649\n",
      "36 of 493 202.09390382766725 42.66426860131599\n",
      "37 of 493 207.62463386853537 42.553697490427226\n",
      "38 of 493 213.12511557737986 42.43807126781397\n",
      "39 of 493 218.58980898062387 42.316745083602065\n",
      "40 of 493 224.0436665256818 42.19489053670565\n",
      "41 of 493 229.49140844345092 42.07342491103543\n",
      "42 of 493 234.95471155643463 41.956198500271825\n",
      "43 of 493 240.37697505950928 41.83304722056987\n",
      "44 of 493 245.78223837614058 41.70850106843795\n",
      "45 of 493 251.21702159245808 41.59037358211587\n",
      "46 of 493 256.6892603715261 41.479496430106785\n",
      "47 of 493 262.1915139754613 41.37419281699415\n",
      "48 of 493 267.6165635466576 41.25755355230636\n",
      "49 of 493 272.96157785654066 41.12992483207428\n",
      "50 of 493 278.2371687332789 40.9936095344358\n",
      "51 of 493 283.5366176565488 40.86263019610465\n",
      "52 of 493 289.60530152718223 40.841773300598824\n",
      "53 of 493 294.91107836564385 40.71256711417899\n",
      "54 of 493 300.2390883207321 40.587876759782255\n",
      "55 of 493 305.6837917606036 40.47994455098624\n",
      "56 of 493 311.30412789583204 40.39541660108264\n",
      "57 of 493 316.9019059936206 40.30769857489924\n",
      "58 of 493 322.33804945151013 40.199630313417465\n",
      "59 of 493 327.6913280010223 40.082018373723095\n",
      "60 of 493 333.0425228913625 39.9651027514802\n",
      "61 of 493 338.4226385593414 39.85250197697641\n",
      "62 of 493 343.7497998515765 39.73451987826268\n",
      "63 of 493 349.0919693549474 39.619167956318805\n",
      "64 of 493 354.4545696934064 39.5069155846205\n",
      "65 of 493 359.75503208637235 39.38856377414761\n",
      "66 of 493 365.04371907313663 39.26985463594547\n",
      "67 of 493 370.3638798594475 39.15538531352138\n",
      "68 of 493 375.637486855189 39.03683687279817\n",
      "69 of 493 380.8792008280754 38.91591835178326\n",
      "70 of 493 386.2205136179924 38.80596589668781\n",
      "71 of 493 391.50669785340625 38.69115488645989\n",
      "72 of 493 396.78755156596503 38.57656751894288\n",
      "73 of 493 402.12099335591 38.46773886596231\n",
      "74 of 493 407.54813758134844 38.368270614644786\n",
      "75 of 493 413.1512510975202 38.28534927199417\n",
      "76 of 493 418.7732340812683 38.20387398998292\n",
      "78 of 493 429.9619575540225 38.03509624913717\n",
      "79 of 493 435.5434194366137 37.94924730883453\n",
      "80 of 493 441.1356782078743 37.86414571566714\n",
      "81 of 493 446.676216506958 37.77447016516341\n",
      "82 of 493 452.2174495697021 37.68478746844663\n",
      "83 of 493 457.76925134658813 37.5959083986777\n",
      "84 of 493 463.28317732810973 37.50387626386824\n",
      "85 of 493 468.75806005795795 37.4087314632383\n",
      "86 of 493 474.1288809657097 37.305489474867656\n",
      "87 of 493 479.44252836704254 37.19812720406102\n",
      "88 of 493 484.808277396361 37.0951788037022\n",
      "89 of 493 490.15863019625345 36.99137228259062\n",
      "90 of 493 495.48149906396867 36.885844934684265\n",
      "91 of 493 500.8273267149925 36.78237326514808\n",
      "92 of 493 506.1843669573466 36.68002659390514\n",
      "93 of 493 511.5455485065778 36.578256966922446\n",
      "94 of 493 516.8758599638938 36.47457309957797\n",
      "95 of 493 522.2319629748662 36.372998126896505\n",
      "96 of 493 527.5980699340503 36.272367310581934\n",
      "97 of 493 533.1930156985919 36.18749849030653\n",
      "98 of 493 538.8373419642448 36.105767475219274\n",
      "99 of 493 544.4707670291265 36.023065901499\n",
      "100 of 493 549.9747679233551 35.93168484050433\n",
      "101 of 493 555.4285895387331 35.837059162487954\n",
      "102 of 493 560.8228718837103 35.738712426911\n",
      "103 of 493 566.2717730760575 35.643967597204885\n",
      "104 of 493 571.7333795388539 35.550088346791576\n",
      "105 of 493 577.195398235321 35.456288750631465\n",
      "106 of 493 582.6074669361115 35.359509787735696\n",
      "107 of 493 588.0379568934441 35.26395847664135\n",
      "108 of 493 593.4755814393361 35.16892335273601\n",
      "109 of 493 598.9122474948565 35.073912966577645\n",
      "110 of 493 604.3361534039179 34.978244033431764\n",
      "111 of 493 609.7662790298461 34.883025875762776\n",
      "112 of 493 615.0726702253024 34.78089504444411\n",
      "113 of 493 620.3859559973081 34.67939193843448\n",
      "114 of 493 625.7630355676015 34.581641441301294\n",
      "115 of 493 631.1352308909098 34.483765516253484\n",
      "116 of 493 636.5082933266957 34.386080215899874\n",
      "117 of 493 641.8512135386467 34.286923802437265\n",
      "118 of 493 647.2087806264559 34.188712430016025\n",
      "119 of 493 652.6500932772955 34.095025883810635\n",
      "120 of 493 657.9610234220822 33.9946528788805\n",
      "121 of 493 663.3105204383533 33.89644670926452\n",
      "122 of 493 668.6621248523394 33.79849538362852\n",
      "123 of 493 673.9503217617671 33.697516090075176\n",
      "124 of 493 679.22699842453 33.596174118300915\n",
      "125 of 493 684.6322623968124 33.501338709004195\n",
      "126 of 493 690.2082526723544 33.414843980871815\n",
      "127 of 493 695.8002701282501 33.329015566401594\n",
      "128 of 493 701.4751478552819 33.246999196633695\n",
      "129 of 493 707.2586271087329 33.16988135028563\n",
      "130 of 493 713.1352081775665 33.096787868607755\n",
      "131 of 493 719.0057862520218 33.023039293531845\n",
      "132 of 493 724.907668642203 32.95034857730071\n",
      "133 of 493 730.7739219188691 32.875668920066914\n",
      "134 of 493 736.6495813806852 32.80106345159596\n",
      "135 of 493 742.4536522308986 32.72295726618944\n",
      "136 of 493 748.2692769010862 32.64508119996661\n",
      "137 of 493 754.0913710157076 32.56720641462859\n",
      "138 of 493 759.5047312259674 32.47157909097591\n",
      "139 of 493 765.5769017577171 32.40391442884215\n",
      "140 of 493 770.9146043300628 32.304992944989884\n",
      "141 of 493 776.2211324334145 32.20491932617575\n",
      "142 of 493 781.5262732505798 32.104952541391995\n",
      "143 of 493 786.8249374429384 32.0048838209527\n",
      "144 of 493 792.1307682712873 31.905267056403332\n",
      "145 of 493 797.5178334275881 31.809044622874353\n",
      "146 of 493 803.0840965588887 31.719988289847404\n",
      "147 of 493 808.6435096184413 31.630613473360498\n",
      "148 of 493 814.2546640753746 31.543198700457722\n",
      "149 of 493 819.7452068328857 31.451074491511704\n",
      "150 of 493 825.0933117429415 31.35354584723049\n",
      "151 of 493 830.3941640814145 31.25434988556538\n",
      "152 of 493 835.7199832876523 31.156227449346012\n",
      "153 of 493 841.0580745855967 31.058680533834274\n",
      "154 of 493 846.4357529679934 30.962693129119078\n",
      "155 of 493 851.74893121322 30.86445051942077\n",
      "156 of 493 857.0566756645838 30.766137076682515\n",
      "157 of 493 862.404618593057 30.66937868843581\n",
      "158 of 493 867.7870000044505 30.573930170230895\n",
      "159 of 493 873.157116830349 30.478125777360773\n",
      "160 of 493 878.444105287393 30.379525309112335\n",
      "161 of 493 883.7220591664314 30.280745507111785\n",
      "162 of 493 889.0980339566867 30.18542707993415\n",
      "163 of 493 894.4835567077001 30.09050001744519\n",
      "164 of 493 899.9794396877289 29.999314656919903\n",
      "165 of 493 905.3236151536306 29.903113350254117\n",
      "166 of 493 910.6706712961197 29.80709225384107\n",
      "167 of 493 915.9526463230451 29.709042921063112\n",
      "168 of 493 921.2448301116625 29.611440969445404\n",
      "169 of 493 926.6291718920072 29.516885850866867\n",
      "170 of 493 931.9383809248607 29.420015555529815\n",
      "171 of 493 937.3887369910876 29.327659316553238\n",
      "172 of 493 942.700947578748 29.231037136159205\n",
      "173 of 493 948.1055652499199 29.1373482971415\n",
      "174 of 493 953.4557903130849 29.042044188862103\n",
      "175 of 493 958.7946283896764 28.94646640138588\n",
      "176 of 493 964.1789384881655 28.852324296076493\n",
      "177 of 493 969.5318664669991 28.75730112458914\n",
      "178 of 493 974.8584522445997 28.661568728482234\n",
      "179 of 493 980.3103087027868 28.569564863724928\n",
      "180 of 493 985.9271686633427 28.48234042876738\n",
      "181 of 493 991.519012804826 28.394329005233562\n",
      "182 of 493 996.9906298120817 28.30284755043422\n",
      "183 of 493 1003.0768873294195 28.228666502138523\n",
      "184 of 493 1008.5101454695066 28.135971451047542\n",
      "185 of 493 1013.9865244746209 28.04449216394382\n",
      "186 of 493 1019.430669327577 27.952131256268874\n",
      "187 of 493 1024.9026771187782 27.860545145062133\n",
      "188 of 493 1030.9988463322322 27.7857845119438\n",
      "189 of 493 1036.416422367096 27.692608112221876\n",
      "190 of 493 1041.8004684368768 27.59857381343354\n",
      "191 of 493 1047.2486997882525 27.506270387897384\n",
      "192 of 493 1052.5565256237983 27.41032618879444\n",
      "193 of 493 1057.8956710537275 27.315268190813665\n",
      "194 of 493 1063.2498394608497 27.2206574033059\n",
      "195 of 493 1068.606642238299 27.126168611546866\n",
      "196 of 493 1073.9570302208265 27.031571509098793\n",
      "197 of 493 1079.2608539303144 26.935867336352064\n",
      "198 of 493 1084.5991832733155 26.841090900558815\n",
      "199 of 493 1089.9304702917734 26.746199983414627\n",
      "200 of 493 1095.2799841086069 26.651812946687805\n",
      "201 of 493 1100.535110159715 26.55520041980158\n",
      "202 of 493 1105.8549418568612 26.460225507335046\n",
      "203 of 493 1111.1892938574156 26.365657301421493\n",
      "204 of 493 1117.2348108212152 26.287877902267798\n",
      "205 of 493 1122.552503780524 26.19289175583257\n",
      "206 of 493 1127.8561852216721 26.097643121648755\n",
      "207 of 493 1133.1464939594268 26.002153847484387\n",
      "208 of 493 1138.457909989357 25.90721525995268\n",
      "209 of 493 1143.7136377215386 25.81108129829976\n",
      "210 of 493 1148.9512002150218 25.714622100987132\n",
      "211 of 493 1154.2241829554239 25.619035973162195\n",
      "212 of 493 1159.5413917183876 25.524496044743987\n",
      "213 of 493 1164.863332148393 25.430114998199013\n",
      "214 of 493 1170.9138415416082 25.35156136699493\n",
      "215 of 493 1176.2189338525136 25.256794161446955\n",
      "216 of 493 1181.5192079464593 25.161983132160007\n",
      "217 of 493 1186.7859920978547 25.066524410845986\n",
      "218 of 493 1192.232809706529 24.97490748267169\n",
      "219 of 493 1197.5624248862266 24.880863166020514\n",
      "220 of 493 1202.9107908407848 24.78725266028414\n",
      "221 of 493 1208.219590473175 24.692873983948655\n",
      "222 of 493 1213.502188583215 24.59801733656867\n",
      "223 of 493 1218.7887126723924 24.503300726454118\n",
      "224 of 493 1224.1941158056259 24.411013619230378\n",
      "225 of 493 1229.7843236883482 24.322401068758964\n",
      "226 of 493 1235.3611452420553 24.23348559307959\n",
      "227 of 493 1241.1865692615509 24.14937157543862\n",
      "228 of 493 1247.0969780286152 24.066783786973755\n",
      "229 of 493 1253.0209640026092 23.984316851521275\n",
      "230 of 493 1258.9043048381805 23.900936802384933\n",
      "231 of 493 1264.7215612133343 23.816185244105082\n",
      "232 of 493 1270.5162145137788 23.730906305860053\n",
      "233 of 493 1276.3136232376098 23.645581432155158\n",
      "234 of 493 1282.0714154958725 23.559431994713613\n",
      "235 of 493 1287.7751079479854 23.472212961165617\n",
      "236 of 493 1293.4919721603394 23.385165598805564\n",
      "237 of 493 1299.2091441313426 23.29805427266157\n",
      "238 of 493 1304.7936183055242 23.208513939436855\n",
      "239 of 493 1310.2505821903546 23.116694372219023\n",
      "240 of 493 1315.620515680313 23.02335902450813\n",
      "241 of 493 1320.9770854274432 22.929823544030096\n",
      "242 of 493 1327.0390021006267 22.848467667582284\n",
      "243 of 493 1332.3625621795654 22.75434005404124\n",
      "244 of 493 1337.7945602854093 22.662093644523225\n",
      "245 of 493 1343.0542136629422 22.566965358897942\n",
      "246 of 493 1348.3883629441261 22.47313938253456\n",
      "247 of 493 1353.8436486879984 22.38135586627796\n",
      "248 of 493 1359.3993957161904 22.29122665056832\n",
      "249 of 493 1364.9624352176984 22.201196235714352\n",
      "250 of 493 1370.5077393571535 22.110858195393874\n",
      "251 of 493 1376.0521619319916 22.02048944467356\n",
      "252 of 493 1381.6441211144129 21.93085906560143\n",
      "253 of 493 1387.0978784640631 21.839024568596425\n",
      "254 of 493 1392.44722695748 21.745566930452775\n",
      "255 of 493 1397.7735988577208 21.651787119835806\n",
      "256 of 493 1403.0884556094804 21.557869500696867\n",
      "257 of 493 1408.4559274077415 21.464795262253084\n",
      "258 of 493 1413.8355330030124 21.37193247575168\n",
      "259 of 493 1419.186930425962 21.278671479425626\n",
      "260 of 493 1424.516499920686 21.18511717884153\n",
      "261 of 493 1429.8688188234964 21.091934683968436\n",
      "262 of 493 1435.2292825897534 20.99890171768859\n",
      "263 of 493 1440.5517397522926 20.90534527275977\n",
      "264 of 493 1445.8974889993667 20.81216082723454\n",
      "265 of 493 1451.2400024453798 20.718961041361787\n",
      "266 of 493 1456.6104387879373 20.626187917829164\n",
      "267 of 493 1461.9542734066645 20.533065638163414\n",
      "268 of 493 1467.234211953481 20.439083549967457\n",
      "269 of 493 1472.5256216963132 20.3453044387825\n",
      "270 of 493 1477.8074347257614 20.251435216844815\n",
      "271 of 493 1483.2259440541268 20.159467013292062\n",
      "272 of 493 1488.498519965013 20.06554377384533\n",
      "273 of 493 1493.8892925103505 19.973245119592935\n",
      "274 of 493 1499.3054920752843 19.881301537433583\n",
      "275 of 493 1504.7048859834672 19.789149106378503\n",
      "276 of 493 1510.1003734151523 19.696961392737244\n",
      "277 of 493 1515.5260044256845 19.605179961186742\n",
      "278 of 493 1521.0083718458811 19.51413618540021\n",
      "279 of 493 1526.4912609974542 19.423096690102433\n",
      "280 of 493 1531.9502846598625 19.33175359222435\n",
      "281 of 493 1537.3952296098073 19.24023685952499\n",
      "282 of 493 1542.917512555917 19.1496854398662\n",
      "283 of 493 1548.619761868318 19.061338647383543\n",
      "284 of 493 1554.3435179432233 18.973207261560482\n",
      "285 of 493 1560.1687900622685 18.886253774569745\n",
      "286 of 493 1566.1149327198664 18.80068042775088\n",
      "287 of 493 1572.1000374356906 18.71547663645139\n",
      "288 of 493 1578.1115968982378 18.630484130429444\n",
      "289 of 493 1584.2055277705192 18.54635075779729\n",
      "290 of 493 1590.3505526304245 18.462690323618176\n",
      "291 of 493 1596.4758902231852 18.37867433772669\n",
      "292 of 493 1602.6192151586215 18.294739899155392\n",
      "293 of 493 1608.7806329329808 18.21088429755929\n",
      "294 of 493 1614.95727348725 18.12707143710719\n",
      "295 of 493 1621.1420070608458 18.043218948732658\n",
      "296 of 493 1627.30966086785 17.959048059167447\n",
      "297 of 493 1632.6731474955877 17.86595195102638\n",
      "298 of 493 1637.9038881699244 17.771440397380097\n",
      "299 of 493 1643.1966061155001 17.677644647585776\n",
      "300 of 493 1648.4425844391187 17.583387567310865\n",
      "301 of 493 1653.7184969147047 17.489492409187473\n",
      "302 of 493 1659.0097669561703 17.395797776996517\n",
      "303 of 493 1664.2802695592245 17.301923594459716\n",
      "304 of 493 1669.5603844682375 17.208188173208846\n",
      "305 of 493 1674.8574627637863 17.114663690697522\n",
      "306 of 493 1680.1589731613794 17.02121835533699\n",
      "307 of 493 1685.4863474408785 16.928065921706303\n",
      "308 of 493 1690.7593335866927 16.83440029106787\n",
      "309 of 493 1696.022556312879 16.740675717827568\n",
      "310 of 493 1701.3313826362291 16.64743610935399\n",
      "311 of 493 1706.5949519077938 16.55378811857538\n",
      "312 of 493 1711.8655176917712 16.460245362377577\n",
      "313 of 493 1717.09330590566 16.366331297037533\n",
      "314 of 493 1722.3224092562994 16.272472868869258\n",
      "315 of 493 1727.5992327690124 16.179103925914994\n",
      "316 of 493 1732.860936109225 16.08562894269887\n",
      "317 of 493 1738.1666107177734 15.992594998626599\n",
      "318 of 493 1743.4255547483763 15.899163864058767\n",
      "319 of 493 1748.655804892381 15.805509625980559\n",
      "320 of 493 1753.8879052996635 15.711912484909101\n",
      "321 of 493 1759.1161365071932 15.618320838006241\n",
      "322 of 493 1764.3694888075192 15.524990325633457\n",
      "323 of 493 1769.5995844841004 15.431492764475957\n",
      "324 of 493 1774.9893930514654 15.339414507731975\n",
      "325 of 493 1780.2283133625983 15.246057863203482\n",
      "326 of 493 1785.508157503605 15.153085590208073\n",
      "327 of 493 1790.9657041708629 15.061638184926803\n",
      "328 of 493 1796.501371427377 14.970844761696126\n",
      "329 of 493 1802.0458927472432 14.880115527680342\n",
      "330 of 493 1807.469050904115 14.788383143621257\n",
      "331 of 493 1812.8438113451004 14.696266547016712\n",
      "332 of 493 1818.2487964510917 14.604408003373482\n",
      "333 of 493 1823.6924855470656 14.512868128209504\n",
      "334 of 493 1828.964201215903 14.419977234883934\n",
      "335 of 493 1834.2611001292864 14.32731307081461\n",
      "336 of 493 1839.6630792101225 14.23548811281011\n",
      "337 of 493 1845.1994798580806 14.144704222258385\n",
      "338 of 493 1850.7301713148752 14.053868164637613\n",
      "339 of 493 1856.257658457756 13.963000086905206\n",
      "340 of 493 1861.700337767601 13.8714927126699\n",
      "341 of 493 1866.959863114357 13.77863828575895\n",
      "342 of 493 1872.2165652632714 13.68579360558624\n",
      "343 of 493 1877.5184987425805 13.593306914938665\n",
      "344 of 493 1882.8607318679492 13.501133154622188\n",
      "345 of 493 1888.1577661792437 13.408656600013444\n",
      "346 of 493 1893.4176141222317 13.315942758121553\n",
      "347 of 493 1898.6869593779245 13.223324164648762\n",
      "348 of 493 1903.9730937401453 13.130848922051227\n",
      "349 of 493 1909.3063039620718 13.038720222623322\n",
      "350 of 493 1914.5539856036505 12.946031712023421\n",
      "351 of 493 1919.9367083152135 12.85427710706182\n",
      "352 of 493 1925.1837699015935 12.761634838122765\n",
      "353 of 493 1930.5335821350416 12.669696313200193\n",
      "354 of 493 1936.0735926310222 12.579009217571626\n",
      "355 of 493 1941.6300597906113 12.488418694245428\n",
      "356 of 493 1947.2108793020248 12.397971890602964\n",
      "357 of 493 1952.7495016535124 12.307244757974848\n",
      "358 of 493 1958.2398687442144 12.216207747228173\n",
      "359 of 493 1963.7481479684511 12.125278722289472\n",
      "360 of 493 1969.178247944514 12.033867070575555\n",
      "361 of 493 1974.6548770387967 11.942741869295252\n",
      "362 of 493 1980.1974924961726 11.852010774406791\n",
      "363 of 493 1985.8536589185396 11.761943158768975\n",
      "364 of 493 1991.6035570661227 11.672401799381284\n",
      "365 of 493 1997.3302750547728 11.58269154921732\n",
      "366 of 493 2003.086089058717 11.49311690420618\n",
      "367 of 493 2008.7691591421762 11.403094681629687\n",
      "368 of 493 2014.3231001178424 11.312321757667743\n",
      "369 of 493 2019.7265846411387 11.22070324780764\n",
      "370 of 493 2024.9832304557165 11.128286221133692\n",
      "371 of 493 2030.2370061278343 11.035879503094039\n",
      "372 of 493 2035.5049181580544 10.943574828599521\n",
      "373 of 493 2040.7686155557633 10.851271905557256\n",
      "374 of 493 2046.0819008708 10.759254202268979\n",
      "375 of 493 2051.3625567038853 10.667085294537012\n",
      "376 of 493 2056.6511687874795 10.57497941371397\n",
      "377 of 493 2062.048274560769 10.483446134900117\n",
      "378 of 493 2067.2935906171797 10.391158259538326\n",
      "379 of 493 2072.5357156356176 10.298880204925508\n",
      "380 of 493 2078.5374827742576 10.210359564244403\n",
      "381 of 493 2083.7929078737893 10.11815453914155\n",
      "382 of 493 2089.034663852056 10.025908072477105\n",
      "383 of 493 2094.302720801036 9.933811860791588\n",
      "384 of 493 2099.56617817084 9.841716459737055\n",
      "385 of 493 2104.8243698914844 9.749619375360474\n",
      "386 of 493 2110.097905198733 9.657615628123416\n",
      "387 of 493 2115.340839203199 9.565494750568726\n",
      "388 of 493 2120.593121290207 9.47344006041208\n",
      "389 of 493 2125.848180941741 9.381420849731262\n",
      "390 of 493 2131.135644042492 9.289565627621785\n",
      "391 of 493 2136.380024123192 9.197544008198529\n",
      "392 of 493 2141.5616474350295 9.105279112917083\n",
      "393 of 493 2146.75839223067 9.013107753427379\n",
      "394 of 493 2152.030657569567 8.921277683431391\n",
      "395 of 493 2157.2945532917975 8.829433403533386\n",
      "396 of 493 2162.5294090032576 8.737492561276119\n",
      "397 of 493 2167.777823579311 8.645629438952739\n",
      "398 of 493 2172.985916697979 8.553629654935463\n",
      "399 of 493 2178.201539838314 8.461685179361423\n",
      "400 of 493 2183.4238538185755 8.369791439326598\n",
      "401 of 493 2188.600549987952 8.277749378211642\n",
      "402 of 493 2193.773822021484 8.18572321627863\n",
      "403 of 493 2198.9815186103183 8.093852570418619\n",
      "404 of 493 2204.3490058819452 8.002587149614685\n",
      "405 of 493 2209.577558469772 7.910833233706257\n",
      "406 of 493 2214.816330997149 7.819138114076527\n",
      "407 of 493 2220.0453506390254 7.727430581342091\n",
      "408 of 493 2225.2624343196553 7.635704431109173\n",
      "409 of 493 2230.492970232169 7.5440471279242205\n",
      "410 of 493 2235.706537822882 7.45235512586435\n",
      "411 of 493 2240.9645116329193 7.360832337173423\n",
      "412 of 493 2246.45882879893 7.270093296695551\n",
      "413 of 493 2251.972893802325 7.179413180012424\n",
      "414 of 493 2257.4990074197453 7.08876499882643\n",
      "415 of 493 2262.9252347230913 6.99780092641611\n",
      "416 of 493 2268.2667902112007 6.9065815723254405\n",
      "417 of 493 2273.618383868535 6.815402828882353\n",
      "418 of 493 2278.947281551361 6.724166619674062\n",
      "419 of 493 2284.258917438984 6.632891844321672\n",
      "420 of 493 2289.547831082344 6.541565231304323\n",
      "421 of 493 2294.8337337811786 6.450245252886048\n",
      "422 of 493 2300.174088235696 6.359091080866589\n",
      "423 of 493 2305.482200860977 6.267859411001021\n",
      "424 of 493 2310.7871558467546 6.176632334580589\n",
      "425 of 493 2316.0945666233697 6.085424939187215\n",
      "426 of 493 2321.538733343283 5.994583583496545\n",
      "427 of 493 2327.115057214101 5.90407801352409\n",
      "428 of 493 2332.7143498539926 5.81361831701186\n",
      "429 of 493 2338.314337662856 5.723146980003318\n",
      "430 of 493 2343.8506871978443 5.632509402928424\n",
      "431 of 493 2349.136377811432 5.541272971208915\n",
      "432 of 493 2354.3582350293796 5.449903321612025\n",
      "433 of 493 2360.374157090982 5.360357015486676\n",
      "434 of 493 2365.812515834967 5.269474881368911\n",
      "435 of 493 2371.316934967041 5.1787381335688725\n",
      "436 of 493 2376.8188750108084 5.087991475156078\n",
      "437 of 493 2382.345017794768 4.9972912268863805\n",
      "438 of 493 2387.7987209995586 4.906435727699346\n",
      "439 of 493 2393.2117376724877 4.8154981808774355\n",
      "440 of 493 2398.633518254757 4.724581171942481\n",
      "441 of 493 2403.9913706382117 4.633543457560526\n",
      "442 of 493 2409.3693308631578 4.542551528300512\n",
      "443 of 493 2414.7636424779894 4.451595879360069\n",
      "444 of 493 2420.179340247313 4.360683495570588\n",
      "445 of 493 2425.5406498591105 4.2696782971773795\n",
      "446 of 493 2430.898344743252 4.17867428408491\n",
      "447 of 493 2436.2661625266073 4.087694903151658\n",
      "448 of 493 2441.627808900674 3.9967121869615383\n",
      "449 of 493 2446.9532051881156 3.905678834837583\n",
      "450 of 493 2452.3260259310405 3.8147293731548175\n",
      "451 of 493 2457.6152562975885 3.723659478907632\n",
      "452 of 493 2462.893133926392 3.6325857429213726\n",
      "453 of 493 2468.1916940013566 3.54155541042925\n",
      "454 of 493 2473.507101003329 3.450560566347655\n",
      "455 of 493 2478.8278721253077 3.3595835626425106\n",
      "456 of 493 2484.150461304188 3.2686190276257467\n",
      "457 of 493 2489.5218270222344 3.1777266204515113\n",
      "458 of 493 2494.7775043368338 3.0866970574291916\n",
      "459 of 493 2500.0443480730055 2.9956958416011266\n",
      "460 of 493 2505.3124690890313 2.9047101087650824\n",
      "461 of 493 2510.6048864444097 2.8137654182190617\n",
      "462 of 493 2515.8962258219717 2.7228314128771873\n",
      "463 of 493 2521.193057421843 2.6319149982560175\n",
      "464 of 493 2526.4497832457223 2.5409696092368135\n",
      "465 of 493 2531.725417292118 2.450056855034232\n",
      "466 of 493 2537.04392127196 2.3591967790807233\n",
      "467 of 493 2542.344213481744 2.2683299545091073\n",
      "468 of 493 2547.6289096275964 2.1774606061236486\n",
      "469 of 493 2552.9415541410444 2.0866260034413586\n",
      "470 of 493 2558.202443532149 1.995760771051088\n",
      "471 of 493 2563.3947299957276 1.9048580791865\n",
      "472 of 493 2568.6358280499776 1.8140083527183337\n",
      "473 of 493 2573.8403873682023 1.7231489550938486\n",
      "474 of 493 2579.019827779134 1.6322910296690598\n",
      "475 of 493 2584.1678073048593 1.5414334284716866\n",
      "476 of 493 2589.337824912866 1.4506094254148452\n",
      "477 of 493 2594.6326763470965 1.3598703751419898\n",
      "478 of 493 2599.9542418519654 1.2691547899944997\n",
      "479 of 493 2605.148499417305 1.1783900655332156\n",
      "480 of 493 2610.347671111425 1.0876448624564607\n",
      "481 of 493 2615.6156760891276 0.9969429115035826\n",
      "482 of 493 2620.86712577343 0.9062472768520173\n",
      "483 of 493 2626.148222879569 0.8155739818744769\n",
      "484 of 493 2631.5185072342556 0.724936227434478\n",
      "485 of 493 2636.664986737569 0.6342493092019706\n",
      "486 of 493 2641.8909383177756 0.5435989581835424\n",
      "487 of 493 2647.1441396633786 0.45296785382546656\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got -1.2614840989399294 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(SetsNeeded\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     PercentHoldOutForNext \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m (SamplesPerSet \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(MoveSegments))\n\u001b[0;32m----> 5\u001b[0m     seq_train, seq_test, out_train, out_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMoveSegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNextDataPoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPercentHoldOutForNext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     seq_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(seq_train)\n\u001b[1;32m      7\u001b[0m     out_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(out_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 203\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got -1.2614840989399294 instead."
     ]
    }
   ],
   "source": [
    "st = ti()\n",
    "\n",
    "for i in range(SetsNeeded-1):\n",
    "    PercentHoldOutForNext = 1.0 - (SamplesPerSet / len(MoveSegments))\n",
    "    seq_train, seq_test, out_train, out_test = train_test_split(MoveSegments, NextDataPoint, test_size=PercentHoldOutForNext, shuffle=True, random_state=0)\n",
    "    seq_train = np.asarray(seq_train)\n",
    "    out_train = np.asarray(out_train)\n",
    "    if i == 0:\n",
    "        vb = 1\n",
    "    else:\n",
    "        vb = 0\n",
    "    with tf.device('/GPU:0'):\n",
    "        H = lstm_autoencoder2.model.fit(seq_train, out_train, epochs=2, batch_size=1024, verbose=vb)\n",
    "    MoveSegments = seq_test\n",
    "    NextDataPoint = out_test\n",
    "    print(str(i+1)+' of ' + str(SetsNeeded), (ti()-st)/60, (((ti()-st)/(i+1) * ( SetsNeeded -1) - (ti()-st) )/60/60))\n",
    "\n",
    "    if i%5 == 0:\n",
    "        lstm_autoencoder2.model.save(\"LSTM_predict_large_500p25.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_autoencoder2.model.save(\"LSTM_predict_large_500p25b.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(H.history[\"loss\"], label=\"Training Loss\")\n",
    "#plt.plot(H.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00311845,  0.01081402,  0.00319379],\n",
       "       [ 0.00332033,  0.01263257,  0.00348377],\n",
       "       [ 0.0037333 ,  0.0078548 ,  0.00498618],\n",
       "       ...,\n",
       "       [ 0.03218827,  0.01272697, -0.00209308],\n",
       "       [ 0.03081046,  0.0056819 ,  0.00099249],\n",
       "       [ 0.02999813,  0.00075985,  0.00289052]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_Test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_X = lstm_autoencoder2.model.predict(Input_Test[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 3), dtype=float32). Expected shape (None, 500, 3), but input has incompatible shape (32, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=('tf.Tensor(shape=(32, 3), dtype=float32)', 'tf.Tensor(shape=(32, 3), dtype=float32)', 'tf.Tensor(shape=(32, 3), dtype=float32)', 'tf.Tensor(shape=(32, 3), dtype=float32)')\n  • training=False\n  • mask=('None', 'None', 'None', 'None')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_X \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_autoencoder2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInput_Test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m TestResults \u001b[38;5;241m=\u001b[39m output_X \u001b[38;5;241m-\u001b[39m Output_test[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/models/functional.py:244\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 3), dtype=float32). Expected shape (None, 500, 3), but input has incompatible shape (32, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=('tf.Tensor(shape=(32, 3), dtype=float32)', 'tf.Tensor(shape=(32, 3), dtype=float32)', 'tf.Tensor(shape=(32, 3), dtype=float32)', 'tf.Tensor(shape=(32, 3), dtype=float32)')\n  • training=False\n  • mask=('None', 'None', 'None', 'None')"
     ]
    }
   ],
   "source": [
    "TestResults = output_X - Output_test[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "178f6c3502586c94dc93af50f98dbd15c5205250cbf2345a6eb57380f8c77d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
