{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Header used on the projects\n",
    "\n",
    "#first the major packages used for math and graphing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import scipy.special as sp\n",
    "import pandas as pd\n",
    "\n",
    "#Custome graph format style sheet\n",
    "#plt.style.use('Prospectus.mplstyle')\n",
    "\n",
    "#If being run by a seperate file, use the seperate file's graph format and saving paramaeters\n",
    "#otherwise set what is needed\n",
    "if not 'Saving' in locals():\n",
    "    Saving = True\n",
    "if not 'Titles' in locals():\n",
    "    Titles = True\n",
    "if not 'Ledgends' in locals():\n",
    "    Ledgends = True\n",
    "if not 'FFormat' in locals():\n",
    "    FFormat = '.png'\n",
    "Computer = \"SciClone\"   # \"SciClone\"    \"WinLap\"  \"LinLap\"   \"Desktop\" \n",
    "\n",
    "#Standard cycle for collors and line styles\n",
    "default_cycler = (cycler('color', ['0.00', '0.40', '0.60', '0.70']) + cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "my_cmap = plt.get_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotWidthIn = 11\n",
    "PlotHeightIn = 3.75\n",
    "PlotDPI = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import pywt\n",
    "from pywt._extensions._pywt import (DiscreteContinuousWavelet, ContinuousWavelet,\n",
    "                                Wavelet, _check_dtype)\n",
    "from pywt._functions import integrate_wavelet, scale2frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaveletToUse = 'gaus2'\n",
    "scales = 400\n",
    "spacer = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Computer == \"SciClone\":\n",
    "    location = '/sciclone/home20/dchendrickson01/image/'\n",
    "elif Computer == \"WinLap\":\n",
    "    location = 'C:\\\\Data\\\\'\n",
    "elif Computer == \"Desktop\":\n",
    "    location = \"E:\\\\Backups\\\\Dan\\\\CraneData\\\\\"\n",
    "elif Computer == \"LinLap\":\n",
    "    location = '/home/dan/Output/'\n",
    "    \n",
    "\n",
    "if Computer ==  \"SciClone\":\n",
    "    rootfolder = '/sciclone/home20/dchendrickson01/'\n",
    "    folder = '/sciclone/data10/dchendrickson01/SmallCopy/'\n",
    "elif Computer == \"Desktop\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"SmallCopy\\\\\"\n",
    "elif Computer ==\"WinLap\":\n",
    "    rootfolder = location\n",
    "    folder = rootfolder + \"SmallCopy\\\\\"   \n",
    "elif Computer == \"LinLap\":\n",
    "    rootfolder = '/home/dan/Data/'\n",
    "    folder = rootfolder + 'SmallCopy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SensorPositonFile = rootfolder + 'SensorStatsSmall.csv'\n",
    "SaveModelFolder = rootfolder + 'SavedModel\\\\'\n",
    "OutputVectors = np.genfromtxt(open(SensorPositonFile,'r'), delimiter=',',skip_header=1,dtype=int, missing_values=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Headers:\n",
    "import os as os\n",
    "import statistics as st\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns names for a file with all 6 dimmensions\n",
    "Header = np.array(['t', 's','x','y','z','s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwt_fixed(data, scales, wavelet, scalespace =spacer, sampling_period=1.):\n",
    "    \"\"\"\n",
    "    COPIED AND FIXED FROM pywt.cwt TO BE ABLE TO USE WAVELET FAMILIES SUCH\n",
    "    AS COIF AND DB\n",
    "\n",
    "    COPIED From Spenser Kirn\n",
    "    \n",
    "    All wavelet work except bior family, rbio family, haar, and db1.\n",
    "    \n",
    "    cwt(data, scales, wavelet)\n",
    "\n",
    "    One dimensional Continuous Wavelet Transform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Input signal\n",
    "    scales : array_like\n",
    "        scales to use\n",
    "    wavelet : Wavelet object or name\n",
    "        Wavelet to use\n",
    "    sampling_period : float\n",
    "        Sampling period for frequencies output (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coefs : array_like\n",
    "        Continous wavelet transform of the input signal for the given scales\n",
    "        and wavelet\n",
    "    frequencies : array_like\n",
    "        if the unit of sampling period are seconds and given, than frequencies\n",
    "        are in hertz. Otherwise Sampling period of 1 is assumed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Size of coefficients arrays depends on the length of the input array and\n",
    "    the length of given scales.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pywt\n",
    "    >>> import numpy as np\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> x = np.arange(512)\n",
    "    >>> y = np.sin(2*np.pi*x/32)\n",
    "    >>> coef, freqs=pywt.cwt(y,np.arange(1,129),'gaus1')\n",
    "    >>> plt.matshow(coef) # doctest: +SKIP\n",
    "    >>> plt.show() # doctest: +SKIP\n",
    "    ----------\n",
    "    >>> import pywt\n",
    "    >>> import numpy as np\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "    >>> sig  = np.cos(2 * np.pi * 7 * t) + np.real(np.exp(-7*(t-0.4)**2)*np.exp(1j*2*np.pi*2*(t-0.4)))\n",
    "    >>> widths = np.arange(1, 31)\n",
    "    >>> cwtmatr, freqs = pywt.cwt(sig, widths, 'mexh')\n",
    "    >>> plt.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "    ...            vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "    >>> plt.show() # doctest: +SKIP\n",
    "    \"\"\"\n",
    "\n",
    "    # accept array_like input; make a copy to ensure a contiguous array\n",
    "    dt = _check_dtype(data)\n",
    "    data = np.array(data, dtype=dt)\n",
    "    if not isinstance(wavelet, (ContinuousWavelet, Wavelet)):\n",
    "        wavelet = DiscreteContinuousWavelet(wavelet)\n",
    "    if np.isscalar(scales):\n",
    "        scales = np.r_[1:scales+1] * scalespace\n",
    "    if data.ndim == 1:\n",
    "        try:\n",
    "            if wavelet.complex_cwt:\n",
    "                out = np.zeros((np.size(scales), data.size), dtype=complex)\n",
    "            else:\n",
    "                out = np.zeros((np.size(scales), data.size))\n",
    "        except AttributeError:\n",
    "            out = np.zeros((np.size(scales), data.size))\n",
    "        precision = 10\n",
    "        int_psi, x = integrate_wavelet(wavelet, precision=precision)\n",
    "        step = x[1] - x[0]\n",
    "        for i in np.arange(np.size(scales)):\n",
    "            \n",
    "            j = np.floor(\n",
    "                np.arange(scales[i] * (x[-1] - x[0]) + 1) / (scales[i] * step))\n",
    "            if np.max(j) >= np.size(int_psi):\n",
    "                j = np.delete(j, np.where((j >= np.size(int_psi)))[0])\n",
    "            coef = - np.sqrt(scales[i]) * np.diff(np.convolve(data, int_psi[j.astype(int)][::-1]))\n",
    "            d = (coef.size - data.size) / 2.\n",
    "            out[i, :] = coef[int(np.floor(d)):int(-np.ceil(d))]\n",
    "        #frequencies = scale2frequency(wavelet, scales, precision)\n",
    "        #if np.isscalar(frequencies):\n",
    "        #    frequencies = np.array([frequencies])\n",
    "        #for i in np.arange(len(frequencies)):\n",
    "        #    frequencies[i] /= sampling_period\n",
    "        frequencies = []\n",
    "        return out, frequencies\n",
    "    else:\n",
    "        raise ValueError(\"Only dim == 1 supported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWvltImage(data, wvt=WaveletToUse, ns=scales, scalespace=spacer):\n",
    "    if np.shape(data)[0] == 2:\n",
    "        wvt = data[1]\n",
    "        data = data[0]\n",
    "\n",
    "    #try:\n",
    "    cfX, freqs = cwt_fixed(data[0], ns, wvt,scalespace)\n",
    "    cfY, freqs = cwt_fixed(data[1], ns, wvt,scalespace)\n",
    "    cfZ, freqs = cwt_fixed(data[2], ns, wvt,scalespace)\n",
    "    \n",
    "    ThreeColor = np.concatenate((cfX,cfY),axis=2)\n",
    "    ThreeColor = np.concatenate((ThreeColor,cfZ),axis=2)\n",
    "    \n",
    "    minVal = np.min(ThreeColor)\n",
    "    maxVal = np.max(ThreeColor)\n",
    "    rangeVal = maxVal - minVal#\n",
    "\n",
    "    ThreeColor -= minVal\n",
    "    ThreeColor /= rangeVal\n",
    "\n",
    "    ThreeColor *= float(255)\n",
    "\n",
    "    ThreeColor = ThreeColor.astype(int)\n",
    "    \n",
    "    return ThreeColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truthVector(Filename):\n",
    "    # Parses the filename, and compares it against the record of sensor position on cranes\n",
    "    # inputs: filename\n",
    "    # outputs: truth vector\n",
    "\n",
    "\n",
    "    #Parsing the file name.  Assuming it is in the standard format\n",
    "    sSensor = Filename[23]\n",
    "    sDate = datetime.datetime.strptime('20'+Filename[10:21],\"%Y%m%d-%H%M\")\n",
    "\n",
    "    mask = []\n",
    "\n",
    "    i=0\n",
    "    #loops through the known sensor movements, and creates a filter mask\n",
    "    for spf in OutputVectors:\n",
    "        \n",
    "        startDate = datetime.datetime.strptime(str(spf[0])+str(spf[1]).zfill(2)+str(spf[2]).zfill(2)\n",
    "            +str(spf[3]).zfill(2)+str(spf[4]).zfill(2),\"%Y%m%d%H%M\")\n",
    "        #datetime.date(int(spf[0]), int(spf[1]), int(spf[2])) + datetime.timedelta(hours=spf[3]) + datetime.timedelta(minutes=spf[4])\n",
    "        endDate = datetime.datetime.strptime(str(spf[5])+str(spf[6]).zfill(2)+str(spf[7]).zfill(2)\n",
    "            +str(spf[8]).zfill(2)+str(spf[9]).zfill(2),\"%Y%m%d%H%M\")\n",
    "        #datetime.date(int(spf[5]), int(spf[6]), int(spf[7])) + datetime.timedelta(hours=spf[8]) + datetime.timedelta(minutes=spf[9])\n",
    "        \n",
    "        if sDate >= startDate and sDate <= endDate and int(spf[10]) == int(sSensor):\n",
    "            mask.append(True)\n",
    "            i+=1\n",
    "        else:\n",
    "            mask.append(False)\n",
    "        \n",
    "    if i != 1: print('error ', i, Filename)\n",
    "\n",
    "    results = OutputVectors[mask,11:]\n",
    "\n",
    "    if i > 1: \n",
    "        print('Found Two ', Filename)\n",
    "        results = results[0,:]\n",
    "    #np.array(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opens all files in a folder and returns the 3 axis acceleration in one array\n",
    "# made to run in parallel\n",
    "\n",
    "def getAcceleration(FileName):\n",
    "    \n",
    "        DataSet = np.genfromtxt(open(FileName,'r'), delimiter=',',skip_header=0)\n",
    "        JustFileName = FileName.rsplit('/', 1)[-1]\n",
    "        if FileName[-20:-16] == 'Gyro':\n",
    "            return [False,FileName,False]\n",
    "        else:\n",
    "            if FileName[-6:-5] == 's':\n",
    "                FileDate = FileName[-18:-7]\n",
    "                sensor = FileName[-5:-4]\n",
    "            elif FileName[-21:-16] == 'Accel':\n",
    "                FileDate = FileName[-15:-4]\n",
    "                sensor = 1\n",
    "            else:\n",
    "                FileDate = FileName[-20:-4]\n",
    "                sensor = 1\n",
    "            return [[FileDate, 'x',DataSet[:,2], sensor,JustFileName],[FileDate,'y',DataSet[:,3],sensor,JustFileName],[FileDate,'z',DataSet[:,4],sensor,JustFileName]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KalmanFilterDenoise(data, rate=1):\n",
    "\n",
    "    #https://jamwheeler.com/college-productivity/how-to-denoise-a-1-d-signal-with-a-kalman-filter-with-python/\n",
    "    #\n",
    "\n",
    "    def oavar(data, rate, numpoints=30):\n",
    "\n",
    "        x = np.cumsum(data)\n",
    "\n",
    "        max_ratio = 1/9\n",
    "        num_points = 30\n",
    "        ms = np.unique(\n",
    "            np.logspace(0, np.log10(len(x) * max_ratio), numpoints\n",
    "           ).astype(int))        \n",
    "\n",
    "        oavars = np.empty(len(ms))\n",
    "        for i, m in enumerate(ms):\n",
    "            oavars[i] = (\n",
    "                (x[2*m:] - 2*x[m:-m] + x[:-2*m])**2\n",
    "            ).mean() / (2*m**2)\n",
    "\n",
    "        return ms / rate, oavars\n",
    "\n",
    "    def ln_NKfit(ln_tau, ln_N, ln_K):\n",
    "        tau = np.exp(ln_tau)\n",
    "        N, K = np.exp([ln_N, ln_K])\n",
    "        oadev = N**2 / tau + K**2 * (tau/3)\n",
    "        return np.log(oadev)\n",
    "\n",
    "    def get_NK(data, rate):\n",
    "        taus, oavars = oavar(data, rate)\n",
    "\n",
    "        ln_params, ln_varmatrix = (\n",
    "            curve_fit(ln_NKfit, np.log(taus), np.log(oavars))\n",
    "        )\n",
    "        return np.exp(ln_params)    \n",
    "\n",
    "    # Initialize state and uncertainty\n",
    "    state = data[0]\n",
    "    output = np.empty(len(data))\n",
    "\n",
    "    #rate = 1 # We can set this to 1, if we're calculating N, K internally\n",
    "    # N and K will just be scaled relative to the sampling rate internally\n",
    "    dt = 1/rate\n",
    "\n",
    "    N, K = get_NK(data, rate)\n",
    "\n",
    "    process_noise = K**2 * dt\n",
    "    measurement_noise = N**2 / dt\n",
    "\n",
    "    covariance = measurement_noise\n",
    "\n",
    "    for index, measurement in enumerate(data):\n",
    "        # 1. Predict state using system's model\n",
    "\n",
    "        covariance += process_noise\n",
    "\n",
    "        # Update\n",
    "        kalman_gain = covariance / (covariance + measurement_noise)\n",
    "\n",
    "        state += kalman_gain * (measurement - state)\n",
    "        covariance = (1 - kalman_gain) * covariance\n",
    "\n",
    "        output[index] = state\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs:\n",
    "#folder1 = 'C:\\\\Users\\\\Hendrickson\\\\Desktop\\\\Phone Acceleration\\\\'\n",
    "#folder2 = 'E:\\\\Documents\\\\Dan\\\\PhD\\\\Data Backup\\\\ASC Accel Pi\\\\Excel Versions\\\\'\n",
    "#folder = \"E:\\\\Documents\\\\Dan\\\\Port Work\\\\OneDrive\\OneDrive - The Port of Virginia\\\\Shared with Everyone\\\\Crane Data\\\\\"\n",
    "#folder = \"C:\\\\Users\\\\Dan\\\\Desktop\\\\TempData\\\\\"\n",
    "\n",
    "\n",
    "files = os.listdir(folder)\n",
    "\n",
    "Groups = 1\n",
    "GroupSize = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Calculations\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()-1\n",
    "\n",
    "if np.shape(files)[0] < GroupSize:\n",
    "    GroupSize = np.shape(files)[0]\n",
    "\n",
    "if Groups !=0:\n",
    "    files = random.sample(files,GroupSize*Groups)\n",
    "\n",
    "loops = int(float(np.size(files))/float(GroupSize))+1\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllAccels = Parallel(n_jobs=num_cores)(delayed(getAcceleration)(folder+file) for file in files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaData = []  #np.asarray([],dtype=object)\n",
    "DataOnlyMatrix = np.asarray([],dtype=object)\n",
    "for j in range(np.shape(AllAccels)[0]):\n",
    "    if AllAccels[j][0] == False :\n",
    "        if AllAccels[j][1][4:9] =='Accel':\n",
    "            print(j,AllAccels[j][1])\n",
    "    else: \n",
    "        for k in range(3):\n",
    "            MetaData.append([AllAccels[j][k][0], AllAccels[j][k][1], AllAccels[j][k][3], AllAccels[j][k][4]])\n",
    "            if np.size(DataOnlyMatrix) == 0:\n",
    "                    DataOnlyMatrix =np.matrix(AllAccels[j][k][2])\n",
    "            else:\n",
    "                    DataOnlyMatrix = np.concatenate((DataOnlyMatrix,np.matrix(AllAccels[j][k][2])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveKalmaned = np.asarray([],dtype=object)\n",
    "waveKalmaned = Parallel(n_jobs=num_cores)(delayed(KalmanFilterDenoise)(np.asarray(data).flatten()) for data in DataOnlyMatrix)\n",
    "waveKalmaned = np.matrix(waveKalmaned)\n",
    "\n",
    "DataOnlyMatrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.shape(waveKalmaned)[0]\n",
    "justifier = np.ones((length, np.shape(waveKalmaned)[1]))\n",
    "average = np.zeros(length)\n",
    "for i in range(length):\n",
    "    average[i]= np.average(waveKalmaned[i][:])\n",
    "justifier = justifier.T * average.T\n",
    "waveKalmaned = waveKalmaned - justifier.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "maxes = np.amax(waveKalmaned[:,500:], axis = 1)\n",
    "mins = np.amin(waveKalmaned[:,500:], axis = 1)\n",
    "\n",
    "Files = np.zeros(int(mins.size/3))\n",
    "Keep = np.zeros(mins.size)\n",
    "for i in range(mins.size):\n",
    "    if i % 3 == 0:\n",
    "        if maxes[i] > 0.01 and mins[i] < -0.01:\n",
    "            Keep[i]=1\n",
    "            Keep[i+1]=1\n",
    "            Keep[i+2]=1\n",
    "            print(i)\n",
    "            \n",
    "            Files[int(i/3)] = 1\n",
    "\n",
    "Keep = np.array(Keep, dtype='bool')\n",
    "Files = np.array(Files, dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveKalmaned = waveKalmaned[Keep,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFiles = []\n",
    "\n",
    "for i in range(np.size(files)):\n",
    "    if Files[i]:\n",
    "        newFiles.append(files[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "MovesLeft = np.size(newFiles)\n",
    "ColorWaveletMoves = []\n",
    "for i in range(MovesLeft):\n",
    "    ThreeAxis = np.concatenate((np.concatenate(([waveKalmaned[i*3,], waveKalmaned[i*3+1]]),axis=1)\n",
    "                                                       , waveKalmaned[i*3+2]),axis=1)\n",
    "    ColorWaveletMoves.append(ThreeAxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 180000)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/scipy/optimize/minpack.py:834: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/scipy/optimize/minpack.py:834: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    }
   ],
   "source": [
    "np.shape(ColorWaveletMoves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/sciclone/home20/dchendrickson01/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/local/scr/dchendrickson01/TMPDIR/ipykernel_171961/376838003.py\", line 7, in getWvltImage\nIndexError: index 0 is out of bounds for axis 0 with size 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_171961/525334114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetWvltImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mColorWaveletMoves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/testenv2/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/testenv2/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/testenv2/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "images = Parallel(n_jobs=num_cores)(delayed(getWvltImage)(image) for image in ColorWaveletMoves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Truth = []\n",
    "for file in newFiles:\n",
    "    Truth.append(truthVector(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_171961/2879421289.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "np.shape(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local/scr/dchendrickson01/TMPDIR/ipykernel_171961/2879362679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch_size = GroupSize\n",
    "img_height = np.shape(images[0])[0]\n",
    "img_width = np.shape(images[0])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[files[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11c16a051206f53cf7fe024f12cacb318023d916d0a5509b7bf3391ee4b4163a"
  },
  "kernelspec": {
   "display_name": "testenv2",
   "language": "python",
   "name": "testenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
